<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: dropincc | Meta-Interpretation]]></title>
  <link href="http://pfmiles.github.com/blog/category/dropincc/atom.xml" rel="self"/>
  <link href="http://pfmiles.github.com/"/>
  <updated>2012-08-13T19:32:12+08:00</updated>
  <id>http://pfmiles.github.com/</id>
  <author>
    <name><![CDATA[pf_miles]]></name>
    <email><![CDATA[miles.wy.1@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Growing a Full-Featured Calculator in 15 Minutes Using Dropincc.java]]></title>
    <link href="http://pfmiles.github.com/blog/growing-a-full-featured-calculator-in-15-minutes-using-dropincc-dot-java"/>
    <updated>2012-08-12T15:58:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/growing-a-full-featured-calculator-in-15-minutes-using-dropincc-dot-java</id>
    <content type="html"><![CDATA[<p>First, let's create a empty java project in eclipse IDE, download newest playable dropincc.java jar file from <a href="https://github.com/pfmiles/dropincc.java/downloads">here</a>. Adding it to the build path of the project, like this(note: jdk1.6 or above required):<br/>
<img src="/images/dropincc/calc/emptyProjWithJar.png" alt="emptyProjWithJar" /><br/>
And then, create a new java source file to build our grammar, for example, <code>Calculator.java</code>.<br/>
We start by specifying the EBNF form of our expected calculator language. The calculator expression would do addition and subtraction operations and also multiplication and division operations which have a greater priority.<br/>
Also, we expect the calculator could handle parentheses to do priority adjustment.<br/>
We could write the EBNF grammar rules in a top-down pattern:</p>

<pre><code>calc ::= expr $
expr ::= addend (('+'|'-') addend)*
</code></pre>

<p>We specified that the overall <code>expression</code> consists one or more <code>addend</code> sub-expressions with <code>'+'</code> or <code>'-'</code> symbol delimited.<br/>
And for every single <code>addend</code> expression:</p>

<pre><code>addend ::= factor (('\*'|'/') factor)*
</code></pre>

<p>consists one or more <code>factor</code> separated by <code>'*'</code> or <code>'/'</code>.<br/>
And finally, for any single <code>factor</code>, is either a single digit or a quoted expression:</p>

<pre><code>factor ::= '\d+(\.\d+)?'
         | '(' expr ')'
</code></pre>

<p>Ok, we've done defining the EBNF of our calculator. This is what it look like all over:</p>

<pre><code>calc ::= expr $
expr ::= addend (('+'|'-') addend)*
addend ::= factor (('\*'|'/') factor)*
factor ::= '\d+(\.\d+)?'
         | '(' expr ')'
</code></pre>

<!-- more -->


<p>It's quite short because it utilized the kleene notation to represent 'zero or more'. And a shorter EBNF ends up a shorter dropincc.java program!<br/>
Now let's 'translate' the EBNF into dropincc.java program. I say 'translate' here because it's a really straightforward step:</p>

<pre><code>// some elements' pre-definitions in order to call the methods
Lang calc = new Lang("Calc");
TokenDef a = calc.newToken("\\+");
TokenDef m = calc.newToken("\\*");
Grule expr = calc.newGrule();
Grule addend = calc.newGrule();
Grule factor = calc.newGrule();

// grammar definition section start
calc.defineGrule(expr, CC.EOF);
expr.define(addend, CC.ks(a.or("\\-"), addend));
addend.define(factor, CC.ks(m.or("/"), factor));
factor.define("\\d+(\\.\\d+)?")
.alt("\\(", expr, "\\)");
// grammar definition end
</code></pre>

<p>The 'grammar definition' part is as many lines as the EBNF. In fact it's a line-by-line translation of the EBNF(please look at the 'grammar definition' section carefully).</p>

<p>Just a little more explanation:</p>

<ul>
<li>The basic elements of grammar rule is <code>TokenDef</code>s and <code>Grule</code>s.(In fact <code>Grule</code> means 'grammar rule') <code>TokenDef</code>s are defined using java built-in regular expression currently.</li>
<li>Rule production's match sequence is represented as comma separated elements list. Like <code>expr, CC.EOF</code> means <code>expr $</code>, <code>addend, CC.ks(a.or("\\-"), addend)</code> means <code>addend (('+'|'-') addend)*</code>.</li>
<li>Note the <code>CC.EOF</code> constant, it's a predefined constant provided by dropincc.java to represent <code>EOF</code> token definition.</li>
<li>And the <code>CC.ks</code> method call means all elements passed in as parameters are enclosed in a kleene star node(kleene star node means zero or more multiplication of its enclosing elements, the same as you learnt from using a regular expression). And <code>ks</code> in fact means 'kleene star'.</li>
<li>Likewise, there are <code>CC.kc</code> method and <code>CC.op</code> method which means <code>kleene cross</code>(one or more) and <code>optional</code>(zero or one) respectively but not used in the above example, you can browse them from source code.</li>
<li>Rule alternative productions are represented by an <code>alt</code> method call. Look at the <code>factor</code> rule definition, the <code>factor</code> rule has two productions. And, respectively, in java code, it has an additional <code>alt</code> call besides <code>define</code>.</li>
</ul>


<p>'Comma separated match sequence', 'CC.EOF', 'CC.ks/kc/op' and 'alt', those are almost all you need to know to define a non-trivial DSL grammar in dropincc.java.</p>

<p>Ok, after we have defined the grammar, it's time to add <code>Action</code>s to process the elements the parser matched while parsing. It's also achieved by a very intuitive way:</p>

<ul>
<li>One <code>alternative production</code>(note: not one rule) could have only one action. That's, the <code>calc</code> rule could have only one action because it has only one alternative production. While <code>factor</code> rule could have two actions because it has two alternative productions.</li>
<li>Let's add actions for the <code>factor</code> rule first:</li>
</ul>


<p>For the first alternative production:</p>

<pre><code>factor.define("\\d+(\\.\\d+)?").action(new Action&lt;String&gt;(){
    public Double act(String matched) {
        return Double.parseDouble(matched);
    }})
</code></pre>

<p>The first alt of <code>factor</code> rule only matches a single string which have a 'digit' format. So the <code>act</code> method of the <code>Action</code> interface should be a single <code>String</code> object holding the matched digit string. And, also, the generic type argument of <code>Action</code> interface should be <code>String</code>, to provide a strong type safety for the actually matched element.<br/>
We just parse the matched digit string to a number and returned it. So the return type of this action is <code>Double</code>.</p>

<p>And the <code>Action</code> for the second alt:</p>

<pre><code>.alt("\\(", expr, "\\)").action(new Action&lt;Object[]&gt;(){
    public Double act(Object[] ms) {
        return (Double) ms[1];
    }
});
</code></pre>

<p>The second alt is an expression enclosed by parentheses. There are three element in the match sequence: <code>(</code>, enclosing <code>expr</code>, and <code>)</code>.<br/>
The type argument of <code>Action</code> interface should be <code>Object[]</code> since the matched element will be passed in as an object array of length 3. With first element <code>(</code>, second element the returned value of the enclosing <code>expr</code> rule's action, and third element <code>)</code>.<br/>
All we care about is the second element: the returned value of the enclosing <code>expr</code>'s action. So we just return <code>ms[1]</code> here, ignoring <code>(</code> and <code>)</code>. Note that we confidently converted the <code>ms[1]</code> to a <code>Double</code> object, that's because we knew the return value of <code>expr</code> rule's action is definitely a <code>Double</code> value.</p>

<ul>
<li>Then, let's add action for the <code>addend</code> rule:</li>
</ul>


<p>It has only one production, so it could have only one corresponding action:</p>

<pre><code>addend.define(factor, CC.ks(m.or("/"), factor)).action(new Action&lt;Object[]&gt;() {
    public Double act(Object[] ms) {
        Double f0 = (Double) ms[0];
        Object[] others = (Object[]) ms[1];
        for (Object other : others) {
            Object[] opAndFactor = (Object[]) other;
            if ("*".equals(opAndFactor[0])) {
                f0 *= (Double) opAndFactor[1];
            } else {
                f0 /= (Double) opAndFactor[1];
            }
        }
        return f0;
    }
});
</code></pre>

<p>The argument of <code>act</code> method is an object array of length 2. Its first element is the returned value from the matched <code>factor</code> rule's action,<br/>
and the second are other operator &amp; factor pairs.<br/>
If there's only one factor matched here, the 'operator &amp; factor' pairs would be an array of length 0, otherwise it contains all other matched operators and factors.<br/>
You can see that the argument structure of method <code>act</code> is highly consistent to the defined match sequence of the corresponding alternative production.</p>

<p>We wrote some logic to compute the total multiplication or division of all matched factors, and finally, returned the result as the result of this action.</p>

<ul>
<li>Then, we add action for the <code>expr</code> rule. It's almost the same as the action of <code>addend</code> rule, but in an <code>add</code> or <code>subtract</code> manner when computing the matched elements:</li>
</ul>


<p>The <code>expr</code> rule also could have only one action:</p>

<pre><code>expr.define(addend, CC.ks(a.or("\\-"), addend)).action(new Action&lt;Object[]&gt;() {
    public Double act(Object[] ms) {
        Double a0 = (Double) ms[0];
        Object[] others = (Object[]) ms[1];
        for (Object other : others) {
            Object[] opAndFactor = (Object[]) other;
            if ("+".equals(opAndFactor[0])) {
                a0 += (Double) opAndFactor[1];
            } else {
                a0 -= (Double) opAndFactor[1];
            }
        }
        return a0;
    }
});
</code></pre>

<p>Finally, we add action for the <code>calc</code> rule. It's the starter rule. All computations should have been done at this point. So all we need to do in its action is return the final result, ignoring the <code>EOF</code>:</p>

<pre><code>calc.defineGrule(expr, CC.EOF).action(new Action&lt;Object[]&gt;() {
    public Double act(Object[] ms) {
        return (Double) ms[0];
    }
});
</code></pre>

<p>Now, we have done defining a calculator and added proper actions for it, we could <code>compile</code> it now:</p>

<pre><code>Exe exe = calc.compile();
</code></pre>

<p>Then, enjoy with our new calculator:</p>

<pre><code>// this should print the result: 3389.0
System.out.println(exe.eval("1 +2+3+(4 +5*6*7*(64/8/2/(2/1 )/1)*8  +9  )+   10"));
</code></pre>

<p>It's quite simple isn't it? If you are already familiar with the API, 15 min is too much for defining such a calculator!<br/>
And the follow is all the code in a gist, you could copy and try it in your own IDE:<br/>
<div><script src='https://gist.github.com/3339604.js?file='></script>
<noscript><pre><code>import com.github.pfmiles.dropincc.Action;
import com.github.pfmiles.dropincc.CC;
import com.github.pfmiles.dropincc.Exe;
import com.github.pfmiles.dropincc.Grule;
import com.github.pfmiles.dropincc.Lang;
import com.github.pfmiles.dropincc.TokenDef;

public class Calculator {
    private static Exe exe = null;
    /**
     * &lt;pre&gt;
     * calc ::= expr $
     * expr ::= addend (('+'|'-') addend)*
     * addend ::= factor (('\*'|'/') factor)*
     * factor ::= '\d+(\.\d+)?'
     *          | '(' expr ')'
     * &lt;/pre&gt;
     */
    static {
        // some elements' pre-definitions in order to call the methods
        Lang calc = new Lang(&quot;Calc&quot;);
        TokenDef a = calc.newToken(&quot;\\+&quot;);
        TokenDef m = calc.newToken(&quot;\\*&quot;);
        Grule expr = calc.newGrule();
        Grule addend = calc.newGrule();
        Grule factor = calc.newGrule();

        // grammar definition starts here
        calc.defineGrule(expr, CC.EOF).action(new Action&lt;Object[]&gt;() {
            public Double act(Object[] ms) {
                return (Double) ms[0];
            }
        });
        expr.define(addend, CC.ks(a.or(&quot;\\-&quot;), addend)).action(new Action&lt;Object[]&gt;() {
            public Double act(Object[] ms) {
                Double a0 = (Double) ms[0];
                Object[] others = (Object[]) ms[1];
                for (Object other : others) {
                    Object[] opAndFactor = (Object[]) other;
                    if (&quot;+&quot;.equals(opAndFactor[0])) {
                        a0 += (Double) opAndFactor[1];
                    } else {
                        a0 -= (Double) opAndFactor[1];
                    }
                }
                return a0;
            }
        });
        addend.define(factor, CC.ks(m.or(&quot;/&quot;), factor)).action(new Action&lt;Object[]&gt;() {
            public Double act(Object[] ms) {
                Double f0 = (Double) ms[0];
                Object[] others = (Object[]) ms[1];
                for (Object other : others) {
                    Object[] opAndFactor = (Object[]) other;
                    if (&quot;*&quot;.equals(opAndFactor[0])) {
                        f0 *= (Double) opAndFactor[1];
                    } else {
                        f0 /= (Double) opAndFactor[1];
                    }
                }
                return f0;
            }
        });
        factor.define(&quot;\\d+(\\.\\d+)?&quot;).action(new Action&lt;String&gt;() {
            public Double act(String matched) {
                return Double.parseDouble(matched);
            }
        }).alt(&quot;\\(&quot;, expr, &quot;\\)&quot;).action(new Action&lt;Object[]&gt;() {
            public Double act(Object[] ms) {
                return (Double) ms[1];
            }
        });
        // grammar definition end

        exe = calc.compile();
    }

    public static void main(String... args) {
        System.out.println(exe.eval(&quot;1 +2+3+(4 +5*6*7*(64/8/2/(2/1 )/1)*8  +9  )+   10&quot;));
    }
}
</code></pre></noscript></div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ideas and Concepts behind Dropincc.java]]></title>
    <link href="http://pfmiles.github.com/blog/ideas-and-concepts-behind-dropincc-dot-java"/>
    <updated>2012-08-10T00:40:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/ideas-and-concepts-behind-dropincc-dot-java</id>
    <content type="html"><![CDATA[<h3>DSLs in java is hard.</h3>

<p>DSLs are rarely discussed in java community. Or, at least comparing to other dynamic languages' world, DSLs in java is much harder to create.</p>

<p>Why does this happen?</p>

<p>According to <a href="http://martinfowler.com/bliki/DomainSpecificLanguage.html">Martin Fowler's comments on DSLs</a>, they are separated mainly to two kinds: internal and external DSLs.</p>

<p>I believe that, the ability of how a specific general purposed programming language could be customized to an internal DSL relies on the language's <a href="http://en.wikipedia.org/wiki/Metaprogramming">meta-programming</a> features.</p>

<p>Some languages, especially dynamic typed ones, have ability to customize its syntactical appearance at runtime. By intercepting their class defining life-cycles, executing fail-over strategies when method or field missings, or doing presentation substitutions via sophisticated macro systems or even, directly change their parse tree at runtime. All those incredible features are the magic behind internal DSLs.</p>

<p>But, we sadly found that java has none of those magic stuff to help building internal DSLs. There's little meta-programming features in java. Annotations? Perhaps one rare creature, but its not enough.<br/>
Maybe the only way to create internal DSLs in java is to design a set of <a href="http://www.martinfowler.com/bliki/FluentInterface.html">Fluent Interface</a> API. It's great, but you won't have much space on customizing the syntax of your DSL.</p>

<p>Then, seems that the possible ways to create real-world, sophisticated DSLs in java are always turns out to be external-DSLs. But, this won't be easy, always, since the creation of computer world.</p>

<!-- more -->


<p>Creating external DSLs means doing lexical &amp; syntactical analyzing all by ourselves. There is a whole bunch of open sourced tools, say, <a href="http://en.wikipedia.org/wiki/Compiler-compiler">parser generators</a>, to help doing so, but there's too much unnecessary efforts must be made before you get your grammar run.</p>

<p>Those traditional parser generators are great but in fact not suitable for DSL creating. Like lex&amp;bison, javacc, jcup and antlr etc. They usually have their own grammar you must learn to define grammar rules, this is some what big learning cost.<br/>
After you have done writing your grammar, they usually requires you to run a specific compiling tool in command-line to 'compile' the rules you just wrote. And finally gives you a couple of source files in your host language and telling you to place them into somewhere of your project directory. Then you could run your program. If errors occur, you would re-do those steps by frequently switching between command-line and your IDE.</p>

<p>These steps are troublesome in practice. Especially for those first using a parser generator. I've seen one of my colleague struggled against antlr for one month, in order to build a SQL-like DSL. And much of his time was spent on getting familiar with antlr's grammar, its 'antlrWorks' IDE and some command-line tools. It was painful when recall on this month.</p>

<p>So I think one must not have to carry so much burden when he just want to create a relatively simple DSL. And <a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a> is something I create to ease the building process of external DSL in java.</p>

<h3>If all done in one place.</h3>

<ul>
<li>I don't think additional grammar must be created to describe grammar rules, this could be done in internal DSL in java, a.k.a fluent interfaces. Creating a <a href="http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form">EBNF</a> like internal DSL in java is affordable.</li>
<li>I don't think additional command-line tools or individual specific IDE is needed since we are adopting internal DSL to describe grammar rules. Just a commonly used java IDE is sufficient.</li>
<li>Also, I don't think we must repeat the compile-copy, and run cycle when we trying and debugging our new creating language. Grammar may be run directly just after we defined it. Like we edit and test java program instantly in most modern IDEs.</li>
</ul>


<p>And, all in all, in summary... dropincc.java ends up such a tool with those missions. I hope this small lib could help a lot in building external DSLs.</p>

<p>For a starter dummy example, please refer to <a href="/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java/">this post</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dropincc.java, The Ultimate Tool to Create DSLs in Java]]></title>
    <link href="http://pfmiles.github.com/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java"/>
    <updated>2012-08-04T17:22:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java</id>
    <content type="html"><![CDATA[<h3>Initial version released.</h3>

<p>Dropincc.java is a dynamic parser generator which allows you crafting your DSLs in pure java, using your favorite editor.<br/>
Now it reached its initial release version 0.1.0. You can download it from the <a href="https://github.com/pfmiles/dropincc.java">project page</a> and play around with it.<br/>
There's a detailed <em>Quick Start</em> guide on the project page, it could guide you through to have a overall feeling on using dropincc.java.</p>

<h3>Main attributes of Dropincc.java.</h3>

<ul>
<li>It's not just 'yet another compiler compiler'. It aims to help you building DSLs in java <strong>Dynamically</strong>.</li>
<li><strong>Dynamic</strong> means you can use your newly defined DSL immediately after you have just finished its definition. No other steps required, no additional command-line instructions needed to type.</li>
<li>Very close to EBNF grammar syntactically when defining grammar rules using dropincc.java. With the fluent interface API, you can feel as if you are writing EBNF directly. Syntactically  close to EBNF is very nice for a parser generator.</li>
<li>It generates LL(*) parser for your language, dynamically, using java 1.6's compiler API. And it provide powerful <em>semantic predicate</em> mechanics to handle even context-sensitive situations.</li>
<li>It won't generate a parser source file to you and telling you to place the file into some where of your project directory. Instead, it handles all those generation &amp; compiling staff in the background and only provides you a executable object which you can invoke.</li>
<li>No other dependencies except for the built-in java library. Requires JDK 1.6 or above.</li>
</ul>


<h3>A dummy language example.</h3>

<!-- more -->


<p>Requires JDK 1.6 or above. Firstly, place the dropincc <a href="https://github.com/downloads/pfmiles/dropincc.java/dropincc.java-0.1.0.jar">jar file</a> in your class path.</p>

<p>And then, crafting your language's <a href="http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form">EBNF</a> definition:<br/>
Let's define a language which accepts arbitrary numbers of quoted 'a' or 'bc'. For example: '(a)(bc)', '(bc)((a))' or '(((bc)))(bc)', the numbers of pairs of parentheses is unlimited.<br/>
The EBNF of this dummy language:</p>

<pre><code>S ::= L $
L ::= Q*
Q ::= 'a'
    | 'bc'
    | '(' Q ')'
</code></pre>

<p>Ok, after defining the EBNF representation of our language, it's time to <strong>translate</strong> the EBNF into dropincc.java representation. I say 'translate' here because this is a line-by-line straightforward step:</p>

<pre><code>public static void main(String... args) throws Throwable {
    Lang lang = new Lang("Dummy");
    TokenDef a = lang.newToken("a");
    TokenDef bc =lang.newToken("bc");
    TokenDef lp = lang.newToken("\\(");
    TokenDef rp = lang.newToken("\\)");
    Grule L = lang.newGrule();
    Grule Q = lang.newGrule();

    lang.defineGrule(L, CC.EOF); // S ::= L $
    L.define(CC.ks(Q));// L ::= Q*
    /*
     * Q ::= 'a'
     *     | 'bc'
     *     | '(' Q ')'
     */
    Q.define(a)
    .alt(bc)
    .alt(lp, Q, rp);
}
</code></pre>

<p>Ok, we have done defining the grammar rules of our dummy language, so easy:</p>

<ul>
<li>Define tokens, using built-in java regular expression syntax. And define rules, say, 'Grule's in dropincc.java. TokenDefs and Grules are basic elements of defining grammar rules.</li>
<li>You just using your defined TokenDefs and Grules to express your grammar, just like writing EBNF.</li>
<li>Elements concatenations are expressed by comma separated sequences: <code>L, CC.EOF</code> means <code>L $</code>. CC.EOF is a predefined TokenDef provided by dropincc.java.</li>
<li>Alternative productions of a grammar rule is expressed by a <code>alt</code> method call on a grule element. For example, the <code>Q</code> rule has three alternative productions.</li>
<li>The kleene star(means <strong>zero or more</strong>) and kleene cross(<strong>means one or more</strong>) notation is expressed by <code>CC.ks</code> and <code>CC.kc</code> utility functions. See the line: <code>L.define(CC.ks(Q));// L ::= Q*</code>.</li>
</ul>


<p>That's almost all you need to learn about how to define a grammar using dropincc.java.<br/>
After that, you can <code>compile</code> your grammar:</p>

<pre><code>Exe exe = lang.compile();
</code></pre>

<p>This step would make you a callable object named 'exe'. You can use this object to <code>eval</code> and test your newly defined language:</p>

<pre><code>System.out.println(exe.eval("a(a)((bc))"));
</code></pre>

<p>This would print the output: <code>[Ljava.lang.Object;@67a5a19</code>. It's an object array which holds the whole parse tree:<br/>
<img src="/images/dropincc/dummy.png" alt="Dummy lang parse tree" /></p>

<p>But it's useless just getting the parse tree. We should do something to manipulate the parse tree and produce some 'results' of this parsing.</p>

<p>Ok, suppose we have a dummy task: to remove all parentheses from the input string, leaving only the <code>'a'</code> and <code>'bc'</code>s there. Then at last, return the resulting string as the return value of <code>eval</code> method call on <code>exe</code>.</p>

<p>This involves adding <code>actions</code> to the grammar. The <code>action</code>s are some kind of code block, it should execute when its' corresponding grammar rule production matches.</p>

<p>In dropincc.java, <code>actions</code> are implemented by <code>closure</code>s, using the <code>Action</code> interface. We try to add an action to the <code>Q</code> rule:</p>

<pre><code>Q.define(a).action(new Action() {
    public String act(Object matched) {
        return (String) matched;// string 'a'
    }
}).alt(bc).action(new Action() {
    public String act(Object matched) {
        return (String) matched;// string 'bc'
    }

}).alt(lp, Q, rp).action(new Action() {
    public String act(Object matched) {
        // returns the middle element matched, that's the returned value of the enclosing 'Q' rule
        return (String) ((Object[]) matched)[1];
    }
});
</code></pre>

<p>Above is the <code>Q</code> rule with three actions, each action for one alternative production. In fact since the first two actions does noting but just returning the matched string, so they are not necessary. The <code>Q</code> rule with action could be defined as follows:</p>

<pre><code>Q.define(a)
.alt(bc)
.alt(lp, Q, rp).action(new Action() {
    public String act(Object matched) {
        // returns the middle element matched, that's the returned value of the enclosing 'Q' rule
        return (String) ((Object[]) matched)[1];
    }
});
</code></pre>

<p>Leaving only the third action there. The third action, returned the middle element matched of its production(ignored left and right parentheses). The middle element matched is the return value of the recursively enclosing <code>Q</code> rule.</p>

<p>The action for <code>L</code> rule is quite simple and significant: it collects all strings matched and concatenates them into a whole large string, then return the resulting string:</p>

<pre><code>L.define(CC.ks(Q)).action(new Action() {
    public String act(Object matched) {
        Object[] ms = (Object[]) matched;
        StringBuilder sb = new StringBuilder();
        for (Object m : ms)
            sb.append(m);
        return sb.toString();
    }
});// L ::= Q*
</code></pre>

<p>Then the last top-level rule's action: just return the value of <code>L</code> rule, just ignoring EOF:</p>

<pre><code>lang.defineGrule(L, CC.EOF).action(new Action() {
    public String act(Object matched) {
        return (String) ((Object[]) matched)[0];
    }
}); // S ::= L $
</code></pre>

<p>Ok, we can now run the program again and could see it prints out the output: <code>aabc</code>, with all parentheses removed.</p>

<p>The whole program in a gist:<br/>
<div><script src='https://gist.github.com/3257023.js?file='></script>
<noscript><pre><code>package test;

import com.github.pfmiles.dropincc.Action;
import com.github.pfmiles.dropincc.CC;
import com.github.pfmiles.dropincc.Exe;
import com.github.pfmiles.dropincc.Grule;
import com.github.pfmiles.dropincc.Lang;
import com.github.pfmiles.dropincc.TokenDef;

public class Test {

    /**
     * &lt;pre&gt;
     * S ::= L $
     * L ::= Q*
     * Q ::= 'a'
     *     | 'bc'
     *     | '(' Q ')'
     * &lt;/pre&gt;
     */
    public static void main(String... args) throws Throwable {
        Lang lang = new Lang(&quot;Dummy&quot;);
        TokenDef a = lang.newToken(&quot;a&quot;);
        TokenDef bc = lang.newToken(&quot;bc&quot;);
        TokenDef lp = lang.newToken(&quot;\\(&quot;);
        TokenDef rp = lang.newToken(&quot;\\)&quot;);
        Grule L = lang.newGrule();
        Grule Q = lang.newGrule();

        lang.defineGrule(L, CC.EOF).action(new Action() {
            public String act(Object matched) {
                return (String) ((Object[]) matched)[0];
            }
        }); // S ::= L $
        L.define(CC.ks(Q)).action(new Action() {
            public String act(Object matched) {
                Object[] ms = (Object[]) matched;
                StringBuilder sb = new StringBuilder();
                for (Object m : ms)
                    sb.append(m);
                return sb.toString();
            }
        });// L ::= Q*
        /*
         * Q ::= 'a' | 'bc' | '(' Q ')'
         */
        Q.define(a).alt(bc).alt(lp, Q, rp).action(new Action() {
            public String act(Object matched) {
                // returns the middle element matched, that's the returned value
                // of the enclosing 'Q' rule
                return (String) ((Object[]) matched)[1];
            }
        });

        Exe exe = lang.compile();
        System.out.println(exe.eval(&quot;a(a)((bc))&quot;));
    }
}</code></pre></noscript></div>

You can download and play around with it on your own.</p>

<p>Dropincc.java is currently on its very initial stage. It has some major improvements to be done:</p>

<ul>
<li>It uses java's built-in regEx implementation to support token definition, so it couldn't do 'longest match' currently. This should be fixed later.</li>
<li>Due to some LL(*) analysis issues, 'Non-LL regular' exceptions may be thrown when it encounters some special case of grammar rules. This must be fixed soon.</li>
</ul>


<p>There is a more practical <strong>Hello World</strong> example which implements a full-featured calculator in the quick start guide of dropincc.java. On its project <a href="https://github.com/pfmiles/dropincc.java">home page</a>. Go and check out there if you like.</p>

<p>I created a <a href="http://dropincc-java.1068093.n5.nabble.com/">forum</a> for dropincc.java, interested people could discuss about it in the forum. And you are welcomed to subscribe to the mailing list(there's a how to guide in the forum about subscribe to the mailing list).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LL(*)的概念与实现]]></title>
    <link href="http://pfmiles.github.com/blog/concept-and-implementation-of-ll-star"/>
    <updated>2012-07-14T13:59:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/concept-and-implementation-of-ll-star</id>
    <content type="html"><![CDATA[<h3>概念和起源</h3>

<p>LL(*)是由<a href="http://www.cs.usfca.edu/~parrt/">Terrence Parr</a>教授创造的，为使用<a href="http://en.wikipedia.org/wiki/LL_parsing">LL分析</a>的语法解析器做超前查看(look ahead)的一种算法。按照Parr教授的说法，这个算法从最初的想法至今的完善和调整已经历了15年。目前该算法的一个著名的实现在<a href="http://www.antlr.org/">antlr3</a>中。</p>

<h3>特点，n言以蔽之...</h3>

<ul>
<li>对于语法产生式分支的预测判断，走LL分析路子的解析器，其能力完全取决于能超前查看多少个token。传统地讲，LL(1), LL(2)直至LL(k)，就是在讲该解析器能够在语法分析过程中超前查看1, 2, k...个token。</li>
<li>而LL(*)的意思就是，它在语法解析的过程中，超前查看的token个数不是固定的，是可伸缩的，不过这一点LL(k)分析也能做到(在k范围之内...)；</li>
<li>但是，LL(*)还能越过一些重复出现的token，“到达”这些重复出现的token之后的token来做分析，这一点LL(k)是无法办到的(LL(k)无法意识到有token在循环出现，不管情况如何，它都将在尝试k个token之后放弃)；</li>
<li>如果将超前查看的决策逻辑画成DFA的话，就是这样的一种形式：<img src="/images/ll3.png" title="Look Ahead DFA" alt="Look Ahead DFA" />

<ul>
<li>这张图画的是这种语法规则的超前查看决策情况：<code>A ::= a b c | a b e</code>, 显然这是一个LL(3)语法；</li>
<li>但是这样的语法: <code>A ::= a b* c | a b* e</code>是无法被LL(k)识别的，因为中间的<code>b*</code>代表“0个或多个b”(kleene闭包)，这并不是一个固定的重复次数，因此LL(k)无法识别，for any k...</li>
<li>但是，LL(*)算法能够构造出这样的DFA来识别它：<img src="/images/llstar.png" title="LL(*) Look Ahead DFA" alt="LL(*) Look Ahead DFA" /></li>
<li>也就是说，传统LL(k)的look ahead DFA是不带环的，而LL(*)算法能构造出带环的DFA来做判断，它能越过无穷多个存在于环上的token，从而“到达”环之后的token继续做判断。</li>
</ul>
</li>
<li>上面的<code>A ::= a b* c | a b* e</code>语法使用了<a href="/blog/left-recursion-removal-using-kleene-closure/">"kleene闭包"表示法</a>来表示“0个或多个”，这种表示法在正则表达式中很常见；事实上，基于LL(*)算法实现的语法解析器生成器(比如antlr3)对Kleene闭包表示法特别友好，可以鼓励使用，还能顺便解决一些LL分析法所不允许的“<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>”。</li>
<li>大多数情况来讲，LL(*)的识别能力弱于<a href="http://en.wikipedia.org/wiki/LR_parser">LR(k)</a>，但也有少数情况是LR(k)识别不了但LL(*)可以的，所以LL(*)与LR(k)之间并没有严格的强弱顺序。</li>
<li>LL(*)本身对语法的识别能力也是有限的，比如它无法区分"具有相同的递归规则前缀"的多个分支，这种情况是要尽量避免的，大多数能够较容易地改写;</li>
<li>对于LL(*)不能正确分析的情况，还能引入"Semantic Predicate"(语义断言)来辅助判断, Semantic Predicate可以是任何逻辑，只要返回一个bool值就行；有了Semantic Predicate的辅助，LL(*)甚至能够parse一些上下文相关的语法，实际上它能parse C++</li>
</ul>


<h3>主要算法及其实现(python)</h3>

<p><strong> Parr教授在2011年发表的paper"LL(*): The Foundation of the ANTLR Parser Generator"中详细描述了这个算法，下面就是其主要过程，具体的代码实现(python)在工程<a href="https://github.com/pfmiles/llstar">llstar</a>中 </strong></p>

<!-- more -->


<p>为了简单起见，约定大写字母用来命名non-terminal, 小写字母命名terminal或Semantic Predicate，<code>$</code>表示EOF，假设有如下语法规则：</p>

<pre><code>S ::= A $  
A ::= a c*  
    | b c*  
</code></pre>

<ul>
<li>针对此语法规则，构造Augmented Transition Network(ATN)，其实也就是一个NFA，NFA的边就是terminal或non-terminal或者Semantic predicate：<img src="/images/atn.png" alt="ATN network" />, 代码在llstar工程的<code>atn_creation.py</code>的<code>rule.merge_to_atn</code>方法中。</li>
<li>接下来将要对这个ATN实施的算法其实就是经典的<a href="http://en.wikipedia.org/wiki/Powerset_construction">Subset Construction算法</a> —— 的改造版本：在“空边闭包运算(closure)”中加入了压栈、出栈功能，用于处理运算过程中<code>closure</code>函数经过non-terminal边时对其所对应的ATN的调用和返回。<br/>
这个算法的具体描述是比较复杂，在Parr教授的paper中已有精确描述。不过真的要用代码实现起来，某些细节还需稍微修饰，才能正确地实现。<br/>
最后的结果，其实就是使用更改后的版本的Subset Construction算法，将上述ATN(NFA)转化为一个个DFA，每条语法规则都对应一个DFA作为其look ahead DFA。<br/>
例如上面的<code>S</code>规则最后的DFA为：<img src="/images/sdfa.png" alt="S DFA" />, well, 就一个终结态，没任何状态转换 —— 这是当然的，S规则只有一个alternative production... <br/>
而<code>A</code>规则的DFA为：<img src="/images/adfa.png" alt="A DFA" />, 意思就是，如果第一个token为<code>a</code>，就选择第一个分支，若是<code>b</code>，就选择第二个分支，这是一个LL(1)的语法。<br/>
简单来说就是这样，具体可以参考llstar的代码...这花了我不少时间调试出来的代码，还是直接看代码了解最直接:)</li>
</ul>


<h3>实验台及例子介绍</h3>

<p>OK，主要的算法原理了解之后，展示了2个玩具例子，似乎还不能看出LL(*)的特点来。<br/>
下面我将逐步展示一些真正non-trivial的例子，以表明它真的不是过家家...</p>

<p>LL(3)(更正：或许这该是LL(4)可能我数错了)语法(对应llstar工程中的<code>LL_3_many_alts.py</code>):</p>

<pre><code>S ::= A $
A ::= B a*
    | C a+
    | D a?
B ::= a b c C
    | a b c D
    | d
C ::= e f g D
    | e f g h
D ::= i j k l
    | i j k m
</code></pre>

<p>这个语法是固定的LL(3)，没有什么特别，不过分支比较多, 它的ATN：<img src="/images/ll3atn.png" alt="LL(3) ATN" /><br/>
规则<code>A</code>的DFA: <img src="/images/llstar/ll3adfa.png" alt="LL(3) Rule A DFA" /><br/>
规则<code>B</code>的DFA: <img src="/images/llstar/ll3bdfa.png" alt="LL(3) Rule B DFA" /><br/>
规则<code>C</code>的DFA: <img src="/images/llstar/ll3cdfa.png" alt="LL(3) Rule C DFA" /><br/>
规则<code>D</code>的DFA: <img src="/images/llstar/ll3ddfa.png" alt="LL(3) Rule D DFA" /></p>

<p>上面这个语法，LL(4)分析也能搞定，而真正体现出LL(*)特点的是下面这样的语法(对应llstar工程中<code>over_kleene.py</code>)：</p>

<pre><code>S ::= A $
A ::= a* b
    | a+ c
</code></pre>

<p>其中，规则<code>A</code>的2条分支拥有共同的kleene闭包前缀，LL(k)是无法识别的，它的ATN:<img src="/images/llstar/overkleeneatn.png" alt="Over Kleene ATN" /><br/>
而LL(*)能够为<code>A</code>生成这样的DFA：<img src="/images/llstar/overkleeneadfa.png" alt="Over Kleene Rule A DFA" /><br/>
这个DFA能够越过terminal<code>a</code>的任意重复，从而考虑到后面的terminal<code>b</code>和<code>c</code>来做判断<br/>
而下面这个更加"恶劣"的列子则更能说明LL(*)的这个特征(对应llstar工程中<code>over_non_recurse_rule.py</code>)：</p>

<pre><code>S ::= A $
A ::= B* b
    | C+ c
B ::= a d
    | e
C ::= a d
    | e
</code></pre>

<p>这个例子中，<code>B</code>和<code>C</code>完全相同，并分别被包含在规则<code>A</code>的2条分支的kleene闭包中，<br/>
最终生成的<code>A</code>的DFA: <img src="/images/llstar/nonrecursiveradfa.png" alt="Non-recursive Rule A DFA" /></p>

<p>上面提到过，LL(*)也有不能解决的情况，比如2条分支拥有"共同的、递归的规则作为前缀"，比如这样：</p>

<pre><code>S ::= A eof
A ::= E a
    | E b
E ::= c E d
    | e
</code></pre>

<p>上面的<code>A</code>规则的两条分支拥有共同的前缀<code>E</code>，而<code>E</code>本身是一条递归规则，这样的规则是LL(*)无法分析的，在llstar工程中对应<code>experiments/common_recurse_prefix_fail.py</code>, 运行的时候会抛出错误提示。这种情况在antlr3中会将parsing策略退化为LL(1) + 回溯的形式。</p>

<pre><code>Traceback (most recent call last):
  File "/home/pf-miles/myWorkspace/llstar/experiments/common_recurse_prefix_fail.py", line 31, in &lt;module&gt;
    d_a = create_dfa(ra.get_start_state(globals_holder.a_net))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 136, in create_dfa
    d_state_new.add_all_confs(closure(d_state, conf))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 99, in closure
    raise Exception("Likely non-LL regular, recursive alts: " + str(d_state.recursive_alts) + ", rule: " + str(globals_holder.a_net.get_rule_of_state(p)))
Exception: Likely non-LL regular, recursive alts: set([0, 1]), rule: E
</code></pre>

<p>还有一些特殊情况，比如规则完全就是冲突的，那么这个时候就是Semantic Predicate发挥作用的时候(对应llstar工程中<code>conflicting_with_preds.py</code>)：</p>

<pre><code>S ::= A $
A ::= {pred1}? B
    | {pred2}? b
B ::= b
    | b
</code></pre>

<p>最终<code>A</code>的DFA：<img src="/images/llstar/confresolvedwithpredsadfa.png" alt="Conflict Resolved With Preds A DFA" /><br/>
实际开发中，写出这样的规则是坑到爷的...不过LL(*)还算能很好解决...其实这里就算没有Semantic Predicate, LL(*)也能按照convention，“选择较早定义的语法分支”来解决。</p>

<p>还有就是在分析的过程中会导致分析栈溢出(不是程序语言的callstack的overflow, 而是LL(*)的closure操作维护的一个规则调用栈溢出)的时候，LL(*)也会使用Semantic Predicate来辅助判断, 比如规则(对应llstar中<code>overflow_with_preds.py</code>):</p>

<pre><code>S ::= A $
A ::= {pred1?} B a
    | {pred2?} b* c
    | {pred3?} b* c
B ::= b+ B
</code></pre>

<p>规则<code>A</code>的三条分支全部存在严重冲突(都拥有能识别无穷个'b'的前缀)并且其中一个是另一条递归规则<code>B</code>，这种形式会导致LL(*)的分析栈溢出，不过仍然没关系，这样的情况能在溢出发生时，调用<code>pred1</code>、<code>pred2</code>和<code>pred3</code>来解决(这三个pred就是Semantic Precicate，是能包含任何逻辑但最终返回bool值的表达式)<br/>
生成的规则<code>A</code>的DFA: <img src="/images/llstar/overflowadfa.png" alt="Overflow A DFA" /><br/>
这里设定的最大分析递归层数为<code>10</code>，因此，DFA在接受了第10个'b'之后达到了溢出状态<code>d14</code>，这时调用了各个alternative附带的几个predicate来解决冲突...</p>

<h3>总结</h3>

<p>OK, 大概如是了；上述算法的实现、例子的代码均在<a href="https://github.com/pfmiles/llstar">llstar</a>工程中能找到<br/>
llstar工程是我花了不少时间实现并调试好的一块LL(*)算法的“实验台”，可以在里面慢慢把玩各种变态的、五花八门的语法规则，以验证LL(*)的分析能力<br/>
在工程的<code>experiments</code>文件夹下已经有许多具有代表性的例子...都是python代码<br/>
另外，llstar工程是在eclipse + pydev环境下开发的，因此如果要在命令行里运行，可能要对例子里面的import路径稍作修改，当然，最好是直接在eclipse + pydev环境下运行它们了<br/>
在linux环境下，llstar的所有例子都能自动生成上文中看到的各种DFA/NFA图像，不过前提是环境中要装有<a href="http://www.graphviz.org/">graphviz</a></p>

<p>现在的所有语法解析器生成器中，似乎都是LR分析的天下，LL分析大多是手写解析器的首选...<br/>
不过在现有的使用LL分析方式的产品中，也就只有LL(*)和PEG(Packrat)parsing比较常见也比较实用了，能与LR分析一较高下。<br/>
而配上回溯策略的LL(*)是严格强于Packrat parsing的，这样看来大概走LL分析路子的自动化工具也只有LL(*)容易一枝独秀了(想必这也是antlr相对较为流行的原因)。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Kleene闭包语法糖消除语法中的左递归]]></title>
    <link href="http://pfmiles.github.com/blog/left-recursion-removal-using-kleene-closure"/>
    <updated>2012-03-28T11:18:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/left-recursion-removal-using-kleene-closure</id>
    <content type="html"><![CDATA[<p>一般来讲，如果使用的解析器生成器是基于LL分析法来解析文本的话(比如antlr)，我们就需要在编写语法规则的时候避免<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>。<br/>
虽然有一套成熟的、公式化的方法来去除左递归，但它会影响原有文法的结合顺序、优先级，或者多出一些本不需要的、额外的产生式。<br/>
例如，有左递归语法规则：</p>

<pre><code>addition ::= addition '+' factor
           | factor
</code></pre>

<p>这个式子其实是想要表达一个“一连串+号组成的和”的表达式，例如<code>1+2+3+4</code>；<br/>
假设目前的输入就是<code>1+2+3+4</code>, 那么超前查看带来的选择应该是<code>addition '+' factor</code>这个产生式；于是在parser的代码中立刻就又直接调用了<code>addition()</code>方法，但注意，整个递归过程没有消耗掉任何token...也就是说，当流程再次递归到<code>addition</code>函数里时，输入<code>1+2+3+4</code>并没有任何改变，这又会进入下一轮递归...很快就会overflow。<br/>
这个问题，除了机械性地按照公式来消除左递归外，还可以改写语法规则，使其成为右递归语法：</p>

<pre><code>addition ::= factor '+' addition
           | factor
</code></pre>

<p>这样就不用stackOverFlow了，但是带来另一个问题：这使得我们的'+'加法成为了一个'右结合'的运算...<br/>
也就是说，<code>1+2+3+4</code>的计算次序是这样的：<code>1+(2+(3+4))</code><br/>
还好这里是“加法”，整数集合和加法运算构成“阿贝尔群(可交换群)”，满足交换律，所以就算实现成右结合的也能蒙混过关...但减法呢？除法呢？</p>

<!-- more -->


<p>难道要先生成一个AST，再写个visitor，把节点顺序给rewrite一下，然后再写个visitor求值？这么麻烦就为了实现一个简单的四则运算功能也太坑爹了。</p>

<p>其实，我们在这里使用递归，只是为了表达元素的“重复”这种意思；的确，递归能表示“重复”的概念，但这很容易让人联想到“循环”，因为平时的编程中，我们都通常使用循环来表达“重复”这种东西的。<br/>
更重要的是，循环与<a href="http://en.wikipedia.org/wiki/Tail_call">尾递归</a>在逻辑上是等价的，这使得我们可以将上述左递归改写成某种表示“循环”的形式，在这里，<a href="http://en.wikipedia.org/wiki/Kleene_star">Kleene Closure(克林闭包)</a>就正是一种表达“循环”的标记形式。<br/>
熟悉正则表达式的我们都知道，符号<code>*</code>(kleene star)和符号<code>+</code>(kleene cross)分别用来表示前面临接元素的“0个或多个”和“一个或多个”，如果这种标记用在我们的语法规则中那就酷毙了：</p>

<pre><code>addition ::= (factor '+')* factor
</code></pre>

<p>表达的意义和"左递归版本"的语法规则是一样的，但是，这种记法的重大意义就是：在生成的parser程序中可以直接以一个<code>while</code>语句来解析重复的<code>(factor '+')</code>而不用再递归回<code>addition</code>中！这样就避免了parser中的左递归实现带来的问题！<br/>
由于kleene闭包所能表达的所有语法规则形式都能被递归所表达，所以引入kleene闭包并没有从形式上增加语法解析器生成器的表达能力，所以说kleene闭包只是一个“语法糖”。<br/>
但它的实现意义却是重大的：解决了“为了表达‘元素重复’”的这一类左递归问题。
当然，<a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a>也会支持kleene闭包的表达形式，大致的api形式如下：</p>

<pre><code>addition.fillGrammarRule(addend, CC.ks(ADD.or(SUB), addend));
</code></pre>

<p><code>CC.ks</code>方法就是kleene star的意思，当然还有<code>CC.kc</code>，顾名思义。</p>
]]></content>
  </entry>
  
</feed>
