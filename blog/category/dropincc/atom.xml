<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: dropincc | Meta-Interpretation]]></title>
  <link href="http://pfmiles.github.com/blog/category/dropincc/atom.xml" rel="self"/>
  <link href="http://pfmiles.github.com/"/>
  <updated>2012-07-22T00:32:23+08:00</updated>
  <id>http://pfmiles.github.com/</id>
  <author>
    <name><![CDATA[pf_miles]]></name>
    <email><![CDATA[miles.wy.1@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[LL(*)的概念与实现]]></title>
    <link href="http://pfmiles.github.com/blog/concept-and-implementation-of-ll-star"/>
    <updated>2012-07-14T13:59:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/concept-and-implementation-of-ll-star</id>
    <content type="html"><![CDATA[<h3>概念和起源</h3>

<p>LL(*)是由<a href="http://www.cs.usfca.edu/~parrt/">Terrence Parr</a>教授创造的，为使用<a href="http://en.wikipedia.org/wiki/LL_parsing">LL分析</a>的语法解析器做超前查看(look ahead)的一种算法。按照Parr教授的说法，这个算法从最初的想法至今的完善和调整已经历了15年。目前该算法的一个著名的实现在<a href="http://www.antlr.org/">antlr3</a>中。</p>

<h3>特点，n言以蔽之...</h3>

<ul>
<li>对于语法产生式分支的预测判断，走LL分析路子的解析器，其能力完全取决于能超前查看多少个token。传统地讲，LL(1), LL(2)直至LL(k)，就是在讲该解析器能够在语法分析过程中超前查看1, 2, k...个token。</li>
<li>而LL(*)的意思就是，它在语法解析的过程中，超前查看的token个数不是固定的，是可伸缩的，不过这一点LL(k)分析也能做到(在k范围之内...)；</li>
<li>但是，LL(*)还能越过一些重复出现的token，“到达”这些重复出现的token之后的token来做分析，这一点LL(k)是无法办到的(LL(k)无法意识到有token在循环出现，不管情况如何，它都将在尝试k个token之后放弃)；</li>
<li>如果将超前查看的决策逻辑画成DFA的话，就是这样的一种形式：<img src="/images/ll3.png" title="Look Ahead DFA" alt="Look Ahead DFA" />

<ul>
<li>这张图画的是这种语法规则的超前查看决策情况：<code>A ::= a b c | a b e</code>, 显然这是一个LL(3)语法；</li>
<li>但是这样的语法: <code>A ::= a b* c | a b* e</code>是无法被LL(k)识别的，因为中间的<code>b*</code>代表“0个或多个b”(kleene闭包)，这并不是一个固定的重复次数，因此LL(k)无法识别，for any k...</li>
<li>但是，LL(*)算法能够构造出这样的DFA来识别它：<img src="/images/llstar.png" title="LL(*) Look Ahead DFA" alt="LL(*) Look Ahead DFA" /></li>
<li>也就是说，传统LL(k)的look ahead DFA是不带环的，而LL(*)算法能构造出带环的DFA来做判断，它能越过无穷多个存在于环上的token，从而“到达”环之后的token继续做判断。</li>
</ul>
</li>
<li>上面的<code>A ::= a b* c | a b* e</code>语法使用了<a href="/blog/left-recursion-removal-using-kleene-closure/">"kleene闭包"表示法</a>来表示“0个或多个”，这种表示法在正则表达式中很常见；事实上，基于LL(*)算法实现的语法解析器生成器(比如antlr3)对Kleene闭包表示法特别友好，可以鼓励使用，还能顺便解决一些LL分析法所不允许的“<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>”。</li>
<li>大多数情况来讲，LL(*)的识别能力弱于<a href="http://en.wikipedia.org/wiki/LR_parser">LR(k)</a>，但也有少数情况是LR(k)识别不了但LL(*)可以的，所以LL(*)与LR(k)之间并没有严格的强弱顺序。</li>
<li>LL(*)本身对语法的识别能力也是有限的，比如它无法区分"具有相同的递归规则前缀"的多个分支，这种情况是要尽量避免的，大多数能够较容易地改写;</li>
<li>对于LL(*)不能正确分析的情况，还能引入"Semantic Predicate"(语义断言)来辅助判断, Semantic Predicate可以是任何逻辑，只要返回一个bool值就行；有了Semantic Predicate的辅助，LL(*)甚至能够parse一些上下文相关的语法，实际上它能parse C++</li>
</ul>


<h3>主要算法及其实现(python)</h3>

<p><strong> Parr教授在2011年发表的paper"LL(*): The Foundation of the ANTLR Parser Generator"中详细描述了这个算法，下面就是其主要过程，具体的代码实现(python)在工程<a href="https://github.com/pfmiles/llstar">llstar</a>中 </strong></p>

<!-- more -->


<p>为了简单起见，约定大写字母用来命名non-terminal, 小写字母命名terminal或Semantic Predicate，<code>$</code>表示EOF，假设有如下语法规则：</p>

<pre><code>S ::= A $  
A ::= a c*  
    | b c*  
</code></pre>

<ul>
<li>针对此语法规则，构造Augmented Transition Network(ATN)，其实也就是一个NFA，NFA的边就是terminal或non-terminal或者Semantic predicate：<img src="/images/atn.png" alt="ATN network" />, 代码在llstar工程的<code>atn_creation.py</code>的<code>rule.merge_to_atn</code>方法中。</li>
<li>接下来将要对这个ATN实施的算法其实就是经典的<a href="http://en.wikipedia.org/wiki/Powerset_construction">Subset Construction算法</a> —— 的改造版本：在“空边闭包运算(closure)”中加入了压栈、出栈功能，用于处理运算过程中<code>closure</code>函数经过non-terminal边时对其所对应的ATN的调用和返回。<br/>
这个算法的具体描述是比较复杂，在Parr教授的paper中已有精确描述。不过真的要用代码实现起来，某些细节还需稍微修饰，才能正确地实现。<br/>
最后的结果，其实就是使用更改后的版本的Subset Construction算法，将上述ATN(NFA)转化为一个个DFA，每条语法规则都对应一个DFA作为其look ahead DFA。<br/>
例如上面的<code>S</code>规则最后的DFA为：<img src="/images/sdfa.png" alt="S DFA" />, well, 就一个终结态，没任何状态转换 —— 这是当然的，S规则只有一个alternative production... <br/>
而<code>A</code>规则的DFA为：<img src="/images/adfa.png" alt="A DFA" />, 意思就是，如果第一个token为<code>a</code>，就选择第一个分支，若是<code>b</code>，就选择第二个分支，这是一个LL(1)的语法。<br/>
简单来说就是这样，具体可以参考llstar的代码...这花了我不少时间调试出来的代码，还是直接看代码了解最直接:)</li>
</ul>


<h3>实验台及例子介绍</h3>

<p>OK，主要的算法原理了解之后，展示了2个玩具例子，似乎还不能看出LL(*)的特点来。<br/>
下面我将逐步展示一些真正non-trivial的例子，以表明它真的不是过家家...</p>

<p>LL(3)(更正：或许这该是LL(4)可能我数错了)语法(对应llstar工程中的<code>LL_3_many_alts.py</code>):</p>

<pre><code>S ::= A $
A ::= B a*
    | C a+
    | D a?
B ::= a b c C
    | a b c D
    | d
C ::= e f g D
    | e f g h
D ::= i j k l
    | i j k m
</code></pre>

<p>这个语法是固定的LL(3)，没有什么特别，不过分支比较多, 它的ATN：<img src="/images/ll3atn.png" alt="LL(3) ATN" /><br/>
规则<code>A</code>的DFA: <img src="/images/llstar/ll3adfa.png" alt="LL(3) Rule A DFA" /><br/>
规则<code>B</code>的DFA: <img src="/images/llstar/ll3bdfa.png" alt="LL(3) Rule B DFA" /><br/>
规则<code>C</code>的DFA: <img src="/images/llstar/ll3cdfa.png" alt="LL(3) Rule C DFA" /><br/>
规则<code>D</code>的DFA: <img src="/images/llstar/ll3ddfa.png" alt="LL(3) Rule D DFA" /></p>

<p>上面这个语法，LL(4)分析也能搞定，而真正体现出LL(*)特点的是下面这样的语法(对应llstar工程中<code>over_kleene.py</code>)：</p>

<pre><code>S ::= A $
A ::= a* b
    | a+ c
</code></pre>

<p>其中，规则<code>A</code>的2条分支拥有共同的kleene闭包前缀，LL(k)是无法识别的，它的ATN:<img src="/images/llstar/overkleeneatn.png" alt="Over Kleene ATN" /><br/>
而LL(*)能够为<code>A</code>生成这样的DFA：<img src="/images/llstar/overkleeneadfa.png" alt="Over Kleene Rule A DFA" /><br/>
这个DFA能够越过terminal<code>a</code>的任意重复，从而考虑到后面的terminal<code>b</code>和<code>c</code>来做判断<br/>
而下面这个更加"恶劣"的列子则更能说明LL(*)的这个特征(对应llstar工程中<code>over_non_recurse_rule.py</code>)：</p>

<pre><code>S ::= A $
A ::= B* b
    | C+ c
B ::= a d
    | e
C ::= a d
    | e
</code></pre>

<p>这个例子中，<code>B</code>和<code>C</code>完全相同，并分别被包含在规则<code>A</code>的2条分支的kleene闭包中，<br/>
最终生成的<code>A</code>的DFA: <img src="/images/llstar/nonrecursiveradfa.png" alt="Non-recursive Rule A DFA" /></p>

<p>上面提到过，LL(*)也有不能解决的情况，比如2条分支拥有"共同的、递归的规则作为前缀"，比如这样：</p>

<pre><code>S ::= A eof
A ::= E a
    | E b
E ::= c E d
    | e
</code></pre>

<p>上面的<code>A</code>规则的两条分支拥有共同的前缀<code>E</code>，而<code>E</code>本身是一条递归规则，这样的规则是LL(*)无法分析的，在llstar工程中对应<code>experiments/common_recurse_prefix_fail.py</code>, 运行的时候会抛出错误提示。这种情况在antlr3中会将parsing策略退化为LL(1) + 回溯的形式。</p>

<pre><code>Traceback (most recent call last):
  File "/home/pf-miles/myWorkspace/llstar/experiments/common_recurse_prefix_fail.py", line 31, in &lt;module&gt;
    d_a = create_dfa(ra.get_start_state(globals_holder.a_net))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 136, in create_dfa
    d_state_new.add_all_confs(closure(d_state, conf))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 99, in closure
    raise Exception("Likely non-LL regular, recursive alts: " + str(d_state.recursive_alts) + ", rule: " + str(globals_holder.a_net.get_rule_of_state(p)))
Exception: Likely non-LL regular, recursive alts: set([0, 1]), rule: E
</code></pre>

<p>还有一些特殊情况，比如规则完全就是冲突的，那么这个时候就是Semantic Predicate发挥作用的时候(对应llstar工程中<code>conflicting_with_preds.py</code>)：</p>

<pre><code>S ::= A $
A ::= {pred1}? B
    | {pred2}? b
B ::= b
    | b
</code></pre>

<p>最终<code>A</code>的DFA：<img src="/images/llstar/confresolvedwithpredsadfa.png" alt="Conflict Resolved With Preds A DFA" /><br/>
实际开发中，写出这样的规则是坑到爷的...不过LL(*)还算能很好解决...其实这里就算没有Semantic Predicate, LL(*)也能按照convention，“选择较早定义的语法分支”来解决。</p>

<p>还有就是在分析的过程中会导致分析栈溢出(不是程序语言的callstack的overflow, 而是LL(*)的closure操作维护的一个规则调用栈溢出)的时候，LL(*)也会使用Semantic Predicate来辅助判断, 比如规则(对应llstar中<code>overflow_with_preds.py</code>):</p>

<pre><code>S ::= A $
A ::= {pred1?} B a
    | {pred2?} b* c
    | {pred3?} b* c
B ::= b+ B
</code></pre>

<p>规则<code>A</code>的三条分支全部存在严重冲突(都拥有能识别无穷个'b'的前缀)并且其中一个是另一条递归规则<code>B</code>，这种形式会导致LL(*)的分析栈溢出，不过仍然没关系，这样的情况能在溢出发生时，调用<code>pred1</code>、<code>pred2</code>和<code>pred3</code>来解决(这三个pred就是Semantic Precicate，是能包含任何逻辑但最终返回bool值的表达式)<br/>
生成的规则<code>A</code>的DFA: <img src="/images/llstar/overflowadfa.png" alt="Overflow A DFA" /><br/>
这里设定的最大分析递归层数为<code>10</code>，因此，DFA在接受了第10个'b'之后达到了溢出状态<code>d14</code>，这时调用了各个alternative附带的几个predicate来解决冲突...</p>

<h3>总结</h3>

<p>OK, 大概如是了；上述算法的实现、例子的代码均在<a href="https://github.com/pfmiles/llstar">llstar</a>工程中能找到<br/>
llstar工程是我花了不少时间实现并调试好的一块LL(*)算法的“实验台”，可以在里面慢慢把玩各种变态的、五花八门的语法规则，以验证LL(*)的分析能力<br/>
在工程的<code>experiments</code>文件夹下已经有许多具有代表性的例子...都是python代码<br/>
另外，llstar工程是在eclipse + pydev环境下开发的，因此如果要在命令行里运行，可能要对例子里面的import路径稍作修改，当然，最好是直接在eclipse + pydev环境下运行它们了<br/>
在linux环境下，llstar的所有例子都能自动生成上文中看到的各种DFA/NFA图像，不过前提是环境中要装有<a href="http://www.graphviz.org/">graphviz</a></p>

<p>现在的所有语法解析器生成器中，似乎都是LR分析的天下，LL分析大多是手写解析器的首选...<br/>
不过在现有的使用LL分析方式的产品中，也就只有LL(*)和PEG(Packrat)parsing比较常见也比较实用了，能与LR分析一较高下。<br/>
而配上回溯策略的LL(*)是严格强于Packrat parsing的，这样看来大概走LL分析路子的自动化工具也只有LL(*)容易一枝独秀了(想必这也是antlr相对较为流行的原因)。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Kleene闭包语法糖消除语法中的左递归]]></title>
    <link href="http://pfmiles.github.com/blog/left-recursion-removal-using-kleene-closure"/>
    <updated>2012-03-28T11:18:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/left-recursion-removal-using-kleene-closure</id>
    <content type="html"><![CDATA[<p>一般来讲，如果使用的解析器生成器是基于LL分析法来解析文本的话(比如antlr)，我们就需要在编写语法规则的时候避免<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>。<br/>
虽然有一套成熟的、公式化的方法来去除左递归，但它会影响原有文法的结合顺序、优先级，或者多出一些本不需要的、额外的产生式。<br/>
例如，有左递归语法规则：</p>

<pre><code>addition ::= addition '+' factor
           | factor
</code></pre>

<p>这个式子其实是想要表达一个“一连串+号组成的和”的表达式，例如<code>1+2+3+4</code>；<br/>
假设目前的输入就是<code>1+2+3+4</code>, 那么超前查看带来的选择应该是<code>addition '+' factor</code>这个产生式；于是在parser的代码中立刻就又直接调用了<code>addition()</code>方法，但注意，整个递归过程没有消耗掉任何token...也就是说，当流程再次递归到<code>addition</code>函数里时，输入<code>1+2+3+4</code>并没有任何改变，这又会进入下一轮递归...很快就会overflow。<br/>
这个问题，除了机械性地按照公式来消除左递归外，还可以改写语法规则，使其成为右递归语法：</p>

<pre><code>addition ::= factor '+' addition
           | factor
</code></pre>

<p>这样就不用stackOverFlow了，但是带来另一个问题：这使得我们的'+'加法成为了一个'右结合'的运算...<br/>
也就是说，<code>1+2+3+4</code>的计算次序是这样的：<code>1+(2+(3+4))</code><br/>
还好这里是“加法”，整数集合和加法运算构成“阿贝尔群(可交换群)”，满足交换律，所以就算实现成右结合的也能蒙混过关...但减法呢？除法呢？</p>

<!-- more -->


<p>难道要先生成一个AST，再写个visitor，把节点顺序给rewrite一下，然后再写个visitor求值？这么麻烦就为了实现一个简单的四则运算功能也太坑爹了。</p>

<p>其实，我们在这里使用递归，只是为了表达元素的“重复”这种意思；的确，递归能表示“重复”的概念，但这很容易让人联想到“循环”，因为平时的编程中，我们都通常使用循环来表达“重复”这种东西的。<br/>
更重要的是，循环与<a href="http://en.wikipedia.org/wiki/Tail_call">尾递归</a>在逻辑上是等价的，这使得我们可以将上述左递归改写成某种表示“循环”的形式，在这里，<a href="http://en.wikipedia.org/wiki/Kleene_star">Kleene Closure(克林闭包)</a>就正是一种表达“循环”的标记形式。<br/>
熟悉正则表达式的我们都知道，符号<code>*</code>(kleene star)和符号<code>+</code>(kleene cross)分别用来表示前面临接元素的“0个或多个”和“一个或多个”，如果这种标记用在我们的语法规则中那就酷毙了：</p>

<pre><code>addition ::= (factor '+')* factor
</code></pre>

<p>表达的意义和"左递归版本"的语法规则是一样的，但是，这种记法的重大意义就是：在生成的parser程序中可以直接以一个<code>while</code>语句来解析重复的<code>(factor '+')</code>而不用再递归回<code>addition</code>中！这样就避免了parser中的左递归实现带来的问题！<br/>
由于kleene闭包所能表达的所有语法规则形式都能被递归所表达，所以引入kleene闭包并没有从形式上增加语法解析器生成器的表达能力，所以说kleene闭包只是一个“语法糖”。<br/>
但它的实现意义却是重大的：解决了“为了表达‘元素重复’”的这一类左递归问题。
当然，<a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a>也会支持kleene闭包的表达形式，大致的api形式如下：</p>

<pre><code>addition.fillGrammarRule(addend, CC.ks(ADD.or(SUB), addend));
</code></pre>

<p><code>CC.ks</code>方法就是kleene star的意思，当然还有<code>CC.kc</code>，顾名思义。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dropincc.java API design]]></title>
    <link href="http://pfmiles.github.com/blog/dropincc-dot-java-api-design"/>
    <updated>2012-03-18T16:29:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/dropincc-dot-java-api-design</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a>为了使得用户能够在java语言中直接定义新语言的词法、语法规则，API设计采用了串接与组合(cascading &amp; composition)风格的<a href="http://martinfowler.com/bliki/FluentInterface.html">FluentInterface</a>形式。</p>

<p>这种形式能够使得这一套API看起来更具有“业务语义”，而不需要像antlr等其它工具一样强迫用户去学习全新的另外一种含有业务语义的DSL。<br/>
新语言的词法、语法规则被用户直接在java语句里书写、执行，其实得到的是dropincc.java这个CC工具的内部概念的AST。这个AST其实与“让用户学习一套DSL，然后编写，然后编译这些DSL得到的AST”是一样的。<br/>
也就是说 —— dropincc.java里面很重要的一个理念就是：像书写字面量一样书写CC工具的AST(AST literal???)。</p>

<blockquote><p>注意：强调一下这里说的AST并非用户想要实现的新语言的AST，我指的是dropincc.java这个工具其内部表达词法、语法规则的内部形式。</p></blockquote>

<p>经过一些初步的尝试，我认为在java中定义出这样一套API是完全可行的，其中一些值得列出的、具有代表性的点如下：</p>

<!-- more -->


<ol>
<li>词法规则强制用户限定在正则文法的表达能力之内(即使用正则表达式，例子略)</li>
<li>上下文无关文法的表示主要是解决3种形式的表示：连接、选择、递归;

<ol>
<li>其中“连接”的表示, 若BNF为：<code>term ::= LEFTPAREN expr RIGHTPAREN</code>, 则右边的部分在java中表达为：<code>func(LEFTPAREN, expr, RIGHTPAREN)</code>;即：“以方法传参的自然按顺序排列表达‘连接’的意思”;而其中<code>expr</code>是一个non-terminal，也就是说这里要引用<code>expr</code>这个规则，这也就表达了“递归” —— 要递归地引用<code>expr</code>的话那么直接写在这里就好了；</li>
<li>“选择”的表示，即一个产生式有好几个alternative的情况，若BNF是<code>term ::= DIGIT multail | LEFTPAREN expr RIGHTPAREN | DIGIT;</code>, 则java中表达为：<code>func(DIGIT, mulTail).alt(LEFTPAREN, expr, RIGHTPAREN).alt(DIGIT);</code>。</li>
</ol>
</li>
<li>上述3种基本元素的表达具备之后，其实已经足够表达出复杂的语法了，不过为了“更好的体验”，为了用得更方便，我认为还应该加入“子rule语法糖”。即让使用者能够以“加括号”的方式在产生式中直接定义子规则，而不必每次都单独写成一个产生式，这种做法应该能很受欢迎，比如：

<ul>
<li>第一个产生式是：<code>MUL_DIV ::= MUL | DIV;</code></li>
<li>第二个产生式是：<code>mulTail ::= MUL_DIV term;</code></li>
<li>其实，若是有了前面说的语法糖，那么上述2个产生式就可以合并为：<code>mulTail ::= (MUL | DIV) term;</code>, 少了<code>MUL_DIV</code>这个没太多意义的产生式定义；</li>
<li>在java中表达为：<code>func(MUL.or(DIV), term)</code>; 若子规则中想表达的不是“选择”关系，而是“连接”关系的话，也就是<code>mulTail ::= (MUL DIV) term;</code>的话，在java中表达为：<code>func(MUL.and(DIV), term)</code>; 其中<code>and</code>这个方法就是表达“连接”关系，只不过加了括号，成为了一个子规则而已。</li>
</ul>
</li>
</ol>


<p>OK, dropincc.java的核心FluentInterface形式的API应该就这些了，我相信这是一种很自然的方式，用户需要掌握的东西很少。</p>

<h3>设计FluentInterface风格API过程中的经验总结</h3>

<p>对于这个接口设计，我的经验就是：</p>

<ol>
<li>传入参数尽量“泛化”、“统一接口化”;这个“统一接口”最好不要包含任何方法(也就是说只是一个标记接口)，否则会给FluentInterface带来一些令人困惑的方法选项(当用户敲入'.'操作符的时候将会在IDE工具的方法提示里多出很多不必要的方法)。</li>
<li>每个串接方法的返回结果可以随意“具体化”，因为这个返回结果的具体类名是不必展示给用户看的，所以你打算让用户下一步还能串接出什么样的方法，就尽管去返回一个具体的子类；但要注意返回结果不应该有太深的继承层次，否则“下一步串接”(当用户敲入'.'操作符的时候)将会在IDE工具里列出令人困惑的方法列表 —— 一般就一层继承关系 —— 继承自Object —— 一个接口实现 —— 就是1中所述的“泛化接口”，这样做方便你将返回值继续传入另一个方法中 —— 实现为所欲为的cascading &amp; composition...</li>
</ol>


<h3>以闭包的形式嵌入动作代码</h3>

<p>几乎所有的CC工具都提供一种“在match到特定的节点或树模式时允许执行一段用户自定义代码”的功能；这种自定义代码我把它叫做“动作代码”, “action”。无论是lex &amp; yacc或是antlr都是这样。<br/>
这个功能几乎是必须的，这提供了一种自由度相当高的形式让用户可以自定义AST节点，或是直接在parse的过程当中做一些自定义的计算，然后当整个parse结束时直接输出的就是整个的计算结果。<br/>
动作代码一般来讲，都是用该CC工具所要生成的程序所使用的语言来写的；比如lex要生成C代码，他们的动作代码就是C来写的；antlr要生成java代码，那么它的动作代码自然就是java写的（当然antlr也能生成其它语言代码，相对应的，就使用那种语言来编写动作代码）。
dropincc.java既然设计目标是要嵌入到java语言中去使用，自然就是要用java语言来写动作代码了；<br/>
但是，跟lex &amp; yacc或者antlr不同的是，我并不打算让用户写一些残缺不全的动作代码放在某个约定的位置然后在生成目标程序的过程中将它们“编织”到目标程序中，这样的话就跟传统的CC工具没有任何区别了，没有什么实质上的改进；<br/>
既然dropincc.java是“嵌入”到普通的java应用程序代码中间工作的，那么它完全有理由使用“闭包(closure)”的形式来组织“动作代码”！为什么用“闭包”？因为dropincc.java是“嵌入”到业务代码中使用的，用闭包来写动作代码可以capture一些业务代码上下文信息，这对构建DSL来讲是非常大的便利！<br/>
比如，你的业务代码上下文里面有个<code>OrderService</code>对象，它负责一些"订单"业务逻辑，而当你编写一个闭包作为动作代码的时候，你完全可以"capture"上下文中的这个<code>OrderService</code>对象，从而使得你创造的语言在执行逻辑上与订单业务紧密、无缝地结合 —— 这是一种非常平滑的构建DSL的方式。</p>

<h3>最终的样子</h3>

<blockquote><p>注：此段代码只代表示意的风格、API情况，虽然能编译通过、运行，但不一定是行为完全正确四则运算表达式计算器</p></blockquote>

<pre><code>// 3.define lexical rules
Lang calculator = new Lang();
Token DIGIT = calculator.addToken("\\d+");
Token ADD = calculator.addToken("\\+");
Token SUB = calculator.addToken("\\-");
Token MUL = calculator.addToken("\\*");
Token DIV = calculator.addToken("/");
Token LEFTPAREN = calculator.addToken("\\(");
Token RIGHTPAREN = calculator.addToken("\\)");
// 2.define grammar rules and corresponding actions
Grule expr = new Grule();
Grule term = new Grule();
Element mulTail = calculator.addGrammarRule(MUL.or(DIV), term).action(
        new Action() {
            public Object act(Object... params) {
                return params;
            }
        });
term.fillGrammarRule(DIGIT, mulTail).action(new Action() {
    public Object act(Object... params) {
        int factor = Integer.parseInt((String) params[0]);
        Object[] mulTailReturn = (Object[]) params[1];
        String op = (String) mulTailReturn[0];
        int factor2 = (Integer) mulTailReturn[1];
        if ("*".equals(op)) {
            return factor * factor2;
        } else if ("/".equals(op)) {
            return factor / factor2;
        } else {
            throw new RuntimeException("Unsupported operator: " + op);
        }
    }
}).alt(LEFTPAREN, expr, RIGHTPAREN).action(new Action() {
    public Object act(Object... params) {
        return params[1];
    }
}).alt(DIGIT).action(new Action() {
    public Object act(Object... params) {
        return Integer.parseInt((String) params[0]);
    }
});
Element addendTail = calculator.addGrammarRule(ADD.or(SUB), term)
        .action(new Action() {
            public Object act(Object... params) {
                return params;
            }
        });
expr.fillGrammarRule(term, addendTail, CC.EOF).action(new Action() {
    public Object act(Object... params) {
        int addend = (Integer) params[0];
        Object[] addendTailReturn = (Object[]) params[1];
        String op = (String) addendTailReturn[0];
        int addend2 = (Integer) addendTailReturn[1];
        if ("+".equals(op)) {
            return addend + addend2;
        } else if ("-".equals(op)) {
            return addend - addend2;
        } else {
            throw new RuntimeException("Unsupported operator: " + op);
        }
    }
});
// 1.compile it!
calculator.compile();
// 0.FIRE!!!
System.out.println(calculator.exe("1+2+3+(4+5*6*7*(64/8/2/(2/1)/1)*8+9)+10"));
</code></pre>

<p>上面约60行java代码实现了一个相当复杂的多项式计算器语言：支持加减乘除四则运算以及括号调整优先级。而以往我们使用antlr来实现这个功能的话，最终生成、放到项目中工作的java代码会以千行计。</p>

<ul>
<li>这段代码是能够完全嵌入到任何普通的java业务系统程序代码当中的，是完全语法合格、能编译通过的，这是与传统CC工具的“代码残片”表示的动作代码所不同的地方</li>
<li>其中用到了上面介绍的“以正则语言来定义词法规则”、“以FluentInterfaces来定义语法规则”，以及“以闭包的形式来书写动作代码”（java中的闭包以“匿名内部类”的形式表示，道理一样）</li>
<li>其中，动作代码是一段段由<code>Action</code>接口实现的闭包（匿名内部类），里面的代码显然可以随意引用当前上下文中的所有变量、对象，这样实现了对上下文的capture，跟业务系统的无缝结合。</li>
<li><code>Action</code>闭包带有一个方法，参数是<code>Object... params</code>，这个参数里的值以位置顺序的方式对应于该action代码所附着的产生式里面的语法元素在parsing的时候所match到的值，听起来比较绕口，但实际上很简单，比如上面的 :</li>
</ul>


<p>带括号的表达式的action:</p>

<pre><code>.alt(LEFTPAREN, expr, RIGHTPAREN).action(new Action() {
    public Object act(Object... params) {
        return params[1];
    }
</code></pre>

<p>它的<code>params</code>的长度为3，分别是<code>["(", expr子规则匹配所返回的值, ")"]</code>，而这里我们的“业务(四则运算)”只需要关心<code>expr</code>的返回值，所以动作代码直接将<code>params[1]</code>（expr的返回值）返回给上一级匹配。<br/>
就是这样，实际上你可以在动作代码里面做任何事情，只要符合java语法的、你能想到的。</p>

<p>第一个版本的API设计基本就是这样了，往后可能还会加入一些语法糖，比如“Kleen闭包”来进一步方便语法规则的定义，不过会很慎重，因为dropincc.java是以小巧、易用为设计目标的，语法糖太多很可能会帮倒忙。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dropincc.java的概念与设计]]></title>
    <link href="http://pfmiles.github.com/blog/the-main-ideas-and-concepts-of-dropincc-dot-java"/>
    <updated>2012-03-17T17:40:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/the-main-ideas-and-concepts-of-dropincc-dot-java</id>
    <content type="html"><![CDATA[<h3>做这么个小lib的动机？</h3>

<p>其实由于java语言先天缺陷的元编程能力，在java的圈子里很少有人提到“DSL”的概念，就算有也是说说而已。与之相比，一些其它语言ruby, python, lisp等等，得益于其强大的元编程能力，直接利用自身语法特性，取一块语法子集，利用一些对象、类生命周期切入函数或者宏系统两三下就DSL 'on-the-fly'了，这种便利性可能由java的设计目标来看，恐怕永远也无法达到了。<br/>
那么，在java里面想实现一个DSL，恐怕就得走“外部DSL(详见Fowler的文章: <a href="http://martinfowler.com/bliki/DomainSpecificLanguage.html">DomainSpecificLanguage</a>)”的路子。<br/>
而“外部DSL”这条路并不好走，说白了也就是自己做词法、语法、语义分析，自己生成目标语言代码去执行真正的逻辑；也就是做一个编译器前端外加一段解释执行逻辑；编译器前端，虽然业界看上去有很多很多工具可以直接采用，但是这些工具，目前看来，我认为还是太“General purpose”了，它们往往要求使用者学习它们自己规定的一套用作表达词法、语法规则的DSL，然后提供一个特殊的编译程序，用作编译你用它的DSL写的这些词法、语法文件，最终生成你想要的、基本不可读的编译器前端代码 —— 放到你的项目中去使用；<br/>
这种形式的工具在目前的编译器前端生成器中占大多数，使用上绝对称不上是“便利”。除了它用作描述规则的DSL需要使用者学习之外，其使用过程涉及好几个步骤与环境，是很麻烦的一件事情。<br/>
曾经有一次，一个同学试图使用antlr来做一个类似SQL子集的DSL，他花很多时间与antlr本身的语法文件、IDE “antlrworks”作斗争...频繁地在eclipse, 命令行, antlrWorks之间切换；我就想，做一个这样的DSL，是否真的用得上这么多工具？是否真的用得上号称能parse C++的antlr？这些事情能否全部在一个工作环境内搞定？比如eclipse？
而来自<a href="https://github.com/luikore/rsec">rsec</a>的启发让我觉得java似乎更应该有这样一个东西：</p>

<ol>
<li>以java的语法来新增词法、语法规则，不需要学习新的语法；</li>
<li>不需要依赖外部环境，仅在java开发环境中就能完成新语言的定义与编译器前端程序的生成；</li>
<li>虽然java是静态类型编译型语言，但整个新语言构建过程应该看上去是“动态的”、“解释性”的，这样“体验”才会好；</li>
<li>这个库要小、要没有其它三方库依赖，仅依靠JDK自带库就能使用；</li>
<li>在使用过程中尝试推行一些好的实践，确保大多数普通青年不会“自找麻烦”，比如“限制词法规则必须为正规文法(或者说乔姆斯基3型文法)”。</li>
</ol>


<p>而<a href="https://github.com/pfmiles/dropincc.java">Dropincc.java</a>正是以上述几点为设计目标的一个小巧(但足够强大)的编译器生成器。</p>

<!-- more -->


<h3>设计与实现思路</h3>

<p>以上第一点，基本上的想法就是，设计一套“串接与组合(cascading &amp; composition)”风格的API，模拟出一套parser combinator，让用户使用这套“貌似带有CC的语义”的java方法API来做词法、语法规则的添加(CC即："compiler-compiler, 就是'编译器生成器'")。<br/>
比如我想创建一套支持加减乘除的表达式计算器，还能使用括号调整运算优先级，我大概能用下面这样的形式直接在java代码中定义其词法、语法规则：</p>

<blockquote><p>注：下面的代码只是示意说明整体API风格，不一定是最终能运行的代码。</p></blockquote>

<pre><code>Lang lang = new Lang();
Token DIGIT = lang.addToken("\\d+");
Token ADD = lang.addToken("\\+");
Token SUB = lang.addToken("\\-");
Token MUL = lang.addToken("\\*");
Token DIV = lang.addToken("/");
Token LEFTPAREN = lang.addToken("\\(");
Token RIGHTPAREN = lang.addToken("\\)");

Grule expr = new Grule(); // grammar root
Grule term = new Grule();

Element mulTail = lang.addGrammarRule(MUL.or(DIV), term);
term.addGrammarRule(DIGIT, mulTail)
        .alt(LEFTPAREN, expr, RIGHTPAREN)
        .alt(DIGIT);
Element addendTail = lang.addGrammarRule(ADD.or(SUB), term);
expr.addGrammarRule(term , addendTail, CC.EOF);
</code></pre>

<p>其实想要表达的规则写成类似"BNF"的形式就是：</p>

<pre><code>// token rules
DIGIT ::= '\d+';
ADD ::= '+';
SUB ::= '-';
MUL ::= '*';
DIV ::= '/';
LEFTPAREN ::= '(';
RIGHTPAREN ::= ')';

// grammar rules
mulTail ::= (MUL | DIV) term;
term ::= DIGIT multail
       | LEFTPAREN expr RIGHTPAREN
       | DIGIT
       ;
addendTail ::= (ADD | SUB) term;
expr ::= term addendTail EOF;
</code></pre>

<p>这简直就是“line to line”的直译，而<a href="https://github.com/pfmiles/dropincc.java">Dropincc.java</a>的目标也就是要达到这样的效果；<br/>
这么做的目的并不是实现一套标准意义上的BNF；它使用了正则表达式来描述词法规则(token)，也就是上面提到的“目标”的第5点：“限制词法规则必须为正规文法”，这么做的意思也就是建议用户在“若词法规则中出现正规文法无法解决的意义冲突时”，将冲突“推后”到后面的语法、甚至语义分析阶段去解决；这种推荐的“较好实践”能够保持词法规则足够简单，使用正则表达式就能清晰地描述；如果用户不理解“保持词法规则足够简单”的重要性，只需要让他思考一下“为什么java的标识符不能由数字开头”应该就能想通了。<br/>
事实上就是：如果你不想自找麻烦，那么就应该保持词法规则足够简单 —— 你不应该在词法解析阶段耗费太多的实现精力 —— 这里用正则表达式就好了 —— 后面还有更麻烦、更有意义的活儿等着你去干呢...你不应该卡在词法分析这里太久...<br/>
好了，上面的这种约束一方面推行了一种“较好的实践”，另一方面也使得我们的这个工具更加直观、好用、简单，并且并不降低其实现语言的能力。</p>

<p>第二、三点，打算使用JDK1.6的新compiler API来实现；目前业界中的大多数CC工具都是“生成一个源文件”，让用户直接在项目中使用这个源文件；其实我认为这个东西以“源文件”的形式出现在项目中意义并不大，因为它几乎不可读(不可读的源代码有什么意义呢？)。只要有一个可执行的内存表示即可，“源文件”其实就不必了...这样也似乎使得项目代码看上去更“干净”。</p>

<p>至于第四点，也是很重要的，实现过程中一直保持“不依赖JDK以外的库”即可。</p>

<p>当所有的规则都定义完毕，只要在代码中触发"compile"，立刻就能基于定义的规则在内存中生成一个可执行的编译器前端，没有“源代码”，因为那没有意义，用户需要做的就只是拿它去执行新出生的语言的代码逻辑：</p>

<pre><code>lang.compile();
lang.exe("1+2+3*4/(5*6*7+8)");
</code></pre>

<p>当然，还有“action代码”的具体组织形式示例，上面没有给出，在<a href="dropincc-dot-java-api-design/">dropincc.java API Design</a>里面有详尽的阐述。<br/>
基本上对于这个工具的最终输出形式，计划中应该有两种：</p>

<ol>
<li>AST</li>
<li>直接执行的action</li>
</ol>


<p>输出AST其实是灵活度最大的一种形式，有了AST，那么后面是想解释执行？还是做翻译？那就交由用户去考虑了，dropincc.java的工作到这里也就结束了；<br/>
而“直接执行action”的方式适合像上面这种简单的诸如“四则运算”这样的简单表达式语言，在创建解析树的过程中就把对应的动作代码给执行了，解析结束后直接就能得到结果。</p>

<p>根据dropincc.java的后续设想，上述2种方式在dropincc.java中实现应该“几乎没有差别”，这两种输出形式虽然目的可能不一样，但在dropincc.java中实现起来应该是高度统一、一致的，这也是为了实现“足够简单”的目标，尽量不要让用户过多地去学习一些概念，增加上手成本。</p>

<p>至于dropincc.java能够用来识别哪种级别的语法？我的设想中dropincc.java是一个LL解析器生成器，最终要能识别LL(*)的语法，也就是跟antlr具有同等能力；不过初期的实现可能还识别不了那种程度的不确定性，这个可以一步一步随着版本推进慢慢来改进。其它一些诸如解决左递归的一些算法改进都可以排在计划中...</p>

<p>OK，前期的设想也就暂时介绍到这里，希望dropincc.java的努力能够将java圈子里的DSL应用甚至<a href="http://en.wikipedia.org/wiki/Language-oriented_programming">LOP</a>编程往前推进一步，这是相当令人振奋的事情。</p>
]]></content>
  </entry>
  
</feed>
