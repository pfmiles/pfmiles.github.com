<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: dropincc | Meta-Interpretation]]></title>
  <link href="http://pfmiles.github.io/blog/category/dropincc/atom.xml" rel="self"/>
  <link href="http://pfmiles.github.io/"/>
  <updated>2014-04-16T22:17:00+08:00</updated>
  <id>http://pfmiles.github.io/</id>
  <author>
    <name><![CDATA[pf_miles]]></name>
    <email><![CDATA[miles.wy.1@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[用于代码生成的模板引擎应该是什么样子？]]></title>
    <link href="http://pfmiles.github.io/blog/what-does-a-template-engine-for-code-generation-look-like"/>
    <updated>2012-09-13T15:27:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/what-does-a-template-engine-for-code-generation-look-like</id>
    <content type="html"><![CDATA[<p>以前在做一个涉及代码生成的项目的时候，使用了velocity模板引擎来做这个代码生成；<br/>
而事后发现，velocity有大部分的语法是我在代码生成过程中没有用到的；<br/>
且velocity的引入，也导致引入了一些看起来很多余的jar包；<br/>
后来我看了看<code>StringTemplate</code>这个东西，发现它不仅包含velocity几乎全部的语法，还有模板继承机制！这岂不是更复杂？虽然标榜为“为了代码生成”的模板引擎...但鉴于<code>velocity</code>的复杂印象，我并没有使用它.  <br/>
再后来，我为了包管理上的简洁(对于某些项目我承认我有洁癖)，我直接使用了java标准库里的<code>java.text.MessageFormat</code>来做代码生成；这也确实可行！不过，缺点也是很快就能遇到的：</p>

<ol>
<li>大括号<code>{</code>和<code>}</code>在<code>MessageFormat</code>中是关键字！所以输出时必须转义；这两个东西在目标代码中(比如java)很常见，遇到一个就要转义一个是很不爽的事情;</li>
<li>除了字符串替换之外，没有任何分支逻辑判断、循环结构支持，这使得所有的分支逻辑和循环结构都要写在调用这些<code>MessageFormat</code>的java代码里；虽然很多时候确实可以这么做并且很合适，但是还是有一些情况，如果能写在模板里会明显比写在java代码里好;</li>
<li><code>MessageFormat</code>的placeholder是数字，渲染时是根据传入参数的位置来做值替换，这很不直观，更好的用户体验应该是依据名字来替换，就像所有的、普遍意义上人们所见过的模板引擎那样;</li>
</ol>


<p>总结性地思考一下：我在做代码生成的时候，需要的模板引擎大概应该是：</p>

<ul>
<li>简单，这意味着只需要拥有简单的语法以及简单的jar包依赖(或者不需要jar包依赖)</li>
<li>高效，最好直接编译成字节码执行，而非像velocity那样每次渲染都遍历AST</li>
</ul>


<p>而重点就在于第一点：简单，这需要我好好总结一份“用作代码生成的模板引擎所必须的语法特性”列表, 并且除此以外，不能有更多其它的东西;<br/>
至于高效，只要确保最终被反复执行的逻辑是一个编译好的java类就行了，而非遍历AST，这很容易办到;<br/>
而且..正好之前开发的<a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a>需要为用户提供一个模板引擎，因为语法解析与代码生成在很多任务中是一对好基友，常常是伴随着出现；那么在dropincc.java中内建一个针对代码生成的模板引擎也就是非常有必要的了；它之于dropincc.java，就好比StringTemplate之于antlr，都是为了方便用户做代码生成创造的;<br/>
并且，这个模板引擎应该随着dropincc.java一起发布，不需要引入新的jar包依赖;<br/>
计划中，这个模板引擎的基本特性：</p>

<!-- more -->


<ol>
<li>编译为java字节码，常驻内存</li>
<li>语法简单，只支持<code>if-else</code>语句和<code>foreach</code>语句, <code>foreach</code>语句支持数组和<code>Collection</code>的遍历, 也支持对"range常量"的遍历</li>
<li>兼容velocity语法的一个子集, 但语义不一样(即只实现其<code>if-else</code>和<code>foreach</code>语法，一方面这是为了利用已有的、强大的velocity语法高亮插件)</li>
<li>任何元素的输出结果总是与<code>String.valueOf(obj)</code>的结果一致</li>
<li>逻辑判断只支持<code>==</code>、<code>!</code>, 支持<code>&amp;&amp;</code>或<code>||</code>和括号优先级，因为我认为，用于代码生成的模板引擎的语法应该全是“开关”形式的，即“已经是判断的结果了”，非<code>true</code>即<code>false</code>(顶多再加上<code>==</code>比较)，不应该有过多的动态的复杂逻辑判断，这些判断其实应该放到调用这个模板引擎的java代码里, 而在模板里，只应该存在对这些bool值的与、或、非的各种组合判断</li>
<li><code>==</code>操作符的判断结果与java中<code>==</code> + <code>equals</code>函数的判断逻辑一致</li>
<li>模板context支持map和javabean两种形式, 可使用<code>.</code>操作读取bean或map中的属性值，但不支持方法调用</li>
<li>没有赋值语句，context中的所有东西，要么是要输出的元素，要么是作为输出控制的bool开关，它们在渲染过程中是不可变的</li>
<li>模板引擎接口简单、清晰，只有4个static方法：

<ul>
<li><code>public static String merge(String filePath, Object context, Class&lt;?&gt; cls)</code></li>
<li><code>public static byte[] mergeAsBytes(String filePath, Object context, Class&lt;?&gt; cls)</code></li>
<li><code>public static String merge(String filePath, Object context, Class&lt;?&gt; cls, String encoding)</code></li>
<li><code>public static byte[] mergeAsBytes(String filePath, Object context, Class&lt;?&gt; cls, String encoding)</code></li>
<li>其中，<code>filePath</code>是模板路径; <code>context</code>可是javabean或map，为模板上下文，包含要输出的元素和控制条件; <code>cls</code>是用于加载模板资源的class类，模板资源查找规律与<code>Class.getResourceAsStream</code>方法一致; <code>encoding</code>是指定模板所使用的编码格式; 返回<code>String</code>的方法即返回渲染后的字符串结果；返回<code>byte[]</code>的接口则是直接返回带编码格式的、<code>byte</code>的数组，这个结果可直接用作写入外部存储或流，而无需再应用编码格式;</li>
</ul>
</li>
</ol>


<p>而基本上就是这些，不需要太多东西，可能第一眼会觉得“功能是不是太少”？但是，我已经见过了许多过重的逻辑被放在模板语法里的情况，与其增加这种不必要的、很可能是错误的使用方式(因为这样做确实不好维护)，还不如一开始就不提供了；<br/>
并且，代码生成所需要的模板引擎，相比起做web页面所需要的模板引擎来讲，一定要简单许多；因为大部分的逻辑是应该放在java代码中(比如负责翻译代码的visitor)而不是模板里。</p>

<p>ok, 下面需要给出这个模板引擎的<a href="http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form">EBNF</a>,这是最重要的准绳，几乎框定了绝大部分东西：</p>

<pre><code>template ::= content $
content ::= renderable*
renderable ::= PLAIN_TEXT
          | '#if' '(' boolExpr ')' renderable ('#elseif' '(' boolExpr ')' renderable)* ('#else' renderable)? '#end'
          | '#foreach' '(' REF 'in' (REF|RANGE) ')' renderable '#end'
          | REF
boolExpr ::= andExpr ('||' andExpr)*
andExpr ::= term ('&amp;&amp;' term)*
term ::= '!'* REF
       | value '==' value
       | '!'* '(' boolExpr ')'
value ::= '-'?[0-9]+('.'[0-9]+)?
        | '\'' .* '\''
</code></pre>

<p>语法就是这样，应该已经足够;上述规则中，全大写字母的元素是terminal，一部分terminal的定义未在上面给出，补充在下面：</p>

<pre><code>REF ::= '${' ID('.'ID)* '}'
ID ::= [a-zA-Z_][a-zA-Z0-9_]*
RANGE ::= '[' [0-9]+ '..' [0-9]+ ']'
</code></pre>

<p>总结起来讲，这个模板语法支持<code>if</code>和<code>foreach</code>语句，以及引用值的输出，其余的元素一律被看作<code>PLAIN_TEXT</code>直接输出;<br/>
在<code>if</code>语句中，逻辑表达式支持<code>==</code>比较，以及“非”逻辑<code>!</code>;支持添加圆括号调整运算优先级;<br/>
<code>foreach</code>语句中，可以支持对引用(必须是<code>Collection</code>或<code>Array</code>)或<code>RANGE</code>表达式的遍历; <code>RANGE</code>表达式即生成一个数字序列的表达式，步长为1，如<code>[1..10]</code>表示一个由1到10的数字序列;</p>

<p>至于具体的实现方式，仍然采用与dropincc.java一致的jdk1.6 compiler API的动态编译的形式，编译为字节码运行。<br/>
这个模板引擎将作为dropincc.java内部自己做一些代码生成，也同时提供给用户做代码生成工作，这样既能避免过多jar包的引入，又能施行一些最佳实践("最佳"的意思是我这里定义的，在我看来是在“什么逻辑放在模板中”和“什么逻辑放在java代码中”找到一个平衡点，当然不同人可以有不同理解)。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Growing a Full-Featured Calculator in 15 Minutes Using Dropincc.java]]></title>
    <link href="http://pfmiles.github.io/blog/growing-a-full-featured-calculator-in-15-minutes-using-dropincc-dot-java"/>
    <updated>2012-08-12T15:58:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/growing-a-full-featured-calculator-in-15-minutes-using-dropincc-dot-java</id>
    <content type="html"><![CDATA[<p>First, let's create a empty java project in eclipse IDE, download newest playable dropincc.java jar file from <a href="https://github.com/pfmiles/dropincc.java/releases">here</a>. Adding it to the build path of the project, like this(note: jdk1.6 or above required):<br/>
<img src="/images/dropincc/calc/emptyProjWithJar.png" alt="emptyProjWithJar" /><br/>
And then, create a new java source file to build our grammar, for example, <code>Calculator.java</code>.<br/>
We start by specifying the EBNF form of our expected calculator language. The calculator expression would do addition and subtraction operations and also multiplication and division operations which have a greater priority.<br/>
Also, we expect the calculator could handle parentheses to do priority adjustment.<br/>
We could write the EBNF grammar rules in a top-down pattern:</p>

<pre><code>calc ::= expr $
expr ::= addend (('+'|'-') addend)*
</code></pre>

<p>We specified that the overall <code>expression</code> consists one or more <code>addend</code> sub-expressions with <code>'+'</code> or <code>'-'</code> symbol delimited.<br/>
And for every single <code>addend</code> expression:</p>

<pre><code>addend ::= factor (('\*'|'/') factor)*
</code></pre>

<p>consists one or more <code>factor</code> separated by <code>'*'</code> or <code>'/'</code>.<br/>
And finally, for any single <code>factor</code>, is either a single digit or a quoted expression:</p>

<pre><code>factor ::= '\d+(\.\d+)?'
         | '(' expr ')'
</code></pre>

<p>Ok, we've done defining the EBNF of our calculator. This is what it look like all over:</p>

<pre><code>calc ::= expr $
expr ::= addend (('+'|'-') addend)*
addend ::= factor (('\*'|'/') factor)*
factor ::= '\d+(\.\d+)?'
         | '(' expr ')'
</code></pre>

<!-- more -->


<p>It's quite short because it utilized the kleene notation to represent 'zero or more'. And a shorter EBNF ends up a shorter dropincc.java program!<br/>
Now let's 'translate' the EBNF into dropincc.java program. I say 'translate' here because it's a really straightforward step:</p>

<pre><code>// some elements' pre-definitions in order to call the methods
Lang calc = new Lang("Calc");
TokenDef a = calc.newToken("\\+");
TokenDef m = calc.newToken("\\*");
Grule expr = calc.newGrule();
Grule addend = calc.newGrule();
Grule factor = calc.newGrule();

// grammar definition section start
calc.defineGrule(expr, CC.EOF);
expr.define(addend, CC.ks(a.or("\\-"), addend));
addend.define(factor, CC.ks(m.or("/"), factor));
factor.define("\\d+(\\.\\d+)?")
.alt("\\(", expr, "\\)");
// grammar definition end
</code></pre>

<p>The 'grammar definition' part is as many lines as the EBNF. In fact it's a line-by-line translation of the EBNF(please look at the 'grammar definition' section carefully).</p>

<p>Just a little more explanation:</p>

<ul>
<li>The basic elements of grammar rule is <code>TokenDef</code>s and <code>Grule</code>s.(In fact <code>Grule</code> means 'grammar rule') <code>TokenDef</code>s are defined using java built-in regular expression currently.</li>
<li>Rule production's match sequence is represented as comma separated elements list. Like <code>expr, CC.EOF</code> means <code>expr $</code>, <code>addend, CC.ks(a.or("\\-"), addend)</code> means <code>addend (('+'|'-') addend)*</code>.</li>
<li>Note the <code>CC.EOF</code> constant, it's a predefined constant provided by dropincc.java to represent <code>EOF</code> token definition.</li>
<li>And the <code>CC.ks</code> method call means all elements passed in as parameters are enclosed in a kleene star node(kleene star node means zero or more multiplication of its enclosing elements, the same as you learnt from using a regular expression). And <code>ks</code> in fact means 'kleene star'.</li>
<li>Likewise, there are <code>CC.kc</code> method and <code>CC.op</code> method which means <code>kleene cross</code>(one or more) and <code>optional</code>(zero or one) respectively but not used in the above example, you can browse them from source code.</li>
<li>Rule alternative productions are represented by an <code>alt</code> method call. Look at the <code>factor</code> rule definition, the <code>factor</code> rule has two productions. And, respectively, in java code, it has an additional <code>alt</code> call besides <code>define</code>.</li>
</ul>


<p>'Comma separated match sequence', 'CC.EOF', 'CC.ks/kc/op' and 'alt', those are almost all you need to know to define a non-trivial DSL grammar in dropincc.java.</p>

<p>Ok, after we have defined the grammar, it's time to add <code>Action</code>s to process the elements the parser matched while parsing. It's also achieved by a very intuitive way:</p>

<ul>
<li>One <code>alternative production</code>(note: not one rule) could have only one action. That's, the <code>calc</code> rule could have only one action because it has only one alternative production. While <code>factor</code> rule could have two actions because it has two alternative productions.</li>
<li>Let's add actions for the <code>factor</code> rule first:</li>
</ul>


<p>For the first alternative production:</p>

<pre><code>factor.define("\\d+(\\.\\d+)?").action(new Action&lt;String&gt;(){
    public Double act(String matched) {
        return Double.parseDouble(matched);
    }})
</code></pre>

<p>The first alt of <code>factor</code> rule only matches a single string which have a 'digit' format. So the <code>act</code> method of the <code>Action</code> interface should be a single <code>String</code> object holding the matched digit string. And, also, the generic type argument of <code>Action</code> interface should be <code>String</code>, to provide a strong type safety for the actually matched element.<br/>
We just parse the matched digit string to a number and returned it. So the return type of this action is <code>Double</code>.</p>

<p>And the <code>Action</code> for the second alt:</p>

<pre><code>.alt("\\(", expr, "\\)").action(new Action&lt;Object[]&gt;(){
    public Double act(Object[] ms) {
        return (Double) ms[1];
    }
});
</code></pre>

<p>The second alt is an expression enclosed by parentheses. There are three element in the match sequence: <code>(</code>, enclosing <code>expr</code>, and <code>)</code>.<br/>
The type argument of <code>Action</code> interface should be <code>Object[]</code> since the matched element will be passed in as an object array of length 3. With first element <code>(</code>, second element the returned value of the enclosing <code>expr</code> rule's action, and third element <code>)</code>.<br/>
All we care about is the second element: the returned value of the enclosing <code>expr</code>'s action. So we just return <code>ms[1]</code> here, ignoring <code>(</code> and <code>)</code>. Note that we confidently converted the <code>ms[1]</code> to a <code>Double</code> object, that's because we knew the return value of <code>expr</code> rule's action is definitely a <code>Double</code> value.</p>

<ul>
<li>Then, let's add action for the <code>addend</code> rule:</li>
</ul>


<p>It has only one production, so it could have only one corresponding action:</p>

<pre><code>addend.define(factor, CC.ks(m.or("/"), factor)).action(new Action&lt;Object[]&gt;() {
    public Double act(Object[] ms) {
        Double f0 = (Double) ms[0];
        Object[] others = (Object[]) ms[1];
        for (Object other : others) {
            Object[] opAndFactor = (Object[]) other;
            if ("*".equals(opAndFactor[0])) {
                f0 *= (Double) opAndFactor[1];
            } else {
                f0 /= (Double) opAndFactor[1];
            }
        }
        return f0;
    }
});
</code></pre>

<p>The argument of <code>act</code> method is an object array of length 2. Its first element is the returned value from the matched <code>factor</code> rule's action,<br/>
and the second are other operator &amp; factor pairs.<br/>
If there's only one factor matched here, the 'operator &amp; factor' pairs would be an array of length 0, otherwise it contains all other matched operators and factors.<br/>
You can see that the argument structure of method <code>act</code> is highly consistent to the defined match sequence of the corresponding alternative production.</p>

<p>We wrote some logic to compute the total multiplication or division of all matched factors, and finally, returned the result as the result of this action.</p>

<ul>
<li>Then, we add action for the <code>expr</code> rule. It's almost the same as the action of <code>addend</code> rule, but in an <code>add</code> or <code>subtract</code> manner when computing the matched elements:</li>
</ul>


<p>The <code>expr</code> rule also could have only one action:</p>

<pre><code>expr.define(addend, CC.ks(a.or("\\-"), addend)).action(new Action&lt;Object[]&gt;() {
    public Double act(Object[] ms) {
        Double a0 = (Double) ms[0];
        Object[] others = (Object[]) ms[1];
        for (Object other : others) {
            Object[] opAndFactor = (Object[]) other;
            if ("+".equals(opAndFactor[0])) {
                a0 += (Double) opAndFactor[1];
            } else {
                a0 -= (Double) opAndFactor[1];
            }
        }
        return a0;
    }
});
</code></pre>

<p>Finally, we add action for the <code>calc</code> rule. It's the starter rule. All computations should have been done at this point. So all we need to do in its action is return the final result, ignoring the <code>EOF</code>:</p>

<pre><code>calc.defineGrule(expr, CC.EOF).action(new Action&lt;Object[]&gt;() {
    public Double act(Object[] ms) {
        return (Double) ms[0];
    }
});
</code></pre>

<p>Now, we have done defining a calculator and added proper actions for it, we could <code>compile</code> it now:</p>

<pre><code>Exe exe = calc.compile();
</code></pre>

<p>Then, enjoy with our new calculator:</p>

<pre><code>// this should print the result: 3389.0
System.out.println(exe.eval("1 +2+3+(4 +5*6*7*(64/8/2/(2/1 )/1)*8  +9  )+   10"));
</code></pre>

<p>It's quite simple isn't it? If you are already familiar with the API, 15 min is too much for defining such a calculator!<br/>
And the follow is all the code in a gist, you could copy and try it in your own IDE:<br/>
<div><script src='https://gist.github.com/3339604.js?file='></script>
<noscript><pre><code>import com.github.pfmiles.dropincc.Action;
import com.github.pfmiles.dropincc.CC;
import com.github.pfmiles.dropincc.Exe;
import com.github.pfmiles.dropincc.Grule;
import com.github.pfmiles.dropincc.Lang;
import com.github.pfmiles.dropincc.TokenDef;

public class Calculator {
    private static Exe exe = null;
    /**
     * &lt;pre&gt;
     * calc ::= expr $
     * expr ::= addend (('+'|'-') addend)*
     * addend ::= factor (('\*'|'/') factor)*
     * factor ::= '\d+(\.\d+)?'
     *          | '(' expr ')'
     * &lt;/pre&gt;
     */
    static {
        // some elements' pre-definitions in order to call the methods
        Lang calc = new Lang(&quot;Calc&quot;);
        TokenDef a = calc.newToken(&quot;\\+&quot;);
        TokenDef m = calc.newToken(&quot;\\*&quot;);
        Grule expr = calc.newGrule();
        Grule addend = calc.newGrule();
        Grule factor = calc.newGrule();

        // grammar definition starts here
        calc.defineGrule(expr, CC.EOF).action(new Action&lt;Object[]&gt;() {
            public Double act(Object[] ms) {
                return (Double) ms[0];
            }
        });
        expr.define(addend, CC.ks(a.or(&quot;\\-&quot;), addend)).action(new Action&lt;Object[]&gt;() {
            public Double act(Object[] ms) {
                Double a0 = (Double) ms[0];
                Object[] others = (Object[]) ms[1];
                for (Object other : others) {
                    Object[] opAndFactor = (Object[]) other;
                    if (&quot;+&quot;.equals(opAndFactor[0])) {
                        a0 += (Double) opAndFactor[1];
                    } else {
                        a0 -= (Double) opAndFactor[1];
                    }
                }
                return a0;
            }
        });
        addend.define(factor, CC.ks(m.or(&quot;/&quot;), factor)).action(new Action&lt;Object[]&gt;() {
            public Double act(Object[] ms) {
                Double f0 = (Double) ms[0];
                Object[] others = (Object[]) ms[1];
                for (Object other : others) {
                    Object[] opAndFactor = (Object[]) other;
                    if (&quot;*&quot;.equals(opAndFactor[0])) {
                        f0 *= (Double) opAndFactor[1];
                    } else {
                        f0 /= (Double) opAndFactor[1];
                    }
                }
                return f0;
            }
        });
        factor.define(&quot;\\d+(\\.\\d+)?&quot;).action(new Action&lt;String&gt;() {
            public Double act(String matched) {
                return Double.parseDouble(matched);
            }
        }).alt(&quot;\\(&quot;, expr, &quot;\\)&quot;).action(new Action&lt;Object[]&gt;() {
            public Double act(Object[] ms) {
                return (Double) ms[1];
            }
        });
        // grammar definition end

        exe = calc.compile();
    }

    public static void main(String... args) {
        System.out.println(exe.eval(&quot;1 +2+3+(4 +5*6*7*(64/8/2/(2/1 )/1)*8  +9  )+   10&quot;));
    }
}
</code></pre></noscript></div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ideas and Concepts behind Dropincc.java]]></title>
    <link href="http://pfmiles.github.io/blog/ideas-and-concepts-behind-dropincc-dot-java"/>
    <updated>2012-08-10T00:40:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/ideas-and-concepts-behind-dropincc-dot-java</id>
    <content type="html"><![CDATA[<h3>DSLs in java is hard.</h3>

<p>DSLs are rarely discussed in java community. Or, at least comparing to other dynamic languages' world, DSLs in java is much harder to create.</p>

<p>Why does this happen?</p>

<p>According to <a href="http://martinfowler.com/bliki/DomainSpecificLanguage.html">Martin Fowler's comments on DSLs</a>, they are separated mainly to two kinds: internal and external DSLs.</p>

<p>I believe that, the ability of how a specific general purposed programming language could be customized to an internal DSL relies on the language's <a href="http://en.wikipedia.org/wiki/Metaprogramming">meta-programming</a> features.</p>

<p>Some languages, especially dynamic typed ones, have ability to customize its syntactical appearance at runtime. By intercepting their class defining life-cycles, executing fail-over strategies when method or field missings, or doing presentation substitutions via sophisticated macro systems or even, directly change their parse tree at runtime. All those incredible features are the magic behind internal DSLs.</p>

<p>But, we sadly found that java has none of those magic stuff to help building internal DSLs. There's little meta-programming features in java. Annotations? Perhaps one rare creature, but its not enough.<br/>
Maybe the only way to create internal DSLs in java is to design a set of <a href="http://www.martinfowler.com/bliki/FluentInterface.html">Fluent Interface</a> API. It's great, but you won't have much space on customizing the syntax of your DSL.</p>

<p>Then, seems that the possible ways to create real-world, sophisticated DSLs in java are always turns out to be external-DSLs. But, this won't be easy, always, since the creation of computer world.</p>

<!-- more -->


<p>Creating external DSLs means doing lexical &amp; syntactical analyzing all by ourselves. There is a whole bunch of open sourced tools, say, <a href="http://en.wikipedia.org/wiki/Compiler-compiler">parser generators</a>, to help doing so, but there's too much unnecessary efforts must be made before you get your grammar run.</p>

<p>Those traditional parser generators are great but in fact not suitable for DSL creating. Like lex&amp;bison, javacc, jcup and antlr etc. They usually have their own grammar you must learn to define grammar rules, this is some what big learning cost.<br/>
After you have done writing your grammar, they usually requires you to run a specific compiling tool in command-line to 'compile' the rules you just wrote. And finally gives you a couple of source files in your host language and telling you to place them into somewhere of your project directory. Then you could run your program. If errors occur, you would re-do those steps by frequently switching between command-line and your IDE.</p>

<p>These steps are troublesome in practice. Especially for those first using a parser generator. I've seen one of my colleague struggled against antlr for one month, in order to build a SQL-like DSL. And much of his time was spent on getting familiar with antlr's grammar, its 'antlrWorks' IDE and some command-line tools. It was painful when recall on this month.</p>

<p>So I think one must not have to carry so much burden when he just want to create a relatively simple DSL. And <a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a> is something I create to ease the building process of external DSL in java.</p>

<h3>If all done in one place.</h3>

<ul>
<li>I don't think additional grammar must be created to describe grammar rules, this could be done in internal DSL in java, a.k.a fluent interfaces. Creating a <a href="http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form">EBNF</a> like internal DSL in java is affordable.</li>
<li>I don't think additional command-line tools or individual specific IDE is needed since we are adopting internal DSL to describe grammar rules. Just a commonly used java IDE is sufficient.</li>
<li>Also, I don't think we must repeat the compile-copy, and run cycle when we trying and debugging our new creating language. Grammar may be run directly just after we defined it. Like we edit and test java program instantly in most modern IDEs.</li>
</ul>


<p>And, all in all, in summary... dropincc.java ends up such a tool with those missions. I hope this small lib could help a lot in building external DSLs.</p>

<p>For a starter dummy example, please refer to <a href="/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java/">this post</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dropincc.java, The Ultimate Tool to Create DSLs in Java]]></title>
    <link href="http://pfmiles.github.io/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java"/>
    <updated>2012-08-04T17:22:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java</id>
    <content type="html"><![CDATA[<h3>Initial version released.</h3>

<p>Dropincc.java is a dynamic parser generator which allows you crafting your DSLs in pure java, using your favorite editor.<br/>
Now it reached its initial release version 0.1.0. You can download it from the <a href="https://github.com/pfmiles/dropincc.java">project page</a> and play around with it.<br/>
There's a detailed <em>Quick Start</em> guide on the project page, it could guide you through to have a overall feeling on using dropincc.java.</p>

<h3>Main attributes of Dropincc.java.</h3>

<ul>
<li>It's not just 'yet another compiler compiler'. It aims to help you building DSLs in java <strong>Dynamically</strong>.</li>
<li><strong>Dynamic</strong> means you can use your newly defined DSL immediately after you have just finished its definition. No other steps required, no additional command-line instructions needed to type.</li>
<li>Very close to EBNF grammar syntactically when defining grammar rules using dropincc.java. With the fluent interface API, you can feel as if you are writing EBNF directly. Syntactically  close to EBNF is very nice for a parser generator.</li>
<li>It generates LL(*) parser for your language, dynamically, using java 1.6's compiler API. And it provide powerful <em>semantic predicate</em> mechanics to handle even context-sensitive situations.</li>
<li>It won't generate a parser source file to you and telling you to place the file into some where of your project directory. Instead, it handles all those generation &amp; compiling staff in the background and only provides you a executable object which you can invoke.</li>
<li>No other dependencies except for the built-in java library. Requires JDK 1.6 or above.</li>
</ul>


<h3>A dummy language example.</h3>

<!-- more -->


<p>Requires JDK 1.6 or above. Firstly, place the dropincc <a href="https://github.com/pfmiles/dropincc.java/releases">jar file</a> in your class path.</p>

<p>And then, crafting your language's <a href="http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form">EBNF</a> definition:<br/>
Let's define a language which accepts arbitrary numbers of quoted 'a' or 'bc'. For example: '(a)(bc)', '(bc)((a))' or '(((bc)))(bc)', the numbers of pairs of parentheses is unlimited.<br/>
The EBNF of this dummy language:</p>

<pre><code>S ::= L $
L ::= Q*
Q ::= 'a'
    | 'bc'
    | '(' Q ')'
</code></pre>

<p>Ok, after defining the EBNF representation of our language, it's time to <strong>translate</strong> the EBNF into dropincc.java representation. I say 'translate' here because this is a line-by-line straightforward step:</p>

<pre><code>public static void main(String... args) throws Throwable {
    Lang lang = new Lang("Dummy");
    TokenDef a = lang.newToken("a");
    TokenDef bc =lang.newToken("bc");
    TokenDef lp = lang.newToken("\\(");
    TokenDef rp = lang.newToken("\\)");
    Grule L = lang.newGrule();
    Grule Q = lang.newGrule();

    lang.defineGrule(L, CC.EOF); // S ::= L $
    L.define(CC.ks(Q));// L ::= Q*
    /*
     * Q ::= 'a'
     *     | 'bc'
     *     | '(' Q ')'
     */
    Q.define(a)
    .alt(bc)
    .alt(lp, Q, rp);
}
</code></pre>

<p>Ok, we have done defining the grammar rules of our dummy language, so easy:</p>

<ul>
<li>Define tokens, using built-in java regular expression syntax. And define rules, say, 'Grule's in dropincc.java. TokenDefs and Grules are basic elements of defining grammar rules.</li>
<li>You just using your defined TokenDefs and Grules to express your grammar, just like writing EBNF.</li>
<li>Elements concatenations are expressed by comma separated sequences: <code>L, CC.EOF</code> means <code>L $</code>. CC.EOF is a predefined TokenDef provided by dropincc.java.</li>
<li>Alternative productions of a grammar rule is expressed by a <code>alt</code> method call on a grule element. For example, the <code>Q</code> rule has three alternative productions.</li>
<li>The kleene star(means <strong>zero or more</strong>) and kleene cross(<strong>means one or more</strong>) notation is expressed by <code>CC.ks</code> and <code>CC.kc</code> utility functions. See the line: <code>L.define(CC.ks(Q));// L ::= Q*</code>.</li>
</ul>


<p>That's almost all you need to learn about how to define a grammar using dropincc.java.<br/>
After that, you can <code>compile</code> your grammar:</p>

<pre><code>Exe exe = lang.compile();
</code></pre>

<p>This step would make you a callable object named 'exe'. You can use this object to <code>eval</code> and test your newly defined language:</p>

<pre><code>System.out.println(exe.eval("a(a)((bc))"));
</code></pre>

<p>This would print the output: <code>[Ljava.lang.Object;@67a5a19</code>. It's an object array which holds the whole parse tree:<br/>
<img src="/images/dropincc/dummy.png" alt="Dummy lang parse tree" /></p>

<p>But it's useless just getting the parse tree. We should do something to manipulate the parse tree and produce some 'results' of this parsing.</p>

<p>Ok, suppose we have a dummy task: to remove all parentheses from the input string, leaving only the <code>'a'</code> and <code>'bc'</code>s there. Then at last, return the resulting string as the return value of <code>eval</code> method call on <code>exe</code>.</p>

<p>This involves adding <code>actions</code> to the grammar. The <code>action</code>s are some kind of code block, it should execute when its' corresponding grammar rule production matches.</p>

<p>In dropincc.java, <code>actions</code> are implemented by <code>closure</code>s, using the <code>Action</code> interface. We try to add an action to the <code>Q</code> rule:</p>

<pre><code>Q.define(a).action(new Action() {
    public String act(Object matched) {
        return (String) matched;// string 'a'
    }
}).alt(bc).action(new Action() {
    public String act(Object matched) {
        return (String) matched;// string 'bc'
    }

}).alt(lp, Q, rp).action(new Action() {
    public String act(Object matched) {
        // returns the middle element matched, that's the returned value of the enclosing 'Q' rule
        return (String) ((Object[]) matched)[1];
    }
});
</code></pre>

<p>Above is the <code>Q</code> rule with three actions, each action for one alternative production. In fact since the first two actions does noting but just returning the matched string, so they are not necessary. The <code>Q</code> rule with action could be defined as follows:</p>

<pre><code>Q.define(a)
.alt(bc)
.alt(lp, Q, rp).action(new Action() {
    public String act(Object matched) {
        // returns the middle element matched, that's the returned value of the enclosing 'Q' rule
        return (String) ((Object[]) matched)[1];
    }
});
</code></pre>

<p>Leaving only the third action there. The third action, returned the middle element matched of its production(ignored left and right parentheses). The middle element matched is the return value of the recursively enclosing <code>Q</code> rule.</p>

<p>The action for <code>L</code> rule is quite simple and significant: it collects all strings matched and concatenates them into a whole large string, then return the resulting string:</p>

<pre><code>L.define(CC.ks(Q)).action(new Action() {
    public String act(Object matched) {
        Object[] ms = (Object[]) matched;
        StringBuilder sb = new StringBuilder();
        for (Object m : ms)
            sb.append(m);
        return sb.toString();
    }
});// L ::= Q*
</code></pre>

<p>Then the last top-level rule's action: just return the value of <code>L</code> rule, just ignoring EOF:</p>

<pre><code>lang.defineGrule(L, CC.EOF).action(new Action() {
    public String act(Object matched) {
        return (String) ((Object[]) matched)[0];
    }
}); // S ::= L $
</code></pre>

<p>Ok, we can now run the program again and could see it prints out the output: <code>aabc</code>, with all parentheses removed.</p>

<p>The whole program in a gist:<br/>
<div><script src='https://gist.github.com/3257023.js?file='></script>
<noscript><pre><code>package test;

import com.github.pfmiles.dropincc.Action;
import com.github.pfmiles.dropincc.CC;
import com.github.pfmiles.dropincc.Exe;
import com.github.pfmiles.dropincc.Grule;
import com.github.pfmiles.dropincc.Lang;
import com.github.pfmiles.dropincc.TokenDef;

public class Test {

    /**
     * &lt;pre&gt;
     * S ::= L $
     * L ::= Q*
     * Q ::= 'a'
     *     | 'bc'
     *     | '(' Q ')'
     * &lt;/pre&gt;
     */
    public static void main(String... args) throws Throwable {
        Lang lang = new Lang(&quot;Dummy&quot;);
        TokenDef a = lang.newToken(&quot;a&quot;);
        TokenDef bc = lang.newToken(&quot;bc&quot;);
        TokenDef lp = lang.newToken(&quot;\\(&quot;);
        TokenDef rp = lang.newToken(&quot;\\)&quot;);
        Grule L = lang.newGrule();
        Grule Q = lang.newGrule();

        lang.defineGrule(L, CC.EOF).action(new Action() {
            public String act(Object matched) {
                return (String) ((Object[]) matched)[0];
            }
        }); // S ::= L $
        L.define(CC.ks(Q)).action(new Action() {
            public String act(Object matched) {
                Object[] ms = (Object[]) matched;
                StringBuilder sb = new StringBuilder();
                for (Object m : ms)
                    sb.append(m);
                return sb.toString();
            }
        });// L ::= Q*
        /*
         * Q ::= 'a' | 'bc' | '(' Q ')'
         */
        Q.define(a).alt(bc).alt(lp, Q, rp).action(new Action() {
            public String act(Object matched) {
                // returns the middle element matched, that's the returned value
                // of the enclosing 'Q' rule
                return (String) ((Object[]) matched)[1];
            }
        });

        Exe exe = lang.compile();
        System.out.println(exe.eval(&quot;a(a)((bc))&quot;));
    }
}</code></pre></noscript></div>

You can download and play around with it on your own.</p>

<p>Dropincc.java is currently on its very initial stage. It has some major improvements to be done:</p>

<ul>
<li>It uses java's built-in regEx implementation to support token definition, so it couldn't do 'longest match' currently. This should be fixed later.</li>
<li>Due to some LL(*) analysis issues, 'Non-LL regular' exceptions may be thrown when it encounters some special case of grammar rules. This must be fixed soon.</li>
</ul>


<p>There is a more practical <strong>Hello World</strong> example which implements a full-featured calculator in the quick start guide of dropincc.java. On its project <a href="https://github.com/pfmiles/dropincc.java">home page</a>. Go and check out there if you like.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LL(*)的概念与实现]]></title>
    <link href="http://pfmiles.github.io/blog/concept-and-implementation-of-ll-star"/>
    <updated>2012-07-14T13:59:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/concept-and-implementation-of-ll-star</id>
    <content type="html"><![CDATA[<h3>概念和起源</h3>

<p>LL(*)是由<a href="http://www.cs.usfca.edu/~parrt/">Terrence Parr</a>教授创造的，为使用<a href="http://en.wikipedia.org/wiki/LL_parsing">LL分析</a>的语法解析器做超前查看(look ahead)的一种算法。按照Parr教授的说法，这个算法从最初的想法至今的完善和调整已经历了15年。目前该算法的一个著名的实现在<a href="http://www.antlr.org/">antlr3</a>中。</p>

<h3>特点，n言以蔽之...</h3>

<ul>
<li>对于语法产生式分支的预测判断，走LL分析路子的解析器，其能力完全取决于能超前查看多少个token。传统地讲，LL(1), LL(2)直至LL(k)，就是在讲该解析器能够在语法分析过程中超前查看1, 2, k...个token。</li>
<li>而LL(*)的意思就是，它在语法解析的过程中，超前查看的token个数不是固定的，是可伸缩的，不过这一点LL(k)分析也能做到(在k范围之内...)；</li>
<li>但是，LL(*)还能越过一些重复出现的token，“到达”这些重复出现的token之后的token来做分析，这一点LL(k)是无法办到的(LL(k)无法意识到有token在循环出现，不管情况如何，它都将在尝试k个token之后放弃)；</li>
<li>如果将超前查看的决策逻辑画成DFA的话，就是这样的一种形式：<img src="/images/ll3.png" title="Look Ahead DFA" alt="Look Ahead DFA" />

<ul>
<li>这张图画的是这种语法规则的超前查看决策情况：<code>A ::= a b c | a b e</code>, 显然这是一个LL(3)语法；</li>
<li>但是这样的语法: <code>A ::= a b* c | a b* e</code>是无法被LL(k)识别的，因为中间的<code>b*</code>代表“0个或多个b”(kleene闭包)，这并不是一个固定的重复次数，因此LL(k)无法识别，for any k...</li>
<li>但是，LL(*)算法能够构造出这样的DFA来识别它：<img src="/images/llstar.png" title="LL(*) Look Ahead DFA" alt="LL(*) Look Ahead DFA" /></li>
<li>也就是说，传统LL(k)的look ahead DFA是不带环的，而LL(*)算法能构造出带环的DFA来做判断，它能越过无穷多个存在于环上的token，从而“到达”环之后的token继续做判断。</li>
</ul>
</li>
<li>上面的<code>A ::= a b* c | a b* e</code>语法使用了<a href="/blog/left-recursion-removal-using-kleene-closure/">"kleene闭包"表示法</a>来表示“0个或多个”，这种表示法在正则表达式中很常见；事实上，基于LL(*)算法实现的语法解析器生成器(比如antlr3)对Kleene闭包表示法特别友好，可以鼓励使用，还能顺便解决一些LL分析法所不允许的“<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>”。</li>
<li>大多数情况来讲，LL(*)的识别能力弱于<a href="http://en.wikipedia.org/wiki/LR_parser">LR(k)</a>，但也有少数情况是LR(k)识别不了但LL(*)可以的，所以LL(*)与LR(k)之间并没有严格的强弱顺序。</li>
<li>LL(*)本身对语法的识别能力也是有限的，比如它无法区分"具有相同的递归规则前缀"的多个分支，这种情况是要尽量避免的，大多数能够较容易地改写;</li>
<li>对于LL(*)不能正确分析的情况，还能引入"Semantic Predicate"(语义断言)来辅助判断, Semantic Predicate可以是任何逻辑，只要返回一个bool值就行；有了Semantic Predicate的辅助，LL(*)甚至能够parse一些上下文相关的语法，实际上它能parse C++</li>
</ul>


<h3>主要算法及其实现(python)</h3>

<p><strong> Parr教授在2011年发表的paper"LL(*): The Foundation of the ANTLR Parser Generator"中详细描述了这个算法，下面就是其主要过程，具体的代码实现(python)在工程<a href="https://github.com/pfmiles/llstar">llstar</a>中 </strong></p>

<!-- more -->


<p>为了简单起见，约定大写字母用来命名non-terminal, 小写字母命名terminal或Semantic Predicate，<code>$</code>表示EOF，假设有如下语法规则：</p>

<pre><code>S ::= A $  
A ::= a c*  
    | b c*  
</code></pre>

<ul>
<li>针对此语法规则，构造Augmented Transition Network(ATN)，其实也就是一个NFA，NFA的边就是terminal或non-terminal或者Semantic predicate：<img src="/images/atn.png" alt="ATN network" />, 代码在llstar工程的<code>atn_creation.py</code>的<code>rule.merge_to_atn</code>方法中。</li>
<li>接下来将要对这个ATN实施的算法其实就是经典的<a href="http://en.wikipedia.org/wiki/Powerset_construction">Subset Construction算法</a> —— 的改造版本：在“空边闭包运算(closure)”中加入了压栈、出栈功能，用于处理运算过程中<code>closure</code>函数经过non-terminal边时对其所对应的ATN的调用和返回。<br/>
这个算法的具体描述是比较复杂，在Parr教授的paper中已有精确描述。不过真的要用代码实现起来，某些细节还需稍微修饰，才能正确地实现。<br/>
最后的结果，其实就是使用更改后的版本的Subset Construction算法，将上述ATN(NFA)转化为一个个DFA，每条语法规则都对应一个DFA作为其look ahead DFA。<br/>
例如上面的<code>S</code>规则最后的DFA为：<img src="/images/sdfa.png" alt="S DFA" />, well, 就一个终结态，没任何状态转换 —— 这是当然的，S规则只有一个alternative production... <br/>
而<code>A</code>规则的DFA为：<img src="/images/adfa.png" alt="A DFA" />, 意思就是，如果第一个token为<code>a</code>，就选择第一个分支，若是<code>b</code>，就选择第二个分支，这是一个LL(1)的语法。<br/>
简单来说就是这样，具体可以参考llstar的代码...这花了我不少时间调试出来的代码，还是直接看代码了解最直接:)</li>
</ul>


<h3>实验台及例子介绍</h3>

<p>OK，主要的算法原理了解之后，展示了2个玩具例子，似乎还不能看出LL(*)的特点来。<br/>
下面我将逐步展示一些真正non-trivial的例子，以表明它真的不是过家家...</p>

<p>LL(3)(更正：或许这该是LL(4)可能我数错了)语法(对应llstar工程中的<code>LL_3_many_alts.py</code>):</p>

<pre><code>S ::= A $
A ::= B a*
    | C a+
    | D a?
B ::= a b c C
    | a b c D
    | d
C ::= e f g D
    | e f g h
D ::= i j k l
    | i j k m
</code></pre>

<p>这个语法是固定的LL(3)，没有什么特别，不过分支比较多, 它的ATN：<img src="/images/ll3atn.png" alt="LL(3) ATN" /><br/>
规则<code>A</code>的DFA: <img src="/images/llstar/ll3adfa.png" alt="LL(3) Rule A DFA" /><br/>
规则<code>B</code>的DFA: <img src="/images/llstar/ll3bdfa.png" alt="LL(3) Rule B DFA" /><br/>
规则<code>C</code>的DFA: <img src="/images/llstar/ll3cdfa.png" alt="LL(3) Rule C DFA" /><br/>
规则<code>D</code>的DFA: <img src="/images/llstar/ll3ddfa.png" alt="LL(3) Rule D DFA" /></p>

<p>上面这个语法，LL(4)分析也能搞定，而真正体现出LL(*)特点的是下面这样的语法(对应llstar工程中<code>over_kleene.py</code>)：</p>

<pre><code>S ::= A $
A ::= a* b
    | a+ c
</code></pre>

<p>其中，规则<code>A</code>的2条分支拥有共同的kleene闭包前缀，LL(k)是无法识别的，它的ATN:<img src="/images/llstar/overkleeneatn.png" alt="Over Kleene ATN" /><br/>
而LL(*)能够为<code>A</code>生成这样的DFA：<img src="/images/llstar/overkleeneadfa.png" alt="Over Kleene Rule A DFA" /><br/>
这个DFA能够越过terminal<code>a</code>的任意重复，从而考虑到后面的terminal<code>b</code>和<code>c</code>来做判断<br/>
而下面这个更加"恶劣"的列子则更能说明LL(*)的这个特征(对应llstar工程中<code>over_non_recurse_rule.py</code>)：</p>

<pre><code>S ::= A $
A ::= B* b
    | C+ c
B ::= a d
    | e
C ::= a d
    | e
</code></pre>

<p>这个例子中，<code>B</code>和<code>C</code>完全相同，并分别被包含在规则<code>A</code>的2条分支的kleene闭包中，<br/>
最终生成的<code>A</code>的DFA: <img src="/images/llstar/nonrecursiveradfa.png" alt="Non-recursive Rule A DFA" /></p>

<p>上面提到过，LL(*)也有不能解决的情况，比如2条分支拥有"共同的、递归的规则作为前缀"，比如这样：</p>

<pre><code>S ::= A eof
A ::= E a
    | E b
E ::= c E d
    | e
</code></pre>

<p>上面的<code>A</code>规则的两条分支拥有共同的前缀<code>E</code>，而<code>E</code>本身是一条递归规则，这样的规则是LL(*)无法分析的，在llstar工程中对应<code>experiments/common_recurse_prefix_fail.py</code>, 运行的时候会抛出错误提示。这种情况在antlr3中会将parsing策略退化为LL(1) + 回溯的形式。</p>

<pre><code>Traceback (most recent call last):
  File "/home/pf-miles/myWorkspace/llstar/experiments/common_recurse_prefix_fail.py", line 31, in &lt;module&gt;
    d_a = create_dfa(ra.get_start_state(globals_holder.a_net))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 136, in create_dfa
    d_state_new.add_all_confs(closure(d_state, conf))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 99, in closure
    raise Exception("Likely non-LL regular, recursive alts: " + str(d_state.recursive_alts) + ", rule: " + str(globals_holder.a_net.get_rule_of_state(p)))
Exception: Likely non-LL regular, recursive alts: set([0, 1]), rule: E
</code></pre>

<p>还有一些特殊情况，比如规则完全就是冲突的，那么这个时候就是Semantic Predicate发挥作用的时候(对应llstar工程中<code>conflicting_with_preds.py</code>)：</p>

<pre><code>S ::= A $
A ::= {pred1}? B
    | {pred2}? b
B ::= b
    | b
</code></pre>

<p>最终<code>A</code>的DFA：<img src="/images/llstar/confresolvedwithpredsadfa.png" alt="Conflict Resolved With Preds A DFA" /><br/>
实际开发中，写出这样的规则是坑到爷的...不过LL(*)还算能很好解决...其实这里就算没有Semantic Predicate, LL(*)也能按照convention，“选择较早定义的语法分支”来解决。</p>

<p>还有就是在分析的过程中会导致分析栈溢出(不是程序语言的callstack的overflow, 而是LL(*)的closure操作维护的一个规则调用栈溢出)的时候，LL(*)也会使用Semantic Predicate来辅助判断, 比如规则(对应llstar中<code>overflow_with_preds.py</code>):</p>

<pre><code>S ::= A $
A ::= {pred1?} B a
    | {pred2?} b* c
    | {pred3?} b* c
B ::= b+ B
</code></pre>

<p>规则<code>A</code>的三条分支全部存在严重冲突(都拥有能识别无穷个'b'的前缀)并且其中一个是另一条递归规则<code>B</code>，这种形式会导致LL(*)的分析栈溢出，不过仍然没关系，这样的情况能在溢出发生时，调用<code>pred1</code>、<code>pred2</code>和<code>pred3</code>来解决(这三个pred就是Semantic Precicate，是能包含任何逻辑但最终返回bool值的表达式)<br/>
生成的规则<code>A</code>的DFA: <img src="/images/llstar/overflowadfa.png" alt="Overflow A DFA" /><br/>
这里设定的最大分析递归层数为<code>10</code>，因此，DFA在接受了第10个'b'之后达到了溢出状态<code>d14</code>，这时调用了各个alternative附带的几个predicate来解决冲突...</p>

<blockquote><p>(2012-09-03 注： 实际上上述规则是不正确的，<code>B ::= b+ B</code>是有问题的规则，因为<code>b+</code>会贪婪地match掉所有的连续的<code>'b'</code>，导致后面的<code>B</code>只可能抛错; 所以这个例子也只能用来演示分析栈溢出的情况，实际应用中是不可能写出这样的规则的)</p></blockquote>

<h3>总结</h3>

<p>OK, 大概如是了；上述算法的实现、例子的代码均在<a href="https://github.com/pfmiles/llstar">llstar</a>工程中能找到<br/>
llstar工程是我花了不少时间实现并调试好的一块LL(*)算法的“实验台”，可以在里面慢慢把玩各种变态的、五花八门的语法规则，以验证LL(*)的分析能力<br/>
在工程的<code>experiments</code>文件夹下已经有许多具有代表性的例子...都是python代码<br/>
另外，llstar工程是在eclipse + pydev环境下开发的，因此如果要在命令行里运行，可能要对例子里面的import路径稍作修改，当然，最好是直接在eclipse + pydev环境下运行它们了<br/>
在linux环境下，llstar的所有例子都能自动生成上文中看到的各种DFA/NFA图像，不过前提是环境中要装有<a href="http://www.graphviz.org/">graphviz</a></p>

<p>现在的所有语法解析器生成器中，似乎都是LR分析的天下，LL分析大多是手写解析器的首选...<br/>
不过在现有的使用LL分析方式的产品中，也就只有LL(*)和PEG(Packrat)parsing比较常见也比较实用了，能与LR分析一较高下。<br/>
而配上回溯策略的LL(*)是严格强于Packrat parsing的，这样看来大概走LL分析路子的自动化工具也只有LL(*)容易一枝独秀了(想必这也是antlr相对较为流行的原因)。</p>
]]></content>
  </entry>
  
</feed>
