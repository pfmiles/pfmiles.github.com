<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: dropincc | Meta-Interpretation]]></title>
  <link href="http://pfmiles.github.com/blog/category/dropincc/atom.xml" rel="self"/>
  <link href="http://pfmiles.github.com/"/>
  <updated>2012-08-12T15:04:50+08:00</updated>
  <id>http://pfmiles.github.com/</id>
  <author>
    <name><![CDATA[pf_miles]]></name>
    <email><![CDATA[miles.wy.1@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Ideas and Concepts behind Dropincc.java]]></title>
    <link href="http://pfmiles.github.com/blog/ideas-and-concepts-behind-dropincc-dot-java"/>
    <updated>2012-08-10T00:40:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/ideas-and-concepts-behind-dropincc-dot-java</id>
    <content type="html"><![CDATA[<h3>DSLs in java is hard.</h3>

<p>DSLs are rarely discussed in java community. Or, at least comparing to other dynamic languages' world, DSLs in java is much harder to create.</p>

<p>Why does this happen?</p>

<p>According to <a href="http://martinfowler.com/bliki/DomainSpecificLanguage.html">Martin Fowler's comments on DSLs</a>, they are separated mainly to two kinds: internal and external DSLs.</p>

<p>I believe that, the ability of how a specific general purposed programming language could be customized to an internal DSL relies on the language's <a href="http://en.wikipedia.org/wiki/Metaprogramming">meta-programming</a> features.</p>

<p>Some languages, especially dynamic typed ones, have ability to customize its syntactical appearance at runtime. By intercepting their class defining life-cycles, executing fail-over strategies when method or field missings, or doing presentation substitutions via sophisticated macro systems or even, directly change their parse tree at runtime. All those incredible features are the magic behind internal DSLs.</p>

<p>But, we sadly found that java has none of those magic stuff to help building internal DSLs. There's little meta-programming features in java. Annotations? Perhaps one rare creature, but its not enough.<br/>
Maybe the only way to create internal DSLs in java is to design a set of <a href="http://www.martinfowler.com/bliki/FluentInterface.html">Fluent Interface</a> API. It's great, but you won't have much space on customizing the syntax of your DSL.</p>

<p>Then, seems that the possible ways to create real-world, sophisticated DSLs in java are always turns out to be external-DSLs. But, this won't be easy, always, since the creation of computer world.</p>

<!-- more -->


<p>Creating external DSLs means doing lexical &amp; syntactical analyzing all by ourselves. There is a whole bunch of open sourced tools, say, <a href="http://en.wikipedia.org/wiki/Compiler-compiler">parser generators</a>, to help doing so, but there's too much unnecessary efforts must be made before you get your grammar run.</p>

<p>Those traditional parser generators are great but in fact not suitable for DSL creating. Like lex&amp;bison, javacc, jcup and antlr etc. They usually have their own grammar you must learn to define grammar rules, this is some what big learning cost.<br/>
After you have done writing your grammar, they usually requires you to run a specific compiling tool in command-line to 'compile' the rules you just wrote. And finally gives you a couple of source files in your host language and telling you to place them into somewhere of your project directory. Then you could run your program. If errors occur, you would re-do those steps by frequently switching between command-line and your IDE.</p>

<p>These steps are troublesome in practice. Especially for those first using a parser generator. I've seen one of my colleague struggled against antlr for one month, in order to build a SQL-like DSL. And much of his time was spent on getting familiar with antlr's grammar, its 'antlrWorks' IDE and some command-line tools. It was painful when recall on this month.</p>

<p>So I think one must not have to carry so much burden when he just want to create a relatively simple DSL. And <a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a> is something I create to ease the building process of external DSL in java.</p>

<h3>If all done in one place.</h3>

<ul>
<li>I don't think additional grammar must be created to describe grammar rules, this could be done in internal DSL in java, a.k.a fluent interfaces. Creating a <a href="http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form">EBNF</a> like internal DSL in java is affordable.</li>
<li>I don't think additional command-line tools or individual specific IDE is needed since we are adopting internal DSL to describe grammar rules. Just a commonly used java IDE is sufficient.</li>
<li>Also, I don't think we must repeat the compile-copy, and run cycle when we trying and debugging our new creating language. Grammar may be run directly just after we defined it. Like we edit and test java program instantly in most modern IDEs.</li>
</ul>


<p>And, all in all, in summary... dropincc.java ends up such a tool with those missions. I hope this small lib could help a lot in building external DSLs.</p>

<p>For a starter dummy example, please refer to <a href="/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java/">this post</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dropincc.java, The Ultimate Tool to Create DSLs in Java]]></title>
    <link href="http://pfmiles.github.com/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java"/>
    <updated>2012-08-04T17:22:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java</id>
    <content type="html"><![CDATA[<h3>Initial version released.</h3>

<p>Dropincc.java is a dynamic parser generator which allows you crafting your DSLs in pure java, using your favorite editor.<br/>
Now it reached its initial release version 0.1.0. You can download it from the <a href="https://github.com/pfmiles/dropincc.java">project page</a> and play around with it.<br/>
There's a detailed <em>Quick Start</em> guide on the project page, it could guide you through to have a overall feeling on using dropincc.java.</p>

<h3>Main attributes of Dropincc.java.</h3>

<ul>
<li>It's not just 'yet another compiler compiler'. It aims to help you building DSLs in java <strong>Dynamically</strong>.</li>
<li><strong>Dynamic</strong> means you can use your newly defined DSL immediately after you have just finished its definition. No other steps required, no additional command-line instructions needed to type.</li>
<li>Very close to EBNF grammar syntactically when defining grammar rules using dropincc.java. With the fluent interface API, you can feel as if you are writing EBNF directly. Syntactically  close to EBNF is very nice for a parser generator.</li>
<li>It generates LL(*) parser for your language, dynamically, using java 1.6's compiler API. And it provide powerful <em>semantic predicate</em> mechanics to handle even context-sensitive situations.</li>
<li>It won't generate a parser source file to you and telling you to place the file into some where of your project directory. Instead, it handles all those generation &amp; compiling staff in the background and only provides you a executable object which you can invoke.</li>
<li>No other dependencies except for the built-in java library. Requires JDK 1.6 or above.</li>
</ul>


<h3>A dummy language example.</h3>

<!-- more -->


<p>Requires JDK 1.6 or above. Firstly, place the dropincc <a href="https://github.com/downloads/pfmiles/dropincc.java/dropincc.java-0.1.0.jar">jar file</a> in your class path.</p>

<p>And then, crafting your language's <a href="http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form">EBNF</a> definition:<br/>
Let's define a language which accepts arbitrary numbers of quoted 'a' or 'bc'. For example: '(a)(bc)', '(bc)((a))' or '(((bc)))(bc)', the numbers of pairs of parentheses is unlimited.<br/>
The EBNF of this dummy language:</p>

<pre><code>S ::= L $
L ::= Q*
Q ::= 'a'
    | 'bc'
    | '(' Q ')'
</code></pre>

<p>Ok, after defining the EBNF representation of our language, it's time to <strong>translate</strong> the EBNF into dropincc.java representation. I say 'translate' here because this is a line-by-line straightforward step:</p>

<pre><code>public static void main(String... args) throws Throwable {
    Lang lang = new Lang("Dummy");
    TokenDef a = lang.newToken("a");
    TokenDef bc =lang.newToken("bc");
    TokenDef lp = lang.newToken("\\(");
    TokenDef rp = lang.newToken("\\)");
    Grule L = lang.newGrule();
    Grule Q = lang.newGrule();

    lang.defineGrule(L, CC.EOF); // S ::= L $
    L.define(CC.ks(Q));// L ::= Q*
    /*
     * Q ::= 'a'
     *     | 'bc'
     *     | '(' Q ')'
     */
    Q.define(a)
    .alt(bc)
    .alt(lp, Q, rp);
}
</code></pre>

<p>Ok, we have done defining the grammar rules of our dummy language, so easy:</p>

<ul>
<li>Define tokens, using built-in java regular expression syntax. And define rules, say, 'Grule's in dropincc.java. TokenDefs and Grules are basic elements of defining grammar rules.</li>
<li>You just using your defined TokenDefs and Grules to express your grammar, just like writing EBNF.</li>
<li>Elements concatenations are expressed by comma separated sequences: <code>L, CC.EOF</code> means <code>L $</code>. CC.EOF is a predefined TokenDef provided by dropincc.java.</li>
<li>Alternative productions of a grammar rule is expressed by a <code>alt</code> method call on a grule element. For example, the <code>Q</code> rule has three alternative productions.</li>
<li>The kleene star(means <strong>zero or more</strong>) and kleene cross(<strong>means one or more</strong>) notation is expressed by <code>CC.ks</code> and <code>CC.kc</code> utility functions. See the line: <code>L.define(CC.ks(Q));// L ::= Q*</code>.</li>
</ul>


<p>That's almost all you need to learn about how to define a grammar using dropincc.java.<br/>
After that, you can <code>compile</code> your grammar:</p>

<pre><code>Exe exe = lang.compile();
</code></pre>

<p>This step would make you a callable object named 'exe'. You can use this object to <code>eval</code> and test your newly defined language:</p>

<pre><code>System.out.println(exe.eval("a(a)((bc))"));
</code></pre>

<p>This would print the output: <code>[Ljava.lang.Object;@67a5a19</code>. It's an object array which holds the whole parse tree:<br/>
<img src="/images/dropincc/dummy.png" alt="Dummy lang parse tree" /></p>

<p>But it's useless just getting the parse tree. We should do something to manipulate the parse tree and produce some 'results' of this parsing.</p>

<p>Ok, suppose we have a dummy task: to remove all parentheses from the input string, leaving only the <code>'a'</code> and <code>'bc'</code>s there. Then at last, return the resulting string as the return value of <code>eval</code> method call on <code>exe</code>.</p>

<p>This involves adding <code>actions</code> to the grammar. The <code>action</code>s are some kind of code block, it should execute when its' corresponding grammar rule production matches.</p>

<p>In dropincc.java, <code>actions</code> are implemented by <code>closure</code>s, using the <code>Action</code> interface. We try to add an action to the <code>Q</code> rule:</p>

<pre><code>Q.define(a).action(new Action() {
    public String act(Object matched) {
        return (String) matched;// string 'a'
    }
}).alt(bc).action(new Action() {
    public String act(Object matched) {
        return (String) matched;// string 'bc'
    }

}).alt(lp, Q, rp).action(new Action() {
    public String act(Object matched) {
        // returns the middle element matched, that's the returned value of the enclosing 'Q' rule
        return (String) ((Object[]) matched)[1];
    }
});
</code></pre>

<p>Above is the <code>Q</code> rule with three actions, each action for one alternative production. In fact since the first two actions does noting but just returning the matched string, so they are not necessary. The <code>Q</code> rule with action could be defined as follows:</p>

<pre><code>Q.define(a)
.alt(bc)
.alt(lp, Q, rp).action(new Action() {
    public String act(Object matched) {
        // returns the middle element matched, that's the returned value of the enclosing 'Q' rule
        return (String) ((Object[]) matched)[1];
    }
});
</code></pre>

<p>Leaving only the third action there. The third action, returned the middle element matched of its production(ignored left and right parentheses). The middle element matched is the return value of the recursively enclosing <code>Q</code> rule.</p>

<p>The action for <code>L</code> rule is quite simple and significant: it collects all strings matched and concatenates them into a whole large string, then return the resulting string:</p>

<pre><code>L.define(CC.ks(Q)).action(new Action() {
    public String act(Object matched) {
        Object[] ms = (Object[]) matched;
        StringBuilder sb = new StringBuilder();
        for (Object m : ms)
            sb.append(m);
        return sb.toString();
    }
});// L ::= Q*
</code></pre>

<p>Then the last top-level rule's action: just return the value of <code>L</code> rule, just ignoring EOF:</p>

<pre><code>lang.defineGrule(L, CC.EOF).action(new Action() {
    public String act(Object matched) {
        return (String) ((Object[]) matched)[0];
    }
}); // S ::= L $
</code></pre>

<p>Ok, we can now run the program again and could see it prints out the output: <code>aabc</code>, with all parentheses removed.</p>

<p>The whole program in a gist:<br/>
<div><script src='https://gist.github.com/3257023.js?file='></script>
<noscript><pre><code>package test;

import com.github.pfmiles.dropincc.Action;
import com.github.pfmiles.dropincc.CC;
import com.github.pfmiles.dropincc.Exe;
import com.github.pfmiles.dropincc.Grule;
import com.github.pfmiles.dropincc.Lang;
import com.github.pfmiles.dropincc.TokenDef;

public class Test {

    /**
     * &lt;pre&gt;
     * S ::= L $
     * L ::= Q*
     * Q ::= 'a'
     *     | 'bc'
     *     | '(' Q ')'
     * &lt;/pre&gt;
     */
    public static void main(String... args) throws Throwable {
        Lang lang = new Lang(&quot;Dummy&quot;);
        TokenDef a = lang.newToken(&quot;a&quot;);
        TokenDef bc = lang.newToken(&quot;bc&quot;);
        TokenDef lp = lang.newToken(&quot;\\(&quot;);
        TokenDef rp = lang.newToken(&quot;\\)&quot;);
        Grule L = lang.newGrule();
        Grule Q = lang.newGrule();

        lang.defineGrule(L, CC.EOF).action(new Action() {
            public String act(Object matched) {
                return (String) ((Object[]) matched)[0];
            }
        }); // S ::= L $
        L.define(CC.ks(Q)).action(new Action() {
            public String act(Object matched) {
                Object[] ms = (Object[]) matched;
                StringBuilder sb = new StringBuilder();
                for (Object m : ms)
                    sb.append(m);
                return sb.toString();
            }
        });// L ::= Q*
        /*
         * Q ::= 'a' | 'bc' | '(' Q ')'
         */
        Q.define(a).alt(bc).alt(lp, Q, rp).action(new Action() {
            public String act(Object matched) {
                // returns the middle element matched, that's the returned value
                // of the enclosing 'Q' rule
                return (String) ((Object[]) matched)[1];
            }
        });

        Exe exe = lang.compile();
        System.out.println(exe.eval(&quot;a(a)((bc))&quot;));
    }
}</code></pre></noscript></div>

You can download and play around with it on your own.</p>

<p>Dropincc.java is currently on its very initial stage. It has some major improvements to be done:</p>

<ul>
<li>It uses java's built-in regEx implementation to support token definition, so it couldn't do 'longest match' currently. This should be fixed later.</li>
<li>Due to some LL(*) analysis issues, 'Non-LL regular' exceptions may be thrown when it encounters some special case of grammar rules. This must be fixed soon.</li>
</ul>


<p>There is a more practical <strong>Hello World</strong> example which implements a full-featured calculator in the quick start guide of dropincc.java. On its project <a href="https://github.com/pfmiles/dropincc.java">home page</a>. Go and check out there if you like.</p>

<p>I created a <a href="http://dropincc-java.1068093.n5.nabble.com/">forum</a> for dropincc.java, interested people could discuss about it in the forum. And you are welcomed to subscribe to the mailing list(there's a how to guide in the forum about subscribe to the mailing list).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LL(*)的概念与实现]]></title>
    <link href="http://pfmiles.github.com/blog/concept-and-implementation-of-ll-star"/>
    <updated>2012-07-14T13:59:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/concept-and-implementation-of-ll-star</id>
    <content type="html"><![CDATA[<h3>概念和起源</h3>

<p>LL(*)是由<a href="http://www.cs.usfca.edu/~parrt/">Terrence Parr</a>教授创造的，为使用<a href="http://en.wikipedia.org/wiki/LL_parsing">LL分析</a>的语法解析器做超前查看(look ahead)的一种算法。按照Parr教授的说法，这个算法从最初的想法至今的完善和调整已经历了15年。目前该算法的一个著名的实现在<a href="http://www.antlr.org/">antlr3</a>中。</p>

<h3>特点，n言以蔽之...</h3>

<ul>
<li>对于语法产生式分支的预测判断，走LL分析路子的解析器，其能力完全取决于能超前查看多少个token。传统地讲，LL(1), LL(2)直至LL(k)，就是在讲该解析器能够在语法分析过程中超前查看1, 2, k...个token。</li>
<li>而LL(*)的意思就是，它在语法解析的过程中，超前查看的token个数不是固定的，是可伸缩的，不过这一点LL(k)分析也能做到(在k范围之内...)；</li>
<li>但是，LL(*)还能越过一些重复出现的token，“到达”这些重复出现的token之后的token来做分析，这一点LL(k)是无法办到的(LL(k)无法意识到有token在循环出现，不管情况如何，它都将在尝试k个token之后放弃)；</li>
<li>如果将超前查看的决策逻辑画成DFA的话，就是这样的一种形式：<img src="/images/ll3.png" title="Look Ahead DFA" alt="Look Ahead DFA" />

<ul>
<li>这张图画的是这种语法规则的超前查看决策情况：<code>A ::= a b c | a b e</code>, 显然这是一个LL(3)语法；</li>
<li>但是这样的语法: <code>A ::= a b* c | a b* e</code>是无法被LL(k)识别的，因为中间的<code>b*</code>代表“0个或多个b”(kleene闭包)，这并不是一个固定的重复次数，因此LL(k)无法识别，for any k...</li>
<li>但是，LL(*)算法能够构造出这样的DFA来识别它：<img src="/images/llstar.png" title="LL(*) Look Ahead DFA" alt="LL(*) Look Ahead DFA" /></li>
<li>也就是说，传统LL(k)的look ahead DFA是不带环的，而LL(*)算法能构造出带环的DFA来做判断，它能越过无穷多个存在于环上的token，从而“到达”环之后的token继续做判断。</li>
</ul>
</li>
<li>上面的<code>A ::= a b* c | a b* e</code>语法使用了<a href="/blog/left-recursion-removal-using-kleene-closure/">"kleene闭包"表示法</a>来表示“0个或多个”，这种表示法在正则表达式中很常见；事实上，基于LL(*)算法实现的语法解析器生成器(比如antlr3)对Kleene闭包表示法特别友好，可以鼓励使用，还能顺便解决一些LL分析法所不允许的“<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>”。</li>
<li>大多数情况来讲，LL(*)的识别能力弱于<a href="http://en.wikipedia.org/wiki/LR_parser">LR(k)</a>，但也有少数情况是LR(k)识别不了但LL(*)可以的，所以LL(*)与LR(k)之间并没有严格的强弱顺序。</li>
<li>LL(*)本身对语法的识别能力也是有限的，比如它无法区分"具有相同的递归规则前缀"的多个分支，这种情况是要尽量避免的，大多数能够较容易地改写;</li>
<li>对于LL(*)不能正确分析的情况，还能引入"Semantic Predicate"(语义断言)来辅助判断, Semantic Predicate可以是任何逻辑，只要返回一个bool值就行；有了Semantic Predicate的辅助，LL(*)甚至能够parse一些上下文相关的语法，实际上它能parse C++</li>
</ul>


<h3>主要算法及其实现(python)</h3>

<p><strong> Parr教授在2011年发表的paper"LL(*): The Foundation of the ANTLR Parser Generator"中详细描述了这个算法，下面就是其主要过程，具体的代码实现(python)在工程<a href="https://github.com/pfmiles/llstar">llstar</a>中 </strong></p>

<!-- more -->


<p>为了简单起见，约定大写字母用来命名non-terminal, 小写字母命名terminal或Semantic Predicate，<code>$</code>表示EOF，假设有如下语法规则：</p>

<pre><code>S ::= A $  
A ::= a c*  
    | b c*  
</code></pre>

<ul>
<li>针对此语法规则，构造Augmented Transition Network(ATN)，其实也就是一个NFA，NFA的边就是terminal或non-terminal或者Semantic predicate：<img src="/images/atn.png" alt="ATN network" />, 代码在llstar工程的<code>atn_creation.py</code>的<code>rule.merge_to_atn</code>方法中。</li>
<li>接下来将要对这个ATN实施的算法其实就是经典的<a href="http://en.wikipedia.org/wiki/Powerset_construction">Subset Construction算法</a> —— 的改造版本：在“空边闭包运算(closure)”中加入了压栈、出栈功能，用于处理运算过程中<code>closure</code>函数经过non-terminal边时对其所对应的ATN的调用和返回。<br/>
这个算法的具体描述是比较复杂，在Parr教授的paper中已有精确描述。不过真的要用代码实现起来，某些细节还需稍微修饰，才能正确地实现。<br/>
最后的结果，其实就是使用更改后的版本的Subset Construction算法，将上述ATN(NFA)转化为一个个DFA，每条语法规则都对应一个DFA作为其look ahead DFA。<br/>
例如上面的<code>S</code>规则最后的DFA为：<img src="/images/sdfa.png" alt="S DFA" />, well, 就一个终结态，没任何状态转换 —— 这是当然的，S规则只有一个alternative production... <br/>
而<code>A</code>规则的DFA为：<img src="/images/adfa.png" alt="A DFA" />, 意思就是，如果第一个token为<code>a</code>，就选择第一个分支，若是<code>b</code>，就选择第二个分支，这是一个LL(1)的语法。<br/>
简单来说就是这样，具体可以参考llstar的代码...这花了我不少时间调试出来的代码，还是直接看代码了解最直接:)</li>
</ul>


<h3>实验台及例子介绍</h3>

<p>OK，主要的算法原理了解之后，展示了2个玩具例子，似乎还不能看出LL(*)的特点来。<br/>
下面我将逐步展示一些真正non-trivial的例子，以表明它真的不是过家家...</p>

<p>LL(3)(更正：或许这该是LL(4)可能我数错了)语法(对应llstar工程中的<code>LL_3_many_alts.py</code>):</p>

<pre><code>S ::= A $
A ::= B a*
    | C a+
    | D a?
B ::= a b c C
    | a b c D
    | d
C ::= e f g D
    | e f g h
D ::= i j k l
    | i j k m
</code></pre>

<p>这个语法是固定的LL(3)，没有什么特别，不过分支比较多, 它的ATN：<img src="/images/ll3atn.png" alt="LL(3) ATN" /><br/>
规则<code>A</code>的DFA: <img src="/images/llstar/ll3adfa.png" alt="LL(3) Rule A DFA" /><br/>
规则<code>B</code>的DFA: <img src="/images/llstar/ll3bdfa.png" alt="LL(3) Rule B DFA" /><br/>
规则<code>C</code>的DFA: <img src="/images/llstar/ll3cdfa.png" alt="LL(3) Rule C DFA" /><br/>
规则<code>D</code>的DFA: <img src="/images/llstar/ll3ddfa.png" alt="LL(3) Rule D DFA" /></p>

<p>上面这个语法，LL(4)分析也能搞定，而真正体现出LL(*)特点的是下面这样的语法(对应llstar工程中<code>over_kleene.py</code>)：</p>

<pre><code>S ::= A $
A ::= a* b
    | a+ c
</code></pre>

<p>其中，规则<code>A</code>的2条分支拥有共同的kleene闭包前缀，LL(k)是无法识别的，它的ATN:<img src="/images/llstar/overkleeneatn.png" alt="Over Kleene ATN" /><br/>
而LL(*)能够为<code>A</code>生成这样的DFA：<img src="/images/llstar/overkleeneadfa.png" alt="Over Kleene Rule A DFA" /><br/>
这个DFA能够越过terminal<code>a</code>的任意重复，从而考虑到后面的terminal<code>b</code>和<code>c</code>来做判断<br/>
而下面这个更加"恶劣"的列子则更能说明LL(*)的这个特征(对应llstar工程中<code>over_non_recurse_rule.py</code>)：</p>

<pre><code>S ::= A $
A ::= B* b
    | C+ c
B ::= a d
    | e
C ::= a d
    | e
</code></pre>

<p>这个例子中，<code>B</code>和<code>C</code>完全相同，并分别被包含在规则<code>A</code>的2条分支的kleene闭包中，<br/>
最终生成的<code>A</code>的DFA: <img src="/images/llstar/nonrecursiveradfa.png" alt="Non-recursive Rule A DFA" /></p>

<p>上面提到过，LL(*)也有不能解决的情况，比如2条分支拥有"共同的、递归的规则作为前缀"，比如这样：</p>

<pre><code>S ::= A eof
A ::= E a
    | E b
E ::= c E d
    | e
</code></pre>

<p>上面的<code>A</code>规则的两条分支拥有共同的前缀<code>E</code>，而<code>E</code>本身是一条递归规则，这样的规则是LL(*)无法分析的，在llstar工程中对应<code>experiments/common_recurse_prefix_fail.py</code>, 运行的时候会抛出错误提示。这种情况在antlr3中会将parsing策略退化为LL(1) + 回溯的形式。</p>

<pre><code>Traceback (most recent call last):
  File "/home/pf-miles/myWorkspace/llstar/experiments/common_recurse_prefix_fail.py", line 31, in &lt;module&gt;
    d_a = create_dfa(ra.get_start_state(globals_holder.a_net))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 136, in create_dfa
    d_state_new.add_all_confs(closure(d_state, conf))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 99, in closure
    raise Exception("Likely non-LL regular, recursive alts: " + str(d_state.recursive_alts) + ", rule: " + str(globals_holder.a_net.get_rule_of_state(p)))
Exception: Likely non-LL regular, recursive alts: set([0, 1]), rule: E
</code></pre>

<p>还有一些特殊情况，比如规则完全就是冲突的，那么这个时候就是Semantic Predicate发挥作用的时候(对应llstar工程中<code>conflicting_with_preds.py</code>)：</p>

<pre><code>S ::= A $
A ::= {pred1}? B
    | {pred2}? b
B ::= b
    | b
</code></pre>

<p>最终<code>A</code>的DFA：<img src="/images/llstar/confresolvedwithpredsadfa.png" alt="Conflict Resolved With Preds A DFA" /><br/>
实际开发中，写出这样的规则是坑到爷的...不过LL(*)还算能很好解决...其实这里就算没有Semantic Predicate, LL(*)也能按照convention，“选择较早定义的语法分支”来解决。</p>

<p>还有就是在分析的过程中会导致分析栈溢出(不是程序语言的callstack的overflow, 而是LL(*)的closure操作维护的一个规则调用栈溢出)的时候，LL(*)也会使用Semantic Predicate来辅助判断, 比如规则(对应llstar中<code>overflow_with_preds.py</code>):</p>

<pre><code>S ::= A $
A ::= {pred1?} B a
    | {pred2?} b* c
    | {pred3?} b* c
B ::= b+ B
</code></pre>

<p>规则<code>A</code>的三条分支全部存在严重冲突(都拥有能识别无穷个'b'的前缀)并且其中一个是另一条递归规则<code>B</code>，这种形式会导致LL(*)的分析栈溢出，不过仍然没关系，这样的情况能在溢出发生时，调用<code>pred1</code>、<code>pred2</code>和<code>pred3</code>来解决(这三个pred就是Semantic Precicate，是能包含任何逻辑但最终返回bool值的表达式)<br/>
生成的规则<code>A</code>的DFA: <img src="/images/llstar/overflowadfa.png" alt="Overflow A DFA" /><br/>
这里设定的最大分析递归层数为<code>10</code>，因此，DFA在接受了第10个'b'之后达到了溢出状态<code>d14</code>，这时调用了各个alternative附带的几个predicate来解决冲突...</p>

<h3>总结</h3>

<p>OK, 大概如是了；上述算法的实现、例子的代码均在<a href="https://github.com/pfmiles/llstar">llstar</a>工程中能找到<br/>
llstar工程是我花了不少时间实现并调试好的一块LL(*)算法的“实验台”，可以在里面慢慢把玩各种变态的、五花八门的语法规则，以验证LL(*)的分析能力<br/>
在工程的<code>experiments</code>文件夹下已经有许多具有代表性的例子...都是python代码<br/>
另外，llstar工程是在eclipse + pydev环境下开发的，因此如果要在命令行里运行，可能要对例子里面的import路径稍作修改，当然，最好是直接在eclipse + pydev环境下运行它们了<br/>
在linux环境下，llstar的所有例子都能自动生成上文中看到的各种DFA/NFA图像，不过前提是环境中要装有<a href="http://www.graphviz.org/">graphviz</a></p>

<p>现在的所有语法解析器生成器中，似乎都是LR分析的天下，LL分析大多是手写解析器的首选...<br/>
不过在现有的使用LL分析方式的产品中，也就只有LL(*)和PEG(Packrat)parsing比较常见也比较实用了，能与LR分析一较高下。<br/>
而配上回溯策略的LL(*)是严格强于Packrat parsing的，这样看来大概走LL分析路子的自动化工具也只有LL(*)容易一枝独秀了(想必这也是antlr相对较为流行的原因)。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Kleene闭包语法糖消除语法中的左递归]]></title>
    <link href="http://pfmiles.github.com/blog/left-recursion-removal-using-kleene-closure"/>
    <updated>2012-03-28T11:18:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/left-recursion-removal-using-kleene-closure</id>
    <content type="html"><![CDATA[<p>一般来讲，如果使用的解析器生成器是基于LL分析法来解析文本的话(比如antlr)，我们就需要在编写语法规则的时候避免<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>。<br/>
虽然有一套成熟的、公式化的方法来去除左递归，但它会影响原有文法的结合顺序、优先级，或者多出一些本不需要的、额外的产生式。<br/>
例如，有左递归语法规则：</p>

<pre><code>addition ::= addition '+' factor
           | factor
</code></pre>

<p>这个式子其实是想要表达一个“一连串+号组成的和”的表达式，例如<code>1+2+3+4</code>；<br/>
假设目前的输入就是<code>1+2+3+4</code>, 那么超前查看带来的选择应该是<code>addition '+' factor</code>这个产生式；于是在parser的代码中立刻就又直接调用了<code>addition()</code>方法，但注意，整个递归过程没有消耗掉任何token...也就是说，当流程再次递归到<code>addition</code>函数里时，输入<code>1+2+3+4</code>并没有任何改变，这又会进入下一轮递归...很快就会overflow。<br/>
这个问题，除了机械性地按照公式来消除左递归外，还可以改写语法规则，使其成为右递归语法：</p>

<pre><code>addition ::= factor '+' addition
           | factor
</code></pre>

<p>这样就不用stackOverFlow了，但是带来另一个问题：这使得我们的'+'加法成为了一个'右结合'的运算...<br/>
也就是说，<code>1+2+3+4</code>的计算次序是这样的：<code>1+(2+(3+4))</code><br/>
还好这里是“加法”，整数集合和加法运算构成“阿贝尔群(可交换群)”，满足交换律，所以就算实现成右结合的也能蒙混过关...但减法呢？除法呢？</p>

<!-- more -->


<p>难道要先生成一个AST，再写个visitor，把节点顺序给rewrite一下，然后再写个visitor求值？这么麻烦就为了实现一个简单的四则运算功能也太坑爹了。</p>

<p>其实，我们在这里使用递归，只是为了表达元素的“重复”这种意思；的确，递归能表示“重复”的概念，但这很容易让人联想到“循环”，因为平时的编程中，我们都通常使用循环来表达“重复”这种东西的。<br/>
更重要的是，循环与<a href="http://en.wikipedia.org/wiki/Tail_call">尾递归</a>在逻辑上是等价的，这使得我们可以将上述左递归改写成某种表示“循环”的形式，在这里，<a href="http://en.wikipedia.org/wiki/Kleene_star">Kleene Closure(克林闭包)</a>就正是一种表达“循环”的标记形式。<br/>
熟悉正则表达式的我们都知道，符号<code>*</code>(kleene star)和符号<code>+</code>(kleene cross)分别用来表示前面临接元素的“0个或多个”和“一个或多个”，如果这种标记用在我们的语法规则中那就酷毙了：</p>

<pre><code>addition ::= (factor '+')* factor
</code></pre>

<p>表达的意义和"左递归版本"的语法规则是一样的，但是，这种记法的重大意义就是：在生成的parser程序中可以直接以一个<code>while</code>语句来解析重复的<code>(factor '+')</code>而不用再递归回<code>addition</code>中！这样就避免了parser中的左递归实现带来的问题！<br/>
由于kleene闭包所能表达的所有语法规则形式都能被递归所表达，所以引入kleene闭包并没有从形式上增加语法解析器生成器的表达能力，所以说kleene闭包只是一个“语法糖”。<br/>
但它的实现意义却是重大的：解决了“为了表达‘元素重复’”的这一类左递归问题。
当然，<a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a>也会支持kleene闭包的表达形式，大致的api形式如下：</p>

<pre><code>addition.fillGrammarRule(addend, CC.ks(ADD.or(SUB), addend));
</code></pre>

<p><code>CC.ks</code>方法就是kleene star的意思，当然还有<code>CC.kc</code>，顾名思义。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dropincc.java API design]]></title>
    <link href="http://pfmiles.github.com/blog/dropincc-dot-java-api-design"/>
    <updated>2012-03-18T16:29:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/dropincc-dot-java-api-design</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a>为了使得用户能够在java语言中直接定义新语言的词法、语法规则，API设计采用了串接与组合(cascading &amp; composition)风格的<a href="http://martinfowler.com/bliki/FluentInterface.html">FluentInterface</a>形式。</p>

<p>这种形式能够使得这一套API看起来更具有“业务语义”，而不需要像antlr等其它工具一样强迫用户去学习全新的另外一种含有业务语义的DSL。<br/>
新语言的词法、语法规则被用户直接在java语句里书写、执行，其实得到的是dropincc.java这个CC工具的内部概念的AST。这个AST其实与“让用户学习一套DSL，然后编写，然后编译这些DSL得到的AST”是一样的。<br/>
也就是说 —— dropincc.java里面很重要的一个理念就是：像书写字面量一样书写CC工具的AST(AST literal???)。</p>

<blockquote><p>注意：强调一下这里说的AST并非用户想要实现的新语言的AST，我指的是dropincc.java这个工具其内部表达词法、语法规则的内部形式。</p></blockquote>

<p>经过一些初步的尝试，我认为在java中定义出这样一套API是完全可行的，其中一些值得列出的、具有代表性的点如下：</p>

<!-- more -->


<ol>
<li>词法规则强制用户限定在正则文法的表达能力之内(即使用正则表达式，例子略)</li>
<li>上下文无关文法的表示主要是解决3种形式的表示：连接、选择、递归;

<ol>
<li>其中“连接”的表示, 若BNF为：<code>term ::= LEFTPAREN expr RIGHTPAREN</code>, 则右边的部分在java中表达为：<code>func(LEFTPAREN, expr, RIGHTPAREN)</code>;即：“以方法传参的自然按顺序排列表达‘连接’的意思”;而其中<code>expr</code>是一个non-terminal，也就是说这里要引用<code>expr</code>这个规则，这也就表达了“递归” —— 要递归地引用<code>expr</code>的话那么直接写在这里就好了；</li>
<li>“选择”的表示，即一个产生式有好几个alternative的情况，若BNF是<code>term ::= DIGIT multail | LEFTPAREN expr RIGHTPAREN | DIGIT;</code>, 则java中表达为：<code>func(DIGIT, mulTail).alt(LEFTPAREN, expr, RIGHTPAREN).alt(DIGIT);</code>。</li>
</ol>
</li>
<li>上述3种基本元素的表达具备之后，其实已经足够表达出复杂的语法了，不过为了“更好的体验”，为了用得更方便，我认为还应该加入“子rule语法糖”。即让使用者能够以“加括号”的方式在产生式中直接定义子规则，而不必每次都单独写成一个产生式，这种做法应该能很受欢迎，比如：

<ul>
<li>第一个产生式是：<code>MUL_DIV ::= MUL | DIV;</code></li>
<li>第二个产生式是：<code>mulTail ::= MUL_DIV term;</code></li>
<li>其实，若是有了前面说的语法糖，那么上述2个产生式就可以合并为：<code>mulTail ::= (MUL | DIV) term;</code>, 少了<code>MUL_DIV</code>这个没太多意义的产生式定义；</li>
<li>在java中表达为：<code>func(MUL.or(DIV), term)</code>; 若子规则中想表达的不是“选择”关系，而是“连接”关系的话，也就是<code>mulTail ::= (MUL DIV) term;</code>的话，在java中表达为：<code>func(MUL.and(DIV), term)</code>; 其中<code>and</code>这个方法就是表达“连接”关系，只不过加了括号，成为了一个子规则而已。</li>
</ul>
</li>
</ol>


<p>OK, dropincc.java的核心FluentInterface形式的API应该就这些了，我相信这是一种很自然的方式，用户需要掌握的东西很少。</p>

<h3>设计FluentInterface风格API过程中的经验总结</h3>

<p>对于这个接口设计，我的经验就是：</p>

<ol>
<li>传入参数尽量“泛化”、“统一接口化”;这个“统一接口”最好不要包含任何方法(也就是说只是一个标记接口)，否则会给FluentInterface带来一些令人困惑的方法选项(当用户敲入'.'操作符的时候将会在IDE工具的方法提示里多出很多不必要的方法)。</li>
<li>每个串接方法的返回结果可以随意“具体化”，因为这个返回结果的具体类名是不必展示给用户看的，所以你打算让用户下一步还能串接出什么样的方法，就尽管去返回一个具体的子类；但要注意返回结果不应该有太深的继承层次，否则“下一步串接”(当用户敲入'.'操作符的时候)将会在IDE工具里列出令人困惑的方法列表 —— 一般就一层继承关系 —— 继承自Object —— 一个接口实现 —— 就是1中所述的“泛化接口”，这样做方便你将返回值继续传入另一个方法中 —— 实现为所欲为的cascading &amp; composition...</li>
</ol>


<h3>以闭包的形式嵌入动作代码</h3>

<p>几乎所有的CC工具都提供一种“在match到特定的节点或树模式时允许执行一段用户自定义代码”的功能；这种自定义代码我把它叫做“动作代码”, “action”。无论是lex &amp; yacc或是antlr都是这样。<br/>
这个功能几乎是必须的，这提供了一种自由度相当高的形式让用户可以自定义AST节点，或是直接在parse的过程当中做一些自定义的计算，然后当整个parse结束时直接输出的就是整个的计算结果。<br/>
动作代码一般来讲，都是用该CC工具所要生成的程序所使用的语言来写的；比如lex要生成C代码，他们的动作代码就是C来写的；antlr要生成java代码，那么它的动作代码自然就是java写的（当然antlr也能生成其它语言代码，相对应的，就使用那种语言来编写动作代码）。
dropincc.java既然设计目标是要嵌入到java语言中去使用，自然就是要用java语言来写动作代码了；<br/>
但是，跟lex &amp; yacc或者antlr不同的是，我并不打算让用户写一些残缺不全的动作代码放在某个约定的位置然后在生成目标程序的过程中将它们“编织”到目标程序中，这样的话就跟传统的CC工具没有任何区别了，没有什么实质上的改进；<br/>
既然dropincc.java是“嵌入”到普通的java应用程序代码中间工作的，那么它完全有理由使用“闭包(closure)”的形式来组织“动作代码”！为什么用“闭包”？因为dropincc.java是“嵌入”到业务代码中使用的，用闭包来写动作代码可以capture一些业务代码上下文信息，这对构建DSL来讲是非常大的便利！<br/>
比如，你的业务代码上下文里面有个<code>OrderService</code>对象，它负责一些"订单"业务逻辑，而当你编写一个闭包作为动作代码的时候，你完全可以"capture"上下文中的这个<code>OrderService</code>对象，从而使得你创造的语言在执行逻辑上与订单业务紧密、无缝地结合 —— 这是一种非常平滑的构建DSL的方式。</p>

<h3>最终的样子</h3>

<blockquote><p>注：此段代码只代表示意的风格、API情况，虽然能编译通过、运行，但不一定是行为完全正确四则运算表达式计算器</p></blockquote>

<pre><code>// 3.define lexical rules
Lang calculator = new Lang();
Token DIGIT = calculator.addToken("\\d+");
Token ADD = calculator.addToken("\\+");
Token SUB = calculator.addToken("\\-");
Token MUL = calculator.addToken("\\*");
Token DIV = calculator.addToken("/");
Token LEFTPAREN = calculator.addToken("\\(");
Token RIGHTPAREN = calculator.addToken("\\)");
// 2.define grammar rules and corresponding actions
Grule expr = new Grule();
Grule term = new Grule();
Element mulTail = calculator.addGrammarRule(MUL.or(DIV), term).action(
        new Action() {
            public Object act(Object... params) {
                return params;
            }
        });
term.fillGrammarRule(DIGIT, mulTail).action(new Action() {
    public Object act(Object... params) {
        int factor = Integer.parseInt((String) params[0]);
        Object[] mulTailReturn = (Object[]) params[1];
        String op = (String) mulTailReturn[0];
        int factor2 = (Integer) mulTailReturn[1];
        if ("*".equals(op)) {
            return factor * factor2;
        } else if ("/".equals(op)) {
            return factor / factor2;
        } else {
            throw new RuntimeException("Unsupported operator: " + op);
        }
    }
}).alt(LEFTPAREN, expr, RIGHTPAREN).action(new Action() {
    public Object act(Object... params) {
        return params[1];
    }
}).alt(DIGIT).action(new Action() {
    public Object act(Object... params) {
        return Integer.parseInt((String) params[0]);
    }
});
Element addendTail = calculator.addGrammarRule(ADD.or(SUB), term)
        .action(new Action() {
            public Object act(Object... params) {
                return params;
            }
        });
expr.fillGrammarRule(term, addendTail, CC.EOF).action(new Action() {
    public Object act(Object... params) {
        int addend = (Integer) params[0];
        Object[] addendTailReturn = (Object[]) params[1];
        String op = (String) addendTailReturn[0];
        int addend2 = (Integer) addendTailReturn[1];
        if ("+".equals(op)) {
            return addend + addend2;
        } else if ("-".equals(op)) {
            return addend - addend2;
        } else {
            throw new RuntimeException("Unsupported operator: " + op);
        }
    }
});
// 1.compile it!
calculator.compile();
// 0.FIRE!!!
System.out.println(calculator.exe("1+2+3+(4+5*6*7*(64/8/2/(2/1)/1)*8+9)+10"));
</code></pre>

<p>上面约60行java代码实现了一个相当复杂的多项式计算器语言：支持加减乘除四则运算以及括号调整优先级。而以往我们使用antlr来实现这个功能的话，最终生成、放到项目中工作的java代码会以千行计。</p>

<ul>
<li>这段代码是能够完全嵌入到任何普通的java业务系统程序代码当中的，是完全语法合格、能编译通过的，这是与传统CC工具的“代码残片”表示的动作代码所不同的地方</li>
<li>其中用到了上面介绍的“以正则语言来定义词法规则”、“以FluentInterfaces来定义语法规则”，以及“以闭包的形式来书写动作代码”（java中的闭包以“匿名内部类”的形式表示，道理一样）</li>
<li>其中，动作代码是一段段由<code>Action</code>接口实现的闭包（匿名内部类），里面的代码显然可以随意引用当前上下文中的所有变量、对象，这样实现了对上下文的capture，跟业务系统的无缝结合。</li>
<li><code>Action</code>闭包带有一个方法，参数是<code>Object... params</code>，这个参数里的值以位置顺序的方式对应于该action代码所附着的产生式里面的语法元素在parsing的时候所match到的值，听起来比较绕口，但实际上很简单，比如上面的 :</li>
</ul>


<p>带括号的表达式的action:</p>

<pre><code>.alt(LEFTPAREN, expr, RIGHTPAREN).action(new Action() {
    public Object act(Object... params) {
        return params[1];
    }
</code></pre>

<p>它的<code>params</code>的长度为3，分别是<code>["(", expr子规则匹配所返回的值, ")"]</code>，而这里我们的“业务(四则运算)”只需要关心<code>expr</code>的返回值，所以动作代码直接将<code>params[1]</code>（expr的返回值）返回给上一级匹配。<br/>
就是这样，实际上你可以在动作代码里面做任何事情，只要符合java语法的、你能想到的。</p>

<p>第一个版本的API设计基本就是这样了，往后可能还会加入一些语法糖，比如“Kleen闭包”来进一步方便语法规则的定义，不过会很慎重，因为dropincc.java是以小巧、易用为设计目标的，语法糖太多很可能会帮倒忙。</p>
]]></content>
  </entry>
  
</feed>
