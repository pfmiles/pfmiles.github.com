<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: algorithm | Meta-Interpretation]]></title>
  <link href="http://pfmiles.github.com/blog/category/algorithm/atom.xml" rel="self"/>
  <link href="http://pfmiles.github.com/"/>
  <updated>2013-08-30T14:11:08+08:00</updated>
  <id>http://pfmiles.github.com/</id>
  <author>
    <name><![CDATA[pf_miles]]></name>
    <email><![CDATA[miles.wy.1@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[LL(*)的概念与实现]]></title>
    <link href="http://pfmiles.github.com/blog/concept-and-implementation-of-ll-star"/>
    <updated>2012-07-14T13:59:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/concept-and-implementation-of-ll-star</id>
    <content type="html"><![CDATA[<h3>概念和起源</h3>

<p>LL(*)是由<a href="http://www.cs.usfca.edu/~parrt/">Terrence Parr</a>教授创造的，为使用<a href="http://en.wikipedia.org/wiki/LL_parsing">LL分析</a>的语法解析器做超前查看(look ahead)的一种算法。按照Parr教授的说法，这个算法从最初的想法至今的完善和调整已经历了15年。目前该算法的一个著名的实现在<a href="http://www.antlr.org/">antlr3</a>中。</p>

<h3>特点，n言以蔽之...</h3>

<ul>
<li>对于语法产生式分支的预测判断，走LL分析路子的解析器，其能力完全取决于能超前查看多少个token。传统地讲，LL(1), LL(2)直至LL(k)，就是在讲该解析器能够在语法分析过程中超前查看1, 2, k...个token。</li>
<li>而LL(*)的意思就是，它在语法解析的过程中，超前查看的token个数不是固定的，是可伸缩的，不过这一点LL(k)分析也能做到(在k范围之内...)；</li>
<li>但是，LL(*)还能越过一些重复出现的token，“到达”这些重复出现的token之后的token来做分析，这一点LL(k)是无法办到的(LL(k)无法意识到有token在循环出现，不管情况如何，它都将在尝试k个token之后放弃)；</li>
<li>如果将超前查看的决策逻辑画成DFA的话，就是这样的一种形式：<img src="/images/ll3.png" title="Look Ahead DFA" alt="Look Ahead DFA" />

<ul>
<li>这张图画的是这种语法规则的超前查看决策情况：<code>A ::= a b c | a b e</code>, 显然这是一个LL(3)语法；</li>
<li>但是这样的语法: <code>A ::= a b* c | a b* e</code>是无法被LL(k)识别的，因为中间的<code>b*</code>代表“0个或多个b”(kleene闭包)，这并不是一个固定的重复次数，因此LL(k)无法识别，for any k...</li>
<li>但是，LL(*)算法能够构造出这样的DFA来识别它：<img src="/images/llstar.png" title="LL(*) Look Ahead DFA" alt="LL(*) Look Ahead DFA" /></li>
<li>也就是说，传统LL(k)的look ahead DFA是不带环的，而LL(*)算法能构造出带环的DFA来做判断，它能越过无穷多个存在于环上的token，从而“到达”环之后的token继续做判断。</li>
</ul>
</li>
<li>上面的<code>A ::= a b* c | a b* e</code>语法使用了<a href="/blog/left-recursion-removal-using-kleene-closure/">"kleene闭包"表示法</a>来表示“0个或多个”，这种表示法在正则表达式中很常见；事实上，基于LL(*)算法实现的语法解析器生成器(比如antlr3)对Kleene闭包表示法特别友好，可以鼓励使用，还能顺便解决一些LL分析法所不允许的“<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>”。</li>
<li>大多数情况来讲，LL(*)的识别能力弱于<a href="http://en.wikipedia.org/wiki/LR_parser">LR(k)</a>，但也有少数情况是LR(k)识别不了但LL(*)可以的，所以LL(*)与LR(k)之间并没有严格的强弱顺序。</li>
<li>LL(*)本身对语法的识别能力也是有限的，比如它无法区分"具有相同的递归规则前缀"的多个分支，这种情况是要尽量避免的，大多数能够较容易地改写;</li>
<li>对于LL(*)不能正确分析的情况，还能引入"Semantic Predicate"(语义断言)来辅助判断, Semantic Predicate可以是任何逻辑，只要返回一个bool值就行；有了Semantic Predicate的辅助，LL(*)甚至能够parse一些上下文相关的语法，实际上它能parse C++</li>
</ul>


<h3>主要算法及其实现(python)</h3>

<p><strong> Parr教授在2011年发表的paper"LL(*): The Foundation of the ANTLR Parser Generator"中详细描述了这个算法，下面就是其主要过程，具体的代码实现(python)在工程<a href="https://github.com/pfmiles/llstar">llstar</a>中 </strong></p>

<!-- more -->


<p>为了简单起见，约定大写字母用来命名non-terminal, 小写字母命名terminal或Semantic Predicate，<code>$</code>表示EOF，假设有如下语法规则：</p>

<pre><code>S ::= A $  
A ::= a c*  
    | b c*  
</code></pre>

<ul>
<li>针对此语法规则，构造Augmented Transition Network(ATN)，其实也就是一个NFA，NFA的边就是terminal或non-terminal或者Semantic predicate：<img src="/images/atn.png" alt="ATN network" />, 代码在llstar工程的<code>atn_creation.py</code>的<code>rule.merge_to_atn</code>方法中。</li>
<li>接下来将要对这个ATN实施的算法其实就是经典的<a href="http://en.wikipedia.org/wiki/Powerset_construction">Subset Construction算法</a> —— 的改造版本：在“空边闭包运算(closure)”中加入了压栈、出栈功能，用于处理运算过程中<code>closure</code>函数经过non-terminal边时对其所对应的ATN的调用和返回。<br/>
这个算法的具体描述是比较复杂，在Parr教授的paper中已有精确描述。不过真的要用代码实现起来，某些细节还需稍微修饰，才能正确地实现。<br/>
最后的结果，其实就是使用更改后的版本的Subset Construction算法，将上述ATN(NFA)转化为一个个DFA，每条语法规则都对应一个DFA作为其look ahead DFA。<br/>
例如上面的<code>S</code>规则最后的DFA为：<img src="/images/sdfa.png" alt="S DFA" />, well, 就一个终结态，没任何状态转换 —— 这是当然的，S规则只有一个alternative production... <br/>
而<code>A</code>规则的DFA为：<img src="/images/adfa.png" alt="A DFA" />, 意思就是，如果第一个token为<code>a</code>，就选择第一个分支，若是<code>b</code>，就选择第二个分支，这是一个LL(1)的语法。<br/>
简单来说就是这样，具体可以参考llstar的代码...这花了我不少时间调试出来的代码，还是直接看代码了解最直接:)</li>
</ul>


<h3>实验台及例子介绍</h3>

<p>OK，主要的算法原理了解之后，展示了2个玩具例子，似乎还不能看出LL(*)的特点来。<br/>
下面我将逐步展示一些真正non-trivial的例子，以表明它真的不是过家家...</p>

<p>LL(3)(更正：或许这该是LL(4)可能我数错了)语法(对应llstar工程中的<code>LL_3_many_alts.py</code>):</p>

<pre><code>S ::= A $
A ::= B a*
    | C a+
    | D a?
B ::= a b c C
    | a b c D
    | d
C ::= e f g D
    | e f g h
D ::= i j k l
    | i j k m
</code></pre>

<p>这个语法是固定的LL(3)，没有什么特别，不过分支比较多, 它的ATN：<img src="/images/ll3atn.png" alt="LL(3) ATN" /><br/>
规则<code>A</code>的DFA: <img src="/images/llstar/ll3adfa.png" alt="LL(3) Rule A DFA" /><br/>
规则<code>B</code>的DFA: <img src="/images/llstar/ll3bdfa.png" alt="LL(3) Rule B DFA" /><br/>
规则<code>C</code>的DFA: <img src="/images/llstar/ll3cdfa.png" alt="LL(3) Rule C DFA" /><br/>
规则<code>D</code>的DFA: <img src="/images/llstar/ll3ddfa.png" alt="LL(3) Rule D DFA" /></p>

<p>上面这个语法，LL(4)分析也能搞定，而真正体现出LL(*)特点的是下面这样的语法(对应llstar工程中<code>over_kleene.py</code>)：</p>

<pre><code>S ::= A $
A ::= a* b
    | a+ c
</code></pre>

<p>其中，规则<code>A</code>的2条分支拥有共同的kleene闭包前缀，LL(k)是无法识别的，它的ATN:<img src="/images/llstar/overkleeneatn.png" alt="Over Kleene ATN" /><br/>
而LL(*)能够为<code>A</code>生成这样的DFA：<img src="/images/llstar/overkleeneadfa.png" alt="Over Kleene Rule A DFA" /><br/>
这个DFA能够越过terminal<code>a</code>的任意重复，从而考虑到后面的terminal<code>b</code>和<code>c</code>来做判断<br/>
而下面这个更加"恶劣"的列子则更能说明LL(*)的这个特征(对应llstar工程中<code>over_non_recurse_rule.py</code>)：</p>

<pre><code>S ::= A $
A ::= B* b
    | C+ c
B ::= a d
    | e
C ::= a d
    | e
</code></pre>

<p>这个例子中，<code>B</code>和<code>C</code>完全相同，并分别被包含在规则<code>A</code>的2条分支的kleene闭包中，<br/>
最终生成的<code>A</code>的DFA: <img src="/images/llstar/nonrecursiveradfa.png" alt="Non-recursive Rule A DFA" /></p>

<p>上面提到过，LL(*)也有不能解决的情况，比如2条分支拥有"共同的、递归的规则作为前缀"，比如这样：</p>

<pre><code>S ::= A eof
A ::= E a
    | E b
E ::= c E d
    | e
</code></pre>

<p>上面的<code>A</code>规则的两条分支拥有共同的前缀<code>E</code>，而<code>E</code>本身是一条递归规则，这样的规则是LL(*)无法分析的，在llstar工程中对应<code>experiments/common_recurse_prefix_fail.py</code>, 运行的时候会抛出错误提示。这种情况在antlr3中会将parsing策略退化为LL(1) + 回溯的形式。</p>

<pre><code>Traceback (most recent call last):
  File "/home/pf-miles/myWorkspace/llstar/experiments/common_recurse_prefix_fail.py", line 31, in &lt;module&gt;
    d_a = create_dfa(ra.get_start_state(globals_holder.a_net))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 136, in create_dfa
    d_state_new.add_all_confs(closure(d_state, conf))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 99, in closure
    raise Exception("Likely non-LL regular, recursive alts: " + str(d_state.recursive_alts) + ", rule: " + str(globals_holder.a_net.get_rule_of_state(p)))
Exception: Likely non-LL regular, recursive alts: set([0, 1]), rule: E
</code></pre>

<p>还有一些特殊情况，比如规则完全就是冲突的，那么这个时候就是Semantic Predicate发挥作用的时候(对应llstar工程中<code>conflicting_with_preds.py</code>)：</p>

<pre><code>S ::= A $
A ::= {pred1}? B
    | {pred2}? b
B ::= b
    | b
</code></pre>

<p>最终<code>A</code>的DFA：<img src="/images/llstar/confresolvedwithpredsadfa.png" alt="Conflict Resolved With Preds A DFA" /><br/>
实际开发中，写出这样的规则是坑到爷的...不过LL(*)还算能很好解决...其实这里就算没有Semantic Predicate, LL(*)也能按照convention，“选择较早定义的语法分支”来解决。</p>

<p>还有就是在分析的过程中会导致分析栈溢出(不是程序语言的callstack的overflow, 而是LL(*)的closure操作维护的一个规则调用栈溢出)的时候，LL(*)也会使用Semantic Predicate来辅助判断, 比如规则(对应llstar中<code>overflow_with_preds.py</code>):</p>

<pre><code>S ::= A $
A ::= {pred1?} B a
    | {pred2?} b* c
    | {pred3?} b* c
B ::= b+ B
</code></pre>

<p>规则<code>A</code>的三条分支全部存在严重冲突(都拥有能识别无穷个'b'的前缀)并且其中一个是另一条递归规则<code>B</code>，这种形式会导致LL(*)的分析栈溢出，不过仍然没关系，这样的情况能在溢出发生时，调用<code>pred1</code>、<code>pred2</code>和<code>pred3</code>来解决(这三个pred就是Semantic Precicate，是能包含任何逻辑但最终返回bool值的表达式)<br/>
生成的规则<code>A</code>的DFA: <img src="/images/llstar/overflowadfa.png" alt="Overflow A DFA" /><br/>
这里设定的最大分析递归层数为<code>10</code>，因此，DFA在接受了第10个'b'之后达到了溢出状态<code>d14</code>，这时调用了各个alternative附带的几个predicate来解决冲突...</p>

<blockquote><p>(2012-09-03 注： 实际上上述规则是不正确的，<code>B ::= b+ B</code>是有问题的规则，因为<code>b+</code>会贪婪地match掉所有的连续的<code>'b'</code>，导致后面的<code>B</code>只可能抛错; 所以这个例子也只能用来演示分析栈溢出的情况，实际应用中是不可能写出这样的规则的)</p></blockquote>

<h3>总结</h3>

<p>OK, 大概如是了；上述算法的实现、例子的代码均在<a href="https://github.com/pfmiles/llstar">llstar</a>工程中能找到<br/>
llstar工程是我花了不少时间实现并调试好的一块LL(*)算法的“实验台”，可以在里面慢慢把玩各种变态的、五花八门的语法规则，以验证LL(*)的分析能力<br/>
在工程的<code>experiments</code>文件夹下已经有许多具有代表性的例子...都是python代码<br/>
另外，llstar工程是在eclipse + pydev环境下开发的，因此如果要在命令行里运行，可能要对例子里面的import路径稍作修改，当然，最好是直接在eclipse + pydev环境下运行它们了<br/>
在linux环境下，llstar的所有例子都能自动生成上文中看到的各种DFA/NFA图像，不过前提是环境中要装有<a href="http://www.graphviz.org/">graphviz</a></p>

<p>现在的所有语法解析器生成器中，似乎都是LR分析的天下，LL分析大多是手写解析器的首选...<br/>
不过在现有的使用LL分析方式的产品中，也就只有LL(*)和PEG(Packrat)parsing比较常见也比较实用了，能与LR分析一较高下。<br/>
而配上回溯策略的LL(*)是严格强于Packrat parsing的，这样看来大概走LL分析路子的自动化工具也只有LL(*)容易一枝独秀了(想必这也是antlr相对较为流行的原因)。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Algo-class第二周小记: Master Method]]></title>
    <link href="http://pfmiles.github.com/blog/algo-class-week2-notes-master-method"/>
    <updated>2012-04-03T11:40:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/algo-class-week2-notes-master-method</id>
    <content type="html"><![CDATA[<p>week2主要讲了master method，感觉从来没有听过如此清晰有条理的介绍master method的讲解，不得不佩服<a href="http://theory.stanford.edu/~tim/">Tim Roughgarden</a>教授的功力。<br/>
从一些随课笔记总结起来，master method是用来预估divide and conquer算法的大O时间复杂度的公式；它要求divide的时候“所有sub-problems的规模都相等”才能适用。<br/>
要使用master method, 首先要将算法的时间消耗函数写成递推公式形式：
$$T(n) &lt;= aT(\frac{n}{b}) + O(n^d)$$
其中T(n)是本层递归所消耗的时间，$T(\frac{n}{b})$自然就是下一层递归所消耗的时间了，b就是每次往“下层”递归调用时问题规模缩小的倍率，a就是代码中递归调用的个数；$O(n^d)$ 是将递归调用之外的其它代码的时间开销写成关于输入规模n的指数形式，d就是这个指数。<br/>
基础情况： 当n足够小时，T(n) &lt;= 一个常数<br/>
a,b,d与输入规模无关。<br/>
那么，根据a,b,d的情况，T(n)可能被表示为三种情况：<br/>
<img src="/images/masterMethod.png" title="Master Method" alt="Master Method" /></p>

<!-- more -->


<p>对于这个式子，我个人的、不严格的、直觉的理解就是：</p>

<ol>
<li>当$a = b^d$时，程序规模被divide之后，合并代价增大的幅度与程序规模缩小的幅度相当，所以复杂度公式中合并代价部分和切分、解决部分的复杂度都要算在里面</li>
<li>当$a &lt; b^d$时，合并代价增长快于切分、解决缩小幅度，所以复杂度公式中只算合并代价部分</li>
<li>当$a > b^d$时，切分、解决部分时间代价占主导，忽略递归调用以外的项，只写出divide and conquer递归调用部分的时间开销</li>
</ol>


<p>不过其实这个是有严格的证明的：<br/>
设$T(n) = aT(\frac{n}{b}) + cn^d$<br/>
对于第j层递归 ，运算量为：$a^j \times c \times (\frac{n}{b^j})^d$<br/>
即：$cn^d(\frac{a}{b^d})^j$，所以a和$b^d$的大小关系是关键！<br/>
进而总计算时间： $total work \leqslant cn^d \centerdot \sum\limits_{j=0}^{\log_bn}(\frac{a}{b^d})^j$, 然后通过这个式子，由a和$b^d$的大小关系可以较容易想通为什么master method会是上述这种三段分段函数的形式。<br/>
Week2作业是快排...写个快排倒是简单，可是作业要求要count快排过程中的比较次数...在作业论坛里面看到哀嚎声一片...毕竟实现只要稍微有点偏差，虽然同样是快排，确实很容易比较次数不一样。<br/>
值得一提的是讲解中给出的in-place的快排partition方法，就是不用建立额外的数组来进行partition，python示意代码如下：</p>

<pre><code>def partition(pivotIndex, arr):
    swap(arr, 0, pivotIndex)
    pivot = arr[0]
    i = 1 # index 0...i &lt; pivot
    j = 1 # index i...j &gt; pivot
    for k in range(1, len(arr)):
    if arr[k] &lt;= pivot :
        swap(arr, i, k)
        i += 1
        j += 1
    else:
        j += 1
    return (arr[1:i], pivot, arr[i:j])
</code></pre>

<p>另外，从快排的例子可以看出，若divide and conquer算法是基于某种比较结果，将问题规模初步divide and conquer的话，每一次比较“能否将问题划分为规模差不多均等的子问题”将很大地影响算法实际的执行效率。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[algo-class]第一周作业——Count Inversions]]></title>
    <link href="http://pfmiles.github.com/blog/algo-class-week-one-assignment-counting-inversions"/>
    <updated>2012-03-25T15:41:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/algo-class-week-one-assignment-counting-inversions</id>
    <content type="html"><![CDATA[<p><a href="http://algo-class.org">algo-class</a>还是挺有意思的，一上来就讲merge sort；介绍了分治法以及"piggyback"的思路...当作是复习吧：</p>

<h3>分治法(divide and conquer)</h3>

<ol>
<li>divide into smaller problems</li>
<li>conquer sub-problems recursively</li>
<li>combine solutions of problems into one for the original problems</li>
</ol>


<p>而"piggyback"的意思就是：记住一些经典算法的实现，遇到类似问题的时候，可以将要解决的问题“搭载”到那些经典算法上面，一般都具有和那些经典算法相同的平均时间复杂度；相当于是把那些经典算法当作一个个“模式”或者“骨架”了(所以说平时经常听到的经典算法还是要熟悉熟悉的，很多地方能派上用场)。</p>

<p>这一周围绕merge sort来讲divide and conquer真是再合适不过了；而作业“Count Inversions”就是一个将场景piggyback到merge sort上的一个典型例子；  作业给出了一个包含10W行数据的文本文件，每一行一个随机数字，要求找出这10W个数字中的所有Inversions。我用python实现如下：</p>

<pre><code>def countInversions(arr):
    length = len(arr)
    if length == 0 or length == 1:
    return (0, arr) 
    mid = int(length / 2)
    (leftCount, leftSortedArr) = countInversions(arr[0:mid])
    (rightCount, rightSortedArr) = countInversions(arr[mid:length])
    (mergedCount, mergedSortedArr) = mergeCount(leftSortedArr, rightSortedArr)
    return (leftCount + rightCount + mergedCount, mergedSortedArr)

def mergeCount(lArr, rArr):
    count = 0
    mergedArr = []
    i = 0
    j = 0
    lenl = len(lArr)
    lenr = len(rArr)
    while i &lt; lenl and j &lt; lenr:
    if lArr[i] &gt; rArr[j]:
        count += lenl - i # key line
        mergedArr.append(rArr[j])
        j += 1
    else:
        mergedArr.append(lArr[i])
        i += 1
    if i &lt; lenl:
    mergedArr.extend(lArr[i:lenl])

    if j &lt; lenr:
    mergedArr.extend(rArr[j:lenr])
    return (count, mergedArr)

import sys
if len(sys.argv) &lt; 2:
    print 'usage: python countInversionInAFile path_to_file'
    exit(1)
numbers = [int(line) for line in open(sys.argv[1], 'r')]
print countInversions(numbers)[0]
</code></pre>

<p>程序或许想起来简单但实际上要正确还是要费点功夫的；有些地方没想到的还非得debug才能看清楚为什么，比如程序中标注为"key line"那里，本来我写的是<code>count += 1</code>的但怎么都不对，后来debug才看出来应该写<code>count += lenl - i</code>。</p>

<p>另外，本来打算跟2门课程的，但现在看来我这忙碌的程序员完全没有时间...只好放弃“机器人汽车”那门课目前专门跟这一门了，毕竟“算法”的可操作性要强一些...</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[面试中的算法]编程判断两个链表是否相交]]></title>
    <link href="http://pfmiles.github.com/blog/algorithms-in-job-interview-test-if-two-linked-lists-intersected"/>
    <updated>2012-03-06T23:30:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/algorithms-in-job-interview-test-if-two-linked-lists-intersected</id>
    <content type="html"><![CDATA[<p>这是一道广为流传的题目: <a href="http://bop1.wikispaces.com/%E7%AC%AC%E4%B8%89%E7%AB%A0+%E7%BB%93%E6%9E%84%E4%B9%8B%E6%B3%95#x-%E7%AC%AC3%E7%AB%A0%20%E7%BB%93%E6%9E%84%E4%B9%8B%E6%B3%95%E2%80%94%E2%80%94%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8F%8A%E9%93%BE%E8%A1%A8%E7%9A%84%E6%8E%A2%E7%B4%A2-3.6%E7%BC%96%E7%A8%8B%E5%88%A4%E6%96%AD%E4%B8%A4%E4%B8%AA%E9%93%BE%E8%A1%A8%E6%98%AF%E5%90%A6%E7%9B%B8%E4%BA%A4">编程判断两个链表是否相交</a>;原题假设“不带环”，所以只要想通了之后很简单；但是，若要考虑带环的情况，那么要注意的点就很多了。
其实可以把无环和有环的情况全都包括在一个方法实现内解决。</p>

<h3>分析</h3>

<p>首先，无环的情况；无环是《编程之美》原书里的题目，很多人都反应说这个题相对书中其它题来讲太过于简单了。也确实，只要在纸上把“所有单向链表相交的情况”画出来很容易就能想通解法了（只要正确理解题意，那么“两个无环单向链表”画出来只可能是2条不相干的链表或一个"Y"字形） —— 所以，判断两个不带环的链表是否相交，只要将两个链表的头指针都移到链表尾，然后比较尾指针地址是否相等就可以了。
如果带环，个人总结，要明白以下几点：</p>

<ol>
<li>无环链表和有环链表是不可能相交的;</li>
<li>两个有环链表若相交，其“整个环上”的所有node一定都重合;</li>
<li>有环链表的相交，情况只有2种：相交于"环上"或相交于"不是环的部分",即下图所示;两种情况都需要使用“两个指针的追逐”方法来判断两个链表的环部分是否相交;
<img src="/images/circledLinkedListsIntersections.png" title="带环单向链表相交只有2种情况" alt="带环单向链表相交只有2种情况" /></li>
<li>有关链表追逐的考虑: 相对速度、距离、时间要算好，否则很容易漏掉几种边界情况;</li>
</ol>


<!-- more -->


<h3>代码</h3>

<pre><code>#include &lt;stdio.h&gt;

// define the node struct of links
typedef struct Node {
    struct Node* next;
} Node;

int is_intersected(Node* p1, Node* p2);

Node* has_circle(Node* head);

int main(int args, char** argv) {
    Node end1 = { NULL };
    Node end2 = { NULL };
    // 定义几种链表情况
    // two links not intersect with each other, no circle
    Node link_1_n =
            {
                    &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;end1}}}}}}}}};
    Node link_2_n =
            {
                    &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;end2}}}}}}}}};

    // two links intersect with each other, no circle
    Node common_n = { &amp;(Node) {&amp;(Node) {&amp;end1}}};

    Node link_1_y = { &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;common_n}}}}}};
    Node link_2_y = { &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;common_n}}}}}};

    // two links, has circle, not intersected.
    Node circle1 = { &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;circle1}}}}};
    Node link_c1_n = { &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;circle1}}}}};

    Node circle2 = { &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;circle2}}}}};
    Node link_c2_n = { &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;circle2}}}}};

    // two links, has circle, intersected at a non-circle position
    Node common_c = { &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;common_c}}}}};
    Node common_part = { &amp;(Node) {&amp;common_c}};

    Node link_c1_y = { &amp;(Node) {&amp;(Node) {&amp;common_part}}};
    Node link_c2_y = { &amp;(Node) {&amp;(Node) {&amp;common_part}}};
    // two links, has common circle, but different 'joint-points'.

    Node jp1 = { NULL };
    Node jp2 = { NULL };
    // 'weave' the joint-points into a circle:
    jp1.next = &amp;(Node) {&amp;(Node) {&amp;jp2}};
    jp2.next = &amp;(Node) {&amp;jp1};

    Node link_c1_y2 = { &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;jp1}}}}};
    Node link_c2_y2 = { &amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;(Node) {&amp;jp2}}}}};

    if (is_intersected(&amp;link_1_n, &amp;link_2_n)) {
        printf("link_1_n and link_2_n Intersected!\n");
    }

    if (is_intersected(&amp;link_1_y, &amp;link_2_y)) {
        printf("link_1_y and link_2_y Intersected!\n");
    }

    if (is_intersected(&amp;link_c1_n, &amp;link_c2_n)) {
        printf("link_c1_n and link_c2_n Intersected!\n");
    }

    if (is_intersected(&amp;link_c1_y, &amp;link_c2_y)) {
        printf("link_c1_y and link_c2_y Intersected!\n");
    }

    if (is_intersected(&amp;link_c1_y2, &amp;link_c2_y2)) {
        printf("link_c1_y2 and link_c2_y2 Intersected!\n");
    }
    return 0;
}

int is_intersected(Node* p1, Node* p2) {
    Node* has_circle_1 = has_circle(p1);
    Node* has_circle_2 = has_circle(p2);

    if (has_circle_1) {
        if (has_circle_2) {
            Node* pp1 = has_circle_1;
            Node* pp2 = has_circle_2;
            if (pp1 == pp2 || pp1-&gt;next == pp2)
                return 1;
            while (pp1-&gt;next != has_circle_1) {
                pp1 = pp1-&gt;next;
                pp2 = pp2-&gt;next-&gt;next;
                if (pp1 == pp2)
                    return 1;
            }
            return 0;
        } else {
            return 0;
        }
    } else {
        if (has_circle_2) {
            return 0;
        } else {
            while (p1-&gt;next)
                p1 = p1-&gt;next;
            while (p2-&gt;next)
                p2 = p2-&gt;next;
            return p1 == p2;
        }
    }
    return 0;
}

Node* has_circle(Node* head) {
    Node* p1;
    Node* p2;
    p1 = p2 = head;
    if (p2-&gt;next != NULL) {
        p2 = p2-&gt;next;
    } else {
        return NULL;
    }
    while (p2-&gt;next != NULL &amp;&amp; p2-&gt;next-&gt;next != NULL) {
        p1 = p1-&gt;next;
        p2 = p2-&gt;next-&gt;next;
        if (p1 == p2)
            return p1;
    }
    return NULL;
}
</code></pre>

<p>其中，<code>has_circle</code>方法是判断一个单向链表是否带环的，基本原理就是设置2个“速度”不同的链表，快的去追慢的，追上就是带环，直到较快指针遇到null还没追上就是没有环；假设环包含n个节点，指针<code>p2</code>的"速度"是2，<code>p1</code>的速度是1，相对速度就是1，从相同一点出发的话，<code>p2</code>追上<code>p1</code>至少要n步；若再假设该链表除了环的部分外还带有一个长度为k的“尾巴”，那么追上的步数最多是n+k;也就是线性时间复杂度内就能完成这个判断。</p>

<p>这提供了一种很好的判断是否"环状"的思路；以前我只写过“用一个栈来记录”的方式，弱爆了...(时间复杂度为O(n<sup>2</sup>))</p>

<p>在<code>has_circle_1</code>和<code>has_circle_2</code>都满足的时候，也就是说2个链表都带环的时候，要分别取2个环上的一点来玩“追逐游戏”来判断是否相交；在这段程序里是<code>pp1</code>和<code>pp2</code>;然后一个速度为2一个速度为1开始玩“追逐游戏”，当慢的那个走完环上所有节点时快的那个还没追上它的话，说明不相交(此时耗费时间n——即环节点数;因为快慢指针的相对速度为1，快指针理应在时间n以内追上慢链表，否则不相交)。</p>

<h3>总结</h3>

<p>单向链表的问题...着实不简单，可以相当复杂...对于这种关乎“形状”的问题，在纸上画一画会很有帮助。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[编程之美]寻找最大的k个数]]></title>
    <link href="http://pfmiles.github.com/blog/find-the-max-k-numbers"/>
    <updated>2012-03-02T13:37:00+08:00</updated>
    <id>http://pfmiles.github.com/blog/find-the-max-k-numbers</id>
    <content type="html"><![CDATA[<p>《编程之美》上的一道题： <a href="http://bop1.wikispaces.com/%E7%AC%AC%E4%BA%8C%E7%AB%A0+%E6%95%B0%E5%AD%97%E4%B9%8B%E9%AD%85#x-2.5%20%E5%AF%BB%E6%89%BE%E6%9C%80%E5%A4%A7%E7%9A%84K%E4%B8%AA%E6%95%B0%20%E2%98%85%E2%98%85%E2%98%85">wiki链接</a>;
其实在<a href="http://blog.csdn.net/v_JULY_v/article/details/6370650">July的文章里有更加深刻的分析</a>，我这里只是用最小堆的方式实现一遍，体会和总结一下。</p>

<h3>分析</h3>

<ul>
<li>这个问题，只要找到“最大的K个数”，但并不要求这K个数之间排序；</li>
<li>而且如果K很小的话，完全可以采用选择排序的方式，达到O(nk)的复杂度；</li>
<li>若K不小，则可利用这“只能容纳K个数的最小堆”的方法来做；时间复杂度是O(nlogk);用“堆”这种结构来解决此问题，很好地理解和利用了堆的特性:

<ol>
<li> 找最大的K个数要使用最小堆，是因为最小堆总能最方便地剔除“最小的元素”，那么最后剩在堆中的都是最大的K个元素了；反之，若要找“最小的K个元素”则应该使用最大堆</li>
<li> 二叉堆的同层节点之间是没有顺序的，这恰好符合我们的题目“不要求K个数之间排序”的需求，少了K个数之间的排序则能够减少不必要计算</li>
</ol>
</li>
</ul>


<h3>程序</h3>

<pre><code>#include &lt;stdio.h&gt;

// defines the heap structure
typedef struct {
    int size, last_pos;
    int* data;
} Heap;

void into_min_heap(int node, Heap* heap);
void adjust_min_heap(Heap* heap, int cur_index);

// find the max k digits
void max_k(int len, int array[], int k, int rst[]) {
    // build min-heap on rst while iterating array:
    // worst time complexity: n * log k
    int i;
    Heap heap = { k, -1, rst };
    for (i = 0; i &lt; len; i++) {
        into_min_heap(array[i], &amp;heap);
    }
}

void into_min_heap(int node, Heap* heap) {
    if (heap-&gt;last_pos == -1) {
        heap-&gt;data[0] = node;
        heap-&gt;last_pos = 0;
    } else {
        if (node &lt; heap-&gt;data[0]) {
            return;
        } else {
            if (heap-&gt;last_pos + 1 &lt; heap-&gt;size) {
                heap-&gt;data[heap-&gt;last_pos + 1] = node;
                heap-&gt;last_pos++;
            } else {
                heap-&gt;data[0] = node;
                adjust_min_heap(heap, 0); // log k
            }
        }
    }
}

void adjust_min_heap(Heap* heap, int cur_index) {
    int c1_index = (cur_index + 1) * 2;
    int c2_index = (cur_index + 1) * 2 + 1;
    if (c1_index &lt; heap-&gt;size) {
        if (heap-&gt;data[cur_index] &lt;= heap-&gt;data[c1_index]) {
            if (c2_index &lt; heap-&gt;size) {
                if (heap-&gt;data[cur_index] &lt;= heap-&gt;data[c2_index]) {
                    return;
                } else {
                    int tmp = heap-&gt;data[cur_index];
                    heap-&gt;data[cur_index] = heap-&gt;data[c2_index];
                    heap-&gt;data[c2_index] = tmp;
                    adjust_min_heap(heap, c2_index);
                }
            }
        } else {
            int tmp = heap-&gt;data[cur_index];
            heap-&gt;data[cur_index] = heap-&gt;data[c1_index];
            heap-&gt;data[c1_index] = tmp;
            adjust_min_heap(heap, c1_index);
        }
    }
}

int main(int args, char** argv) {
    int k = 3;
    int rst[k];
    int arr[10] = { 1, 20, -35, 4, 7, 11, 19, -5, 0, 18 };
    max_k(10, arr, k, rst);
    printf("The max k numbers are: ");
    int i;
    for (i = 0; i &lt; k; i++) {
        printf("%d ", rst[i]);
    }
    return 0;
}
</code></pre>

<h3>总结</h3>

<p>还是要理解各种常用数据结构的特性及其意义，遇到特定的问题时才好能够正确地选择出最能适合需求的这种结构。</p>
]]></content>
  </entry>
  
</feed>
