<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: compiler | Meta-Interpretation]]></title>
  <link href="http://pfmiles.github.io/blog/category/compiler/atom.xml" rel="self"/>
  <link href="http://pfmiles.github.io/"/>
  <updated>2015-08-15T17:22:27+08:00</updated>
  <id>http://pfmiles.github.io/</id>
  <author>
    <name><![CDATA[pf_miles]]></name>
    <email><![CDATA[miles.wy.1@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[用于代码生成的模板引擎应该是什么样子？]]></title>
    <link href="http://pfmiles.github.io/blog/what-does-a-template-engine-for-code-generation-look-like"/>
    <updated>2012-09-13T15:27:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/what-does-a-template-engine-for-code-generation-look-like</id>
    <content type="html"><![CDATA[<p>以前在做一个涉及代码生成的项目的时候，使用了velocity模板引擎来做这个代码生成；<br/>
而事后发现，velocity有大部分的语法是我在代码生成过程中没有用到的；<br/>
且velocity的引入，也导致引入了一些看起来很多余的jar包；<br/>
后来我看了看<code>StringTemplate</code>这个东西，发现它不仅包含velocity几乎全部的语法，还有模板继承机制！这岂不是更复杂？虽然标榜为“为了代码生成”的模板引擎...但鉴于<code>velocity</code>的复杂印象，我并没有使用它.  <br/>
再后来，我为了包管理上的简洁(对于某些项目我承认我有洁癖)，我直接使用了java标准库里的<code>java.text.MessageFormat</code>来做代码生成；这也确实可行！不过，缺点也是很快就能遇到的：</p>

<ol>
<li>大括号<code>{</code>和<code>}</code>在<code>MessageFormat</code>中是关键字！所以输出时必须转义；这两个东西在目标代码中(比如java)很常见，遇到一个就要转义一个是很不爽的事情;</li>
<li>除了字符串替换之外，没有任何分支逻辑判断、循环结构支持，这使得所有的分支逻辑和循环结构都要写在调用这些<code>MessageFormat</code>的java代码里；虽然很多时候确实可以这么做并且很合适，但是还是有一些情况，如果能写在模板里会明显比写在java代码里好;</li>
<li><code>MessageFormat</code>的placeholder是数字，渲染时是根据传入参数的位置来做值替换，这很不直观，更好的用户体验应该是依据名字来替换，就像所有的、普遍意义上人们所见过的模板引擎那样;</li>
</ol>


<p>总结性地思考一下：我在做代码生成的时候，需要的模板引擎大概应该是：</p>

<ul>
<li>简单，这意味着只需要拥有简单的语法以及简单的jar包依赖(或者不需要jar包依赖)</li>
<li>高效，最好直接编译成字节码执行，而非像velocity那样每次渲染都遍历AST</li>
</ul>


<p>而重点就在于第一点：简单，这需要我好好总结一份“用作代码生成的模板引擎所必须的语法特性”列表, 并且除此以外，不能有更多其它的东西;<br/>
至于高效，只要确保最终被反复执行的逻辑是一个编译好的java类就行了，而非遍历AST，这很容易办到;<br/>
而且..正好之前开发的<a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a>需要为用户提供一个模板引擎，因为语法解析与代码生成在很多任务中是一对好基友，常常是伴随着出现；那么在dropincc.java中内建一个针对代码生成的模板引擎也就是非常有必要的了；它之于dropincc.java，就好比StringTemplate之于antlr，都是为了方便用户做代码生成创造的;<br/>
并且，这个模板引擎应该随着dropincc.java一起发布，不需要引入新的jar包依赖;<br/>
计划中，这个模板引擎的基本特性：</p>

<!-- more -->


<ol>
<li>编译为java字节码，常驻内存</li>
<li>语法简单，只支持<code>if-else</code>语句和<code>foreach</code>语句, <code>foreach</code>语句支持数组和<code>Collection</code>的遍历, 也支持对"range常量"的遍历</li>
<li>兼容velocity语法的一个子集, 但语义不一样(即只实现其<code>if-else</code>和<code>foreach</code>语法，一方面这是为了利用已有的、强大的velocity语法高亮插件)</li>
<li>任何元素的输出结果总是与<code>String.valueOf(obj)</code>的结果一致</li>
<li>逻辑判断只支持<code>==</code>、<code>!</code>, 支持<code>&amp;&amp;</code>或<code>||</code>和括号优先级，因为我认为，用于代码生成的模板引擎的语法应该全是“开关”形式的，即“已经是判断的结果了”，非<code>true</code>即<code>false</code>(顶多再加上<code>==</code>比较)，不应该有过多的动态的复杂逻辑判断，这些判断其实应该放到调用这个模板引擎的java代码里, 而在模板里，只应该存在对这些bool值的与、或、非的各种组合判断</li>
<li><code>==</code>操作符的判断结果与java中<code>==</code> + <code>equals</code>函数的判断逻辑一致</li>
<li>模板context支持map和javabean两种形式, 可使用<code>.</code>操作读取bean或map中的属性值，但不支持方法调用</li>
<li>没有赋值语句，context中的所有东西，要么是要输出的元素，要么是作为输出控制的bool开关，它们在渲染过程中是不可变的</li>
<li>模板引擎接口简单、清晰，只有4个static方法：

<ul>
<li><code>public static String merge(String filePath, Object context, Class&lt;?&gt; cls)</code></li>
<li><code>public static byte[] mergeAsBytes(String filePath, Object context, Class&lt;?&gt; cls)</code></li>
<li><code>public static String merge(String filePath, Object context, Class&lt;?&gt; cls, String encoding)</code></li>
<li><code>public static byte[] mergeAsBytes(String filePath, Object context, Class&lt;?&gt; cls, String encoding)</code></li>
<li>其中，<code>filePath</code>是模板路径; <code>context</code>可是javabean或map，为模板上下文，包含要输出的元素和控制条件; <code>cls</code>是用于加载模板资源的class类，模板资源查找规律与<code>Class.getResourceAsStream</code>方法一致; <code>encoding</code>是指定模板所使用的编码格式; 返回<code>String</code>的方法即返回渲染后的字符串结果；返回<code>byte[]</code>的接口则是直接返回带编码格式的、<code>byte</code>的数组，这个结果可直接用作写入外部存储或流，而无需再应用编码格式;</li>
</ul>
</li>
</ol>


<p>而基本上就是这些，不需要太多东西，可能第一眼会觉得“功能是不是太少”？但是，我已经见过了许多过重的逻辑被放在模板语法里的情况，与其增加这种不必要的、很可能是错误的使用方式(因为这样做确实不好维护)，还不如一开始就不提供了；<br/>
并且，代码生成所需要的模板引擎，相比起做web页面所需要的模板引擎来讲，一定要简单许多；因为大部分的逻辑是应该放在java代码中(比如负责翻译代码的visitor)而不是模板里。</p>

<p>ok, 下面需要给出这个模板引擎的<a href="http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form">EBNF</a>,这是最重要的准绳，几乎框定了绝大部分东西：</p>

<pre><code>template ::= content $
content ::= renderable*
renderable ::= PLAIN_TEXT
          | '#if' '(' boolExpr ')' renderable ('#elseif' '(' boolExpr ')' renderable)* ('#else' renderable)? '#end'
          | '#foreach' '(' REF 'in' (REF|RANGE) ')' renderable '#end'
          | REF
boolExpr ::= andExpr ('||' andExpr)*
andExpr ::= term ('&amp;&amp;' term)*
term ::= '!'* REF
       | value '==' value
       | '!'* '(' boolExpr ')'
value ::= '-'?[0-9]+('.'[0-9]+)?
        | '\'' .* '\''
</code></pre>

<p>语法就是这样，应该已经足够;上述规则中，全大写字母的元素是terminal，一部分terminal的定义未在上面给出，补充在下面：</p>

<pre><code>REF ::= '${' ID('.'ID)* '}'
ID ::= [a-zA-Z_][a-zA-Z0-9_]*
RANGE ::= '[' [0-9]+ '..' [0-9]+ ']'
</code></pre>

<p>总结起来讲，这个模板语法支持<code>if</code>和<code>foreach</code>语句，以及引用值的输出，其余的元素一律被看作<code>PLAIN_TEXT</code>直接输出;<br/>
在<code>if</code>语句中，逻辑表达式支持<code>==</code>比较，以及“非”逻辑<code>!</code>;支持添加圆括号调整运算优先级;<br/>
<code>foreach</code>语句中，可以支持对引用(必须是<code>Collection</code>或<code>Array</code>)或<code>RANGE</code>表达式的遍历; <code>RANGE</code>表达式即生成一个数字序列的表达式，步长为1，如<code>[1..10]</code>表示一个由1到10的数字序列;</p>

<p>至于具体的实现方式，仍然采用与dropincc.java一致的jdk1.6 compiler API的动态编译的形式，编译为字节码运行。<br/>
这个模板引擎将作为dropincc.java内部自己做一些代码生成，也同时提供给用户做代码生成工作，这样既能避免过多jar包的引入，又能施行一些最佳实践("最佳"的意思是我这里定义的，在我看来是在“什么逻辑放在模板中”和“什么逻辑放在java代码中”找到一个平衡点，当然不同人可以有不同理解)。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dropincc.java, The Ultimate Tool to Create DSLs in Java]]></title>
    <link href="http://pfmiles.github.io/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java"/>
    <updated>2012-08-04T17:22:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/dropincc-dot-java-the-ultimate-tool-to-create-dsls-in-java</id>
    <content type="html"><![CDATA[<h3>Initial version released.</h3>

<p>Dropincc.java is a dynamic parser generator which allows you crafting your DSLs in pure java, using your favorite editor.<br/>
Now it reached its initial release version 0.1.0. You can download it from the <a href="https://github.com/pfmiles/dropincc.java">project page</a> and play around with it.<br/>
There's a detailed <em>Quick Start</em> guide on the project page, it could guide you through to have a overall feeling on using dropincc.java.</p>

<h3>Main attributes of Dropincc.java.</h3>

<ul>
<li>It's not just 'yet another compiler compiler'. It aims to help you building DSLs in java <strong>Dynamically</strong>.</li>
<li><strong>Dynamic</strong> means you can use your newly defined DSL immediately after you have just finished its definition. No other steps required, no additional command-line instructions needed to type.</li>
<li>Very close to EBNF grammar syntactically when defining grammar rules using dropincc.java. With the fluent interface API, you can feel as if you are writing EBNF directly. Syntactically  close to EBNF is very nice for a parser generator.</li>
<li>It generates LL(*) parser for your language, dynamically, using java 1.6's compiler API. And it provide powerful <em>semantic predicate</em> mechanics to handle even context-sensitive situations.</li>
<li>It won't generate a parser source file to you and telling you to place the file into some where of your project directory. Instead, it handles all those generation &amp; compiling staff in the background and only provides you a executable object which you can invoke.</li>
<li>No other dependencies except for the built-in java library. Requires JDK 1.6 or above.</li>
</ul>


<h3>A dummy language example.</h3>

<!-- more -->


<p>Requires JDK 1.6 or above. Firstly, place the dropincc <a href="https://github.com/pfmiles/dropincc.java/releases">jar file</a> in your class path.</p>

<p>And then, crafting your language's <a href="http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form">EBNF</a> definition:<br/>
Let's define a language which accepts arbitrary numbers of quoted 'a' or 'bc'. For example: '(a)(bc)', '(bc)((a))' or '(((bc)))(bc)', the numbers of pairs of parentheses is unlimited.<br/>
The EBNF of this dummy language:</p>

<pre><code>S ::= L $
L ::= Q*
Q ::= 'a'
    | 'bc'
    | '(' Q ')'
</code></pre>

<p>Ok, after defining the EBNF representation of our language, it's time to <strong>translate</strong> the EBNF into dropincc.java representation. I say 'translate' here because this is a line-by-line straightforward step:</p>

<pre><code>public static void main(String... args) throws Throwable {
    Lang lang = new Lang("Dummy");
    TokenDef a = lang.newToken("a");
    TokenDef bc =lang.newToken("bc");
    TokenDef lp = lang.newToken("\\(");
    TokenDef rp = lang.newToken("\\)");
    Grule L = lang.newGrule();
    Grule Q = lang.newGrule();

    lang.defineGrule(L, CC.EOF); // S ::= L $
    L.define(CC.ks(Q));// L ::= Q*
    /*
     * Q ::= 'a'
     *     | 'bc'
     *     | '(' Q ')'
     */
    Q.define(a)
    .alt(bc)
    .alt(lp, Q, rp);
}
</code></pre>

<p>Ok, we have done defining the grammar rules of our dummy language, so easy:</p>

<ul>
<li>Define tokens, using built-in java regular expression syntax. And define rules, say, 'Grule's in dropincc.java. TokenDefs and Grules are basic elements of defining grammar rules.</li>
<li>You just using your defined TokenDefs and Grules to express your grammar, just like writing EBNF.</li>
<li>Elements concatenations are expressed by comma separated sequences: <code>L, CC.EOF</code> means <code>L $</code>. CC.EOF is a predefined TokenDef provided by dropincc.java.</li>
<li>Alternative productions of a grammar rule is expressed by a <code>alt</code> method call on a grule element. For example, the <code>Q</code> rule has three alternative productions.</li>
<li>The kleene star(means <strong>zero or more</strong>) and kleene cross(<strong>means one or more</strong>) notation is expressed by <code>CC.ks</code> and <code>CC.kc</code> utility functions. See the line: <code>L.define(CC.ks(Q));// L ::= Q*</code>.</li>
</ul>


<p>That's almost all you need to learn about how to define a grammar using dropincc.java.<br/>
After that, you can <code>compile</code> your grammar:</p>

<pre><code>Exe exe = lang.compile();
</code></pre>

<p>This step would make you a callable object named 'exe'. You can use this object to <code>eval</code> and test your newly defined language:</p>

<pre><code>System.out.println(exe.eval("a(a)((bc))"));
</code></pre>

<p>This would print the output: <code>[Ljava.lang.Object;@67a5a19</code>. It's an object array which holds the whole parse tree:<br/>
<img src="/images/dropincc/dummy.png" alt="Dummy lang parse tree" /></p>

<p>But it's useless just getting the parse tree. We should do something to manipulate the parse tree and produce some 'results' of this parsing.</p>

<p>Ok, suppose we have a dummy task: to remove all parentheses from the input string, leaving only the <code>'a'</code> and <code>'bc'</code>s there. Then at last, return the resulting string as the return value of <code>eval</code> method call on <code>exe</code>.</p>

<p>This involves adding <code>actions</code> to the grammar. The <code>action</code>s are some kind of code block, it should execute when its' corresponding grammar rule production matches.</p>

<p>In dropincc.java, <code>actions</code> are implemented by <code>closure</code>s, using the <code>Action</code> interface. We try to add an action to the <code>Q</code> rule:</p>

<pre><code>Q.define(a).action(new Action() {
    public String act(Object matched) {
        return (String) matched;// string 'a'
    }
}).alt(bc).action(new Action() {
    public String act(Object matched) {
        return (String) matched;// string 'bc'
    }

}).alt(lp, Q, rp).action(new Action() {
    public String act(Object matched) {
        // returns the middle element matched, that's the returned value of the enclosing 'Q' rule
        return (String) ((Object[]) matched)[1];
    }
});
</code></pre>

<p>Above is the <code>Q</code> rule with three actions, each action for one alternative production. In fact since the first two actions does noting but just returning the matched string, so they are not necessary. The <code>Q</code> rule with action could be defined as follows:</p>

<pre><code>Q.define(a)
.alt(bc)
.alt(lp, Q, rp).action(new Action() {
    public String act(Object matched) {
        // returns the middle element matched, that's the returned value of the enclosing 'Q' rule
        return (String) ((Object[]) matched)[1];
    }
});
</code></pre>

<p>Leaving only the third action there. The third action, returned the middle element matched of its production(ignored left and right parentheses). The middle element matched is the return value of the recursively enclosing <code>Q</code> rule.</p>

<p>The action for <code>L</code> rule is quite simple and significant: it collects all strings matched and concatenates them into a whole large string, then return the resulting string:</p>

<pre><code>L.define(CC.ks(Q)).action(new Action() {
    public String act(Object matched) {
        Object[] ms = (Object[]) matched;
        StringBuilder sb = new StringBuilder();
        for (Object m : ms)
            sb.append(m);
        return sb.toString();
    }
});// L ::= Q*
</code></pre>

<p>Then the last top-level rule's action: just return the value of <code>L</code> rule, just ignoring EOF:</p>

<pre><code>lang.defineGrule(L, CC.EOF).action(new Action() {
    public String act(Object matched) {
        return (String) ((Object[]) matched)[0];
    }
}); // S ::= L $
</code></pre>

<p>Ok, we can now run the program again and could see it prints out the output: <code>aabc</code>, with all parentheses removed.</p>

<p>The whole program in a gist:<br/>
<div><script src='https://gist.github.com/3257023.js?file='></script>
<noscript><pre><code>package test;

import com.github.pfmiles.dropincc.Action;
import com.github.pfmiles.dropincc.CC;
import com.github.pfmiles.dropincc.Exe;
import com.github.pfmiles.dropincc.Grule;
import com.github.pfmiles.dropincc.Lang;
import com.github.pfmiles.dropincc.TokenDef;

public class Test {

    /**
     * &lt;pre&gt;
     * S ::= L $
     * L ::= Q*
     * Q ::= 'a'
     *     | 'bc'
     *     | '(' Q ')'
     * &lt;/pre&gt;
     */
    public static void main(String... args) throws Throwable {
        Lang lang = new Lang(&quot;Dummy&quot;);
        TokenDef a = lang.newToken(&quot;a&quot;);
        TokenDef bc = lang.newToken(&quot;bc&quot;);
        TokenDef lp = lang.newToken(&quot;\\(&quot;);
        TokenDef rp = lang.newToken(&quot;\\)&quot;);
        Grule L = lang.newGrule();
        Grule Q = lang.newGrule();

        lang.defineGrule(L, CC.EOF).action(new Action() {
            public String act(Object matched) {
                return (String) ((Object[]) matched)[0];
            }
        }); // S ::= L $
        L.define(CC.ks(Q)).action(new Action() {
            public String act(Object matched) {
                Object[] ms = (Object[]) matched;
                StringBuilder sb = new StringBuilder();
                for (Object m : ms)
                    sb.append(m);
                return sb.toString();
            }
        });// L ::= Q*
        /*
         * Q ::= 'a' | 'bc' | '(' Q ')'
         */
        Q.define(a).alt(bc).alt(lp, Q, rp).action(new Action() {
            public String act(Object matched) {
                // returns the middle element matched, that's the returned value
                // of the enclosing 'Q' rule
                return (String) ((Object[]) matched)[1];
            }
        });

        Exe exe = lang.compile();
        System.out.println(exe.eval(&quot;a(a)((bc))&quot;));
    }
}</code></pre></noscript></div>

You can download and play around with it on your own.</p>

<p>Dropincc.java is currently on its very initial stage. It has some major improvements to be done:</p>

<ul>
<li>It uses java's built-in regEx implementation to support token definition, so it couldn't do 'longest match' currently. This should be fixed later.</li>
<li>Due to some LL(*) analysis issues, 'Non-LL regular' exceptions may be thrown when it encounters some special case of grammar rules. This must be fixed soon.</li>
</ul>


<p>There is a more practical <strong>Hello World</strong> example which implements a full-featured calculator in the quick start guide of dropincc.java. On its project <a href="https://github.com/pfmiles/dropincc.java">home page</a>. Go and check out there if you like.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LL(*)的概念与实现]]></title>
    <link href="http://pfmiles.github.io/blog/concept-and-implementation-of-ll-star"/>
    <updated>2012-07-14T13:59:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/concept-and-implementation-of-ll-star</id>
    <content type="html"><![CDATA[<h3>概念和起源</h3>

<p>LL(*)是由<a href="http://www.cs.usfca.edu/~parrt/">Terrence Parr</a>教授创造的，为使用<a href="http://en.wikipedia.org/wiki/LL_parsing">LL分析</a>的语法解析器做超前查看(look ahead)的一种算法。按照Parr教授的说法，这个算法从最初的想法至今的完善和调整已经历了15年。目前该算法的一个著名的实现在<a href="http://www.antlr.org/">antlr3</a>中。</p>

<h3>特点，n言以蔽之...</h3>

<ul>
<li>对于语法产生式分支的预测判断，走LL分析路子的解析器，其能力完全取决于能超前查看多少个token。传统地讲，LL(1), LL(2)直至LL(k)，就是在讲该解析器能够在语法分析过程中超前查看1, 2, k...个token。</li>
<li>而LL(*)的意思就是，它在语法解析的过程中，超前查看的token个数不是固定的，是可伸缩的，不过这一点LL(k)分析也能做到(在k范围之内...)；</li>
<li>但是，LL(*)还能越过一些重复出现的token，“到达”这些重复出现的token之后的token来做分析，这一点LL(k)是无法办到的(LL(k)无法意识到有token在循环出现，不管情况如何，它都将在尝试k个token之后放弃)；</li>
<li>如果将超前查看的决策逻辑画成DFA的话，就是这样的一种形式：<img src="/images/ll3.png" title="Look Ahead DFA" alt="Look Ahead DFA" />

<ul>
<li>这张图画的是这种语法规则的超前查看决策情况：<code>A ::= a b c | a b e</code>, 显然这是一个LL(3)语法；</li>
<li>但是这样的语法: <code>A ::= a b* c | a b* e</code>是无法被LL(k)识别的，因为中间的<code>b*</code>代表“0个或多个b”(kleene闭包)，这并不是一个固定的重复次数，因此LL(k)无法识别，for any k...</li>
<li>但是，LL(*)算法能够构造出这样的DFA来识别它：<img src="/images/llstar.png" title="LL(*) Look Ahead DFA" alt="LL(*) Look Ahead DFA" /></li>
<li>也就是说，传统LL(k)的look ahead DFA是不带环的，而LL(*)算法能构造出带环的DFA来做判断，它能越过无穷多个存在于环上的token，从而“到达”环之后的token继续做判断。</li>
</ul>
</li>
<li>上面的<code>A ::= a b* c | a b* e</code>语法使用了<a href="/blog/left-recursion-removal-using-kleene-closure/">"kleene闭包"表示法</a>来表示“0个或多个”，这种表示法在正则表达式中很常见；事实上，基于LL(*)算法实现的语法解析器生成器(比如antlr3)对Kleene闭包表示法特别友好，可以鼓励使用，还能顺便解决一些LL分析法所不允许的“<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>”。</li>
<li>大多数情况来讲，LL(*)的识别能力弱于<a href="http://en.wikipedia.org/wiki/LR_parser">LR(k)</a>，但也有少数情况是LR(k)识别不了但LL(*)可以的，所以LL(*)与LR(k)之间并没有严格的强弱顺序。</li>
<li>LL(*)本身对语法的识别能力也是有限的，比如它无法区分"具有相同的递归规则前缀"的多个分支，这种情况是要尽量避免的，大多数能够较容易地改写;</li>
<li>对于LL(*)不能正确分析的情况，还能引入"Semantic Predicate"(语义断言)来辅助判断, Semantic Predicate可以是任何逻辑，只要返回一个bool值就行；有了Semantic Predicate的辅助，LL(*)甚至能够parse一些上下文相关的语法，实际上它能parse C++</li>
</ul>


<h3>主要算法及其实现(python)</h3>

<p><strong> Parr教授在2011年发表的paper"LL(*): The Foundation of the ANTLR Parser Generator"中详细描述了这个算法，下面就是其主要过程，具体的代码实现(python)在工程<a href="https://github.com/pfmiles/llstar">llstar</a>中 </strong></p>

<!-- more -->


<p>为了简单起见，约定大写字母用来命名non-terminal, 小写字母命名terminal或Semantic Predicate，<code>$</code>表示EOF，假设有如下语法规则：</p>

<pre><code>S ::= A $  
A ::= a c*  
    | b c*  
</code></pre>

<ul>
<li>针对此语法规则，构造Augmented Transition Network(ATN)，其实也就是一个NFA，NFA的边就是terminal或non-terminal或者Semantic predicate：<img src="/images/atn.png" alt="ATN network" />, 代码在llstar工程的<code>atn_creation.py</code>的<code>rule.merge_to_atn</code>方法中。</li>
<li>接下来将要对这个ATN实施的算法其实就是经典的<a href="http://en.wikipedia.org/wiki/Powerset_construction">Subset Construction算法</a> —— 的改造版本：在“空边闭包运算(closure)”中加入了压栈、出栈功能，用于处理运算过程中<code>closure</code>函数经过non-terminal边时对其所对应的ATN的调用和返回。<br/>
这个算法的具体描述是比较复杂，在Parr教授的paper中已有精确描述。不过真的要用代码实现起来，某些细节还需稍微修饰，才能正确地实现。<br/>
最后的结果，其实就是使用更改后的版本的Subset Construction算法，将上述ATN(NFA)转化为一个个DFA，每条语法规则都对应一个DFA作为其look ahead DFA。<br/>
例如上面的<code>S</code>规则最后的DFA为：<img src="/images/sdfa.png" alt="S DFA" />, well, 就一个终结态，没任何状态转换 —— 这是当然的，S规则只有一个alternative production... <br/>
而<code>A</code>规则的DFA为：<img src="/images/adfa.png" alt="A DFA" />, 意思就是，如果第一个token为<code>a</code>，就选择第一个分支，若是<code>b</code>，就选择第二个分支，这是一个LL(1)的语法。<br/>
简单来说就是这样，具体可以参考llstar的代码...这花了我不少时间调试出来的代码，还是直接看代码了解最直接:)</li>
</ul>


<h3>实验台及例子介绍</h3>

<p>OK，主要的算法原理了解之后，展示了2个玩具例子，似乎还不能看出LL(*)的特点来。<br/>
下面我将逐步展示一些真正non-trivial的例子，以表明它真的不是过家家...</p>

<p>LL(3)(更正：或许这该是LL(4)可能我数错了)语法(对应llstar工程中的<code>LL_3_many_alts.py</code>):</p>

<pre><code>S ::= A $
A ::= B a*
    | C a+
    | D a?
B ::= a b c C
    | a b c D
    | d
C ::= e f g D
    | e f g h
D ::= i j k l
    | i j k m
</code></pre>

<p>这个语法是固定的LL(3)，没有什么特别，不过分支比较多, 它的ATN：<img src="/images/ll3atn.png" alt="LL(3) ATN" /><br/>
规则<code>A</code>的DFA: <img src="/images/llstar/ll3adfa.png" alt="LL(3) Rule A DFA" /><br/>
规则<code>B</code>的DFA: <img src="/images/llstar/ll3bdfa.png" alt="LL(3) Rule B DFA" /><br/>
规则<code>C</code>的DFA: <img src="/images/llstar/ll3cdfa.png" alt="LL(3) Rule C DFA" /><br/>
规则<code>D</code>的DFA: <img src="/images/llstar/ll3ddfa.png" alt="LL(3) Rule D DFA" /></p>

<p>上面这个语法，LL(4)分析也能搞定，而真正体现出LL(*)特点的是下面这样的语法(对应llstar工程中<code>over_kleene.py</code>)：</p>

<pre><code>S ::= A $
A ::= a* b
    | a+ c
</code></pre>

<p>其中，规则<code>A</code>的2条分支拥有共同的kleene闭包前缀，LL(k)是无法识别的，它的ATN:<img src="/images/llstar/overkleeneatn.png" alt="Over Kleene ATN" /><br/>
而LL(*)能够为<code>A</code>生成这样的DFA：<img src="/images/llstar/overkleeneadfa.png" alt="Over Kleene Rule A DFA" /><br/>
这个DFA能够越过terminal<code>a</code>的任意重复，从而考虑到后面的terminal<code>b</code>和<code>c</code>来做判断<br/>
而下面这个更加"恶劣"的列子则更能说明LL(*)的这个特征(对应llstar工程中<code>over_non_recurse_rule.py</code>)：</p>

<pre><code>S ::= A $
A ::= B* b
    | C+ c
B ::= a d
    | e
C ::= a d
    | e
</code></pre>

<p>这个例子中，<code>B</code>和<code>C</code>完全相同，并分别被包含在规则<code>A</code>的2条分支的kleene闭包中，<br/>
最终生成的<code>A</code>的DFA: <img src="/images/llstar/nonrecursiveradfa.png" alt="Non-recursive Rule A DFA" /></p>

<p>上面提到过，LL(*)也有不能解决的情况，比如2条分支拥有"共同的、递归的规则作为前缀"，比如这样：</p>

<pre><code>S ::= A eof
A ::= E a
    | E b
E ::= c E d
    | e
</code></pre>

<p>上面的<code>A</code>规则的两条分支拥有共同的前缀<code>E</code>，而<code>E</code>本身是一条递归规则，这样的规则是LL(*)无法分析的，在llstar工程中对应<code>experiments/common_recurse_prefix_fail.py</code>, 运行的时候会抛出错误提示。这种情况在antlr3中会将parsing策略退化为LL(1) + 回溯的形式。</p>

<pre><code>Traceback (most recent call last):
  File "/home/pf-miles/myWorkspace/llstar/experiments/common_recurse_prefix_fail.py", line 31, in &lt;module&gt;
    d_a = create_dfa(ra.get_start_state(globals_holder.a_net))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 136, in create_dfa
    d_state_new.add_all_confs(closure(d_state, conf))
  File "/home/pf-miles/myWorkspace/llstar/algos.py", line 99, in closure
    raise Exception("Likely non-LL regular, recursive alts: " + str(d_state.recursive_alts) + ", rule: " + str(globals_holder.a_net.get_rule_of_state(p)))
Exception: Likely non-LL regular, recursive alts: set([0, 1]), rule: E
</code></pre>

<p>还有一些特殊情况，比如规则完全就是冲突的，那么这个时候就是Semantic Predicate发挥作用的时候(对应llstar工程中<code>conflicting_with_preds.py</code>)：</p>

<pre><code>S ::= A $
A ::= {pred1}? B
    | {pred2}? b
B ::= b
    | b
</code></pre>

<p>最终<code>A</code>的DFA：<img src="/images/llstar/confresolvedwithpredsadfa.png" alt="Conflict Resolved With Preds A DFA" /><br/>
实际开发中，写出这样的规则是坑到爷的...不过LL(*)还算能很好解决...其实这里就算没有Semantic Predicate, LL(*)也能按照convention，“选择较早定义的语法分支”来解决。</p>

<p>还有就是在分析的过程中会导致分析栈溢出(不是程序语言的callstack的overflow, 而是LL(*)的closure操作维护的一个规则调用栈溢出)的时候，LL(*)也会使用Semantic Predicate来辅助判断, 比如规则(对应llstar中<code>overflow_with_preds.py</code>):</p>

<pre><code>S ::= A $
A ::= {pred1?} B a
    | {pred2?} b* c
    | {pred3?} b* c
B ::= b+ B
</code></pre>

<p>规则<code>A</code>的三条分支全部存在严重冲突(都拥有能识别无穷个'b'的前缀)并且其中一个是另一条递归规则<code>B</code>，这种形式会导致LL(*)的分析栈溢出，不过仍然没关系，这样的情况能在溢出发生时，调用<code>pred1</code>、<code>pred2</code>和<code>pred3</code>来解决(这三个pred就是Semantic Precicate，是能包含任何逻辑但最终返回bool值的表达式)<br/>
生成的规则<code>A</code>的DFA: <img src="/images/llstar/overflowadfa.png" alt="Overflow A DFA" /><br/>
这里设定的最大分析递归层数为<code>10</code>，因此，DFA在接受了第10个'b'之后达到了溢出状态<code>d14</code>，这时调用了各个alternative附带的几个predicate来解决冲突...</p>

<blockquote><p>(2012-09-03 注： 实际上上述规则是不正确的，<code>B ::= b+ B</code>是有问题的规则，因为<code>b+</code>会贪婪地match掉所有的连续的<code>'b'</code>，导致后面的<code>B</code>只可能抛错; 所以这个例子也只能用来演示分析栈溢出的情况，实际应用中是不可能写出这样的规则的)</p></blockquote>

<h3>总结</h3>

<p>OK, 大概如是了；上述算法的实现、例子的代码均在<a href="https://github.com/pfmiles/llstar">llstar</a>工程中能找到<br/>
llstar工程是我花了不少时间实现并调试好的一块LL(*)算法的“实验台”，可以在里面慢慢把玩各种变态的、五花八门的语法规则，以验证LL(*)的分析能力<br/>
在工程的<code>experiments</code>文件夹下已经有许多具有代表性的例子...都是python代码<br/>
另外，llstar工程是在eclipse + pydev环境下开发的，因此如果要在命令行里运行，可能要对例子里面的import路径稍作修改，当然，最好是直接在eclipse + pydev环境下运行它们了<br/>
在linux环境下，llstar的所有例子都能自动生成上文中看到的各种DFA/NFA图像，不过前提是环境中要装有<a href="http://www.graphviz.org/">graphviz</a></p>

<p>现在的所有语法解析器生成器中，似乎都是LR分析的天下，LL分析大多是手写解析器的首选...<br/>
不过在现有的使用LL分析方式的产品中，也就只有LL(*)和PEG(Packrat)parsing比较常见也比较实用了，能与LR分析一较高下。<br/>
而配上回溯策略的LL(*)是严格强于Packrat parsing的，这样看来大概走LL分析路子的自动化工具也只有LL(*)容易一枝独秀了(想必这也是antlr相对较为流行的原因)。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Kleene闭包语法糖消除语法中的左递归]]></title>
    <link href="http://pfmiles.github.io/blog/left-recursion-removal-using-kleene-closure"/>
    <updated>2012-03-28T11:18:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/left-recursion-removal-using-kleene-closure</id>
    <content type="html"><![CDATA[<p>一般来讲，如果使用的解析器生成器是基于LL分析法来解析文本的话(比如antlr)，我们就需要在编写语法规则的时候避免<a href="http://en.wikipedia.org/wiki/Left_recursion">左递归</a>。<br/>
虽然有一套成熟的、公式化的方法来去除左递归，但它会影响原有文法的结合顺序、优先级，或者多出一些本不需要的、额外的产生式。<br/>
例如，有左递归语法规则：</p>

<pre><code>addition ::= addition '+' factor
           | factor
</code></pre>

<p>这个式子其实是想要表达一个“一连串+号组成的和”的表达式，例如<code>1+2+3+4</code>；<br/>
假设目前的输入就是<code>1+2+3+4</code>, 那么超前查看带来的选择应该是<code>addition '+' factor</code>这个产生式；于是在parser的代码中立刻就又直接调用了<code>addition()</code>方法，但注意，整个递归过程没有消耗掉任何token...也就是说，当流程再次递归到<code>addition</code>函数里时，输入<code>1+2+3+4</code>并没有任何改变，这又会进入下一轮递归...很快就会overflow。<br/>
这个问题，除了机械性地按照公式来消除左递归外，还可以改写语法规则，使其成为右递归语法：</p>

<pre><code>addition ::= factor '+' addition
           | factor
</code></pre>

<p>这样就不用stackOverFlow了，但是带来另一个问题：这使得我们的'+'加法成为了一个'右结合'的运算...<br/>
也就是说，<code>1+2+3+4</code>的计算次序是这样的：<code>1+(2+(3+4))</code><br/>
还好这里是“加法”，整数集合和加法运算构成“阿贝尔群(可交换群)”，满足交换律，所以就算实现成右结合的也能蒙混过关...但减法呢？除法呢？</p>

<!-- more -->


<p>难道要先生成一个AST，再写个visitor，把节点顺序给rewrite一下，然后再写个visitor求值？这么麻烦就为了实现一个简单的四则运算功能也太坑爹了。</p>

<p>其实，我们在这里使用递归，只是为了表达元素的“重复”这种意思；的确，递归能表示“重复”的概念，但这很容易让人联想到“循环”，因为平时的编程中，我们都通常使用循环来表达“重复”这种东西的。<br/>
更重要的是，循环与<a href="http://en.wikipedia.org/wiki/Tail_call">尾递归</a>在逻辑上是等价的，这使得我们可以将上述左递归改写成某种表示“循环”的形式，在这里，<a href="http://en.wikipedia.org/wiki/Kleene_star">Kleene Closure(克林闭包)</a>就正是一种表达“循环”的标记形式。<br/>
熟悉正则表达式的我们都知道，符号<code>*</code>(kleene star)和符号<code>+</code>(kleene cross)分别用来表示前面临接元素的“0个或多个”和“一个或多个”，如果这种标记用在我们的语法规则中那就酷毙了：</p>

<pre><code>addition ::= (factor '+')* factor
</code></pre>

<p>表达的意义和"左递归版本"的语法规则是一样的，但是，这种记法的重大意义就是：在生成的parser程序中可以直接以一个<code>while</code>语句来解析重复的<code>(factor '+')</code>而不用再递归回<code>addition</code>中！这样就避免了parser中的左递归实现带来的问题！<br/>
由于kleene闭包所能表达的所有语法规则形式都能被递归所表达，所以引入kleene闭包并没有从形式上增加语法解析器生成器的表达能力，所以说kleene闭包只是一个“语法糖”。<br/>
但它的实现意义却是重大的：解决了“为了表达‘元素重复’”的这一类左递归问题。
当然，<a href="https://github.com/pfmiles/dropincc.java">dropincc.java</a>也会支持kleene闭包的表达形式，大致的api形式如下：</p>

<pre><code>addition.fillGrammarRule(addend, CC.ks(ADD.or(SUB), addend));
</code></pre>

<p><code>CC.ks</code>方法就是kleene star的意思，当然还有<code>CC.kc</code>，顾名思义。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dropincc.java的概念与设计]]></title>
    <link href="http://pfmiles.github.io/blog/the-main-ideas-and-concepts-of-dropincc-dot-java"/>
    <updated>2012-03-17T17:40:00+08:00</updated>
    <id>http://pfmiles.github.io/blog/the-main-ideas-and-concepts-of-dropincc-dot-java</id>
    <content type="html"><![CDATA[<h3>做这么个小lib的动机？</h3>

<p>其实由于java语言先天缺陷的元编程能力，在java的圈子里很少有人提到“DSL”的概念，就算有也是说说而已。与之相比，一些其它语言ruby, python, lisp等等，得益于其强大的元编程能力，直接利用自身语法特性，取一块语法子集，利用一些对象、类生命周期切入函数或者宏系统两三下就DSL 'on-the-fly'了，这种便利性可能由java的设计目标来看，恐怕永远也无法达到了。<br/>
那么，在java里面想实现一个DSL，恐怕就得走“外部DSL(详见Fowler的文章: <a href="http://martinfowler.com/bliki/DomainSpecificLanguage.html">DomainSpecificLanguage</a>)”的路子。<br/>
而“外部DSL”这条路并不好走，说白了也就是自己做词法、语法、语义分析，自己生成目标语言代码去执行真正的逻辑；也就是做一个编译器前端外加一段解释执行逻辑；编译器前端，虽然业界看上去有很多很多工具可以直接采用，但是这些工具，目前看来，我认为还是太“General purpose”了，它们往往要求使用者学习它们自己规定的一套用作表达词法、语法规则的DSL，然后提供一个特殊的编译程序，用作编译你用它的DSL写的这些词法、语法文件，最终生成你想要的、基本不可读的编译器前端代码 —— 放到你的项目中去使用；<br/>
这种形式的工具在目前的编译器前端生成器中占大多数，使用上绝对称不上是“便利”。除了它用作描述规则的DSL需要使用者学习之外，其使用过程涉及好几个步骤与环境，是很麻烦的一件事情。<br/>
曾经有一次，一个同学试图使用antlr来做一个类似SQL子集的DSL，他花很多时间与antlr本身的语法文件、IDE “antlrworks”作斗争...频繁地在eclipse, 命令行, antlrWorks之间切换；我就想，做一个这样的DSL，是否真的用得上这么多工具？是否真的用得上号称能parse C++的antlr？这些事情能否全部在一个工作环境内搞定？比如eclipse？
而来自<a href="https://github.com/luikore/rsec">rsec</a>的启发让我觉得java似乎更应该有这样一个东西：</p>

<ol>
<li>以java的语法来新增词法、语法规则，不需要学习新的语法；</li>
<li>不需要依赖外部环境，仅在java开发环境中就能完成新语言的定义与编译器前端程序的生成；</li>
<li>虽然java是静态类型编译型语言，但整个新语言构建过程应该看上去是“动态的”、“解释性”的，这样“体验”才会好；</li>
<li>这个库要小、要没有其它三方库依赖，仅依靠JDK自带库就能使用；</li>
<li>在使用过程中尝试推行一些好的实践，确保大多数普通青年不会“自找麻烦”，比如“限制词法规则必须为正规文法(或者说乔姆斯基3型文法)”。</li>
</ol>


<p>而<a href="https://github.com/pfmiles/dropincc.java">Dropincc.java</a>正是以上述几点为设计目标的一个小巧(但足够强大)的编译器生成器。</p>

<!-- more -->


<h3>设计与实现思路</h3>

<p>以上第一点，基本上的想法就是，设计一套“串接与组合(cascading &amp; composition)”风格的API，模拟出一套parser combinator，让用户使用这套“貌似带有CC的语义”的java方法API来做词法、语法规则的添加(CC即："compiler-compiler, 就是'编译器生成器'")。<br/>
比如我想创建一套支持加减乘除的表达式计算器，还能使用括号调整运算优先级，我大概能用下面这样的形式直接在java代码中定义其词法、语法规则：</p>

<blockquote><p>注：下面的代码只是示意说明整体API风格，不一定是最终能运行的代码。</p></blockquote>

<pre><code>Lang lang = new Lang();
Token DIGIT = lang.addToken("\\d+");
Token ADD = lang.addToken("\\+");
Token SUB = lang.addToken("\\-");
Token MUL = lang.addToken("\\*");
Token DIV = lang.addToken("/");
Token LEFTPAREN = lang.addToken("\\(");
Token RIGHTPAREN = lang.addToken("\\)");

Grule expr = new Grule(); // grammar root
Grule term = new Grule();

Element mulTail = lang.addGrammarRule(MUL.or(DIV), term);
term.addGrammarRule(DIGIT, mulTail)
        .alt(LEFTPAREN, expr, RIGHTPAREN)
        .alt(DIGIT);
Element addendTail = lang.addGrammarRule(ADD.or(SUB), term);
expr.addGrammarRule(term , addendTail, CC.EOF);
</code></pre>

<p>其实想要表达的规则写成类似"BNF"的形式就是：</p>

<pre><code>// token rules
DIGIT ::= '\d+';
ADD ::= '+';
SUB ::= '-';
MUL ::= '*';
DIV ::= '/';
LEFTPAREN ::= '(';
RIGHTPAREN ::= ')';

// grammar rules
mulTail ::= (MUL | DIV) term;
term ::= DIGIT multail
       | LEFTPAREN expr RIGHTPAREN
       | DIGIT
       ;
addendTail ::= (ADD | SUB) term;
expr ::= term addendTail EOF;
</code></pre>

<p>这简直就是“line to line”的直译，而<a href="https://github.com/pfmiles/dropincc.java">Dropincc.java</a>的目标也就是要达到这样的效果；<br/>
这么做的目的并不是实现一套标准意义上的BNF；它使用了正则表达式来描述词法规则(token)，也就是上面提到的“目标”的第5点：“限制词法规则必须为正规文法”，这么做的意思也就是建议用户在“若词法规则中出现正规文法无法解决的意义冲突时”，将冲突“推后”到后面的语法、甚至语义分析阶段去解决；这种推荐的“较好实践”能够保持词法规则足够简单，使用正则表达式就能清晰地描述；如果用户不理解“保持词法规则足够简单”的重要性，只需要让他思考一下“为什么java的标识符不能由数字开头”应该就能想通了。<br/>
事实上就是：如果你不想自找麻烦，那么就应该保持词法规则足够简单 —— 你不应该在词法解析阶段耗费太多的实现精力 —— 这里用正则表达式就好了 —— 后面还有更麻烦、更有意义的活儿等着你去干呢...你不应该卡在词法分析这里太久...<br/>
好了，上面的这种约束一方面推行了一种“较好的实践”，另一方面也使得我们的这个工具更加直观、好用、简单，并且并不降低其实现语言的能力。</p>

<p>第二、三点，打算使用JDK1.6的新compiler API来实现；目前业界中的大多数CC工具都是“生成一个源文件”，让用户直接在项目中使用这个源文件；其实我认为这个东西以“源文件”的形式出现在项目中意义并不大，因为它几乎不可读(不可读的源代码有什么意义呢？)。只要有一个可执行的内存表示即可，“源文件”其实就不必了...这样也似乎使得项目代码看上去更“干净”。</p>

<p>至于第四点，也是很重要的，实现过程中一直保持“不依赖JDK以外的库”即可。</p>

<p>当所有的规则都定义完毕，只要在代码中触发"compile"，立刻就能基于定义的规则在内存中生成一个可执行的编译器前端，没有“源代码”，因为那没有意义，用户需要做的就只是拿它去执行新出生的语言的代码逻辑：</p>

<pre><code>lang.compile();
lang.exe("1+2+3*4/(5*6*7+8)");
</code></pre>

<p>当然，还有“action代码”的具体组织形式示例，上面没有给出，在<a href="dropincc-dot-java-api-design/">dropincc.java API Design</a>里面有详尽的阐述。<br/>
基本上对于这个工具的最终输出形式，计划中应该有两种：</p>

<ol>
<li>AST</li>
<li>直接执行的action</li>
</ol>


<p>输出AST其实是灵活度最大的一种形式，有了AST，那么后面是想解释执行？还是做翻译？那就交由用户去考虑了，dropincc.java的工作到这里也就结束了；<br/>
而“直接执行action”的方式适合像上面这种简单的诸如“四则运算”这样的简单表达式语言，在创建解析树的过程中就把对应的动作代码给执行了，解析结束后直接就能得到结果。</p>

<p>根据dropincc.java的后续设想，上述2种方式在dropincc.java中实现应该“几乎没有差别”，这两种输出形式虽然目的可能不一样，但在dropincc.java中实现起来应该是高度统一、一致的，这也是为了实现“足够简单”的目标，尽量不要让用户过多地去学习一些概念，增加上手成本。</p>

<p>至于dropincc.java能够用来识别哪种级别的语法？我的设想中dropincc.java是一个LL解析器生成器，最终要能识别LL(*)的语法，也就是跟antlr具有同等能力；不过初期的实现可能还识别不了那种程度的不确定性，这个可以一步一步随着版本推进慢慢来改进。其它一些诸如解决左递归的一些算法改进都可以排在计划中...</p>

<p>OK，前期的设想也就暂时介绍到这里，希望dropincc.java的努力能够将java圈子里的DSL应用甚至<a href="http://en.wikipedia.org/wiki/Language-oriented_programming">LOP</a>编程往前推进一步，这是相当令人振奋的事情。</p>
]]></content>
  </entry>
  
</feed>
